[
    "Data Science Project",
    "Introduction Session: April 17, 12-2 p.m. via Zoom",
    "Zoom link:",
    "https://tu-berlin.zoom.us/j/63600139054?pwd=RmxRczM2SVJ6Znl3MFFhV2VWSlZyQT09",
    "In this course, a Data Science problem from a scientific or industrial domain is treated in a practice-oriented manner.",
    "In this semester, we offer several different topics with focus on Machine Learning, Natural Languge Processing, Explainable AI, and Time Series:",
    "Topics",
    "Topic overview",
    "Topic 1: Reliably Answering Questions related to Services offered by the Berlin's Administration",
    "Topic 2: Imputation of Missing Values ​​in Time Series Datasets",
    "Topic 3: Towards unsupervised concept attribution for CNNs",
    "Topic 4: Survey: Explainable AI for Vision Transformers",
    "Topic 5: Automatic Image Segmentation by Guiding SAM with Saliency Maps",
    "Topic 6: Survey: Retrieval-Augmented Generation",
    "Topic 7: Evaluation of LLMs' Generated Text Using Zero-Shot Principles via LLMs",
    "Topic 8: Evaluation of Generative Visual Counterfactual Explanations",
    "Topic 9: Survey: Reviewing Current Approaches for Visual Reasoning in Pre-trained Vision Language Models",
    "Topic 1: Reliably Answering Questions related to Services offered by the Berlin's Administration",
    "Bobbi is the chatbot of the Berlin administration. Bobbi reliably answers user questions based on a fixed scheme. This topics explores LLM-based methods for generating more natural answers focused on the user questions. The method should combine information retrieval and LLM-based methods (Retrieval Augmented Generation) as well as dialog management method to explain complex services in a natural-style dialog (eg using Auto-ML methods).",
    "Details",
    "Tasks:",
    "Research on recent LLM, Retrieval, RAG, and ML methods",
    "Setup a system for evaluating the integrated ML and LLM methods",
    "Setup local LLMs or integrate cloud-based LLM services",
    "Evaluate the models/components based on suitable metrics",
    "Discuss the findings in a scientific report",
    "Contact: andreas.lommatzsch@tu-berlin.de",
    "Topic 2: Imputation of Missing Values ​​in Time Series Datasets",
    "Time series are sequences of time-dependent observations. Examples of time series include internet traffic data or sensor signals. Recording such signals is often affected by failures so that the resulting time series have missing values. Most Data Science and Machine Learning methods cannot cope with missing values. Therefore, a common preprocessing step is to insert estimates for the missing values ​​into the time series. This process is called data imputation.",
    "In this project, we want to study a new data imputation technique for time series datasets and compare it to different existing approaches.",
    "Tasks:",
    "Literature research: What approaches are described in the literature and which of those should we select for the study?",
    "Implement Algorithms: Use existing implementations (if available) and implement algorithms described in the literature yourself.",
    "Develop and implement your own ideas you want to investigate (optional).",
    "Experimental Study: Design an experimental setup for comparing different data imputation approaches.",
    "Report: Write a scientific report on your experimental results. Conclude your study.",
    "Contact:",
    "David Schultz (schultz@tu-berlin.de)",
    "Topic 3: Towards unsupervised concept attribution for CNNs",
    "This project aims to enhance Explainable AI (XAI) in neural networks by focusing on Concept Attribution. This technique shifts the focus from identifying \"where\" to understanding \"what\" lies behind model predictions, making XAI more human-centered. It investigates emergent semantic abstractions within convolutional networks aligned with human concepts. The main goal is to analyze emerging concepts in intermediate convolutional layers and categorize them into semantic groups without relying on pre-defined annotations.",
    "Tasks:",
    "Literature review of related works.",
    "Collect and analyze statistics of activation maps.",
    "Develop and evaluate your ideas for identifying concepts.",
    "Write a scientific report on your experimental results.",
    "Contact:",
    "Aray Karjauv (aray.karjauv@tu-berlin.de)",
    "Topic 4: Survey: Explainable AI for Vision Transformers",
    "With the expansion of Transformers from NLP to Computer Vision, there's a need to understand and evaluate Vision Transformers (ViT), especially for Foundation Models as they are usually trained without labels. This project focuses on reviewing and analyzing the latest XAI methods, aiming to explore potential new approaches for ViT.",
    "Tasks:",
    "Literature review of the state-of-the-art methods.",
    "Implement one of the methods (one per student).",
    "Evaluate and compare the methods.",
    "Optionally, propose your own approaches.",
    "Write a scientific report on your experimental results.",
    "Contact:",
    "Aray Karjauv (aray.karjauv@tu-berlin.de)",
    "Topic 5: Automatic Image Segmentation by Guiding SAM with Saliency Maps",
    "This project proposes an automatic image segmentation by combining Saliency Maps with Segment Anything Model (SAM). Utilizing a pretrained classification model, one can generate predictions and saliency maps using existing XAI methods, which are then employed to guide SAM segmentation.",
    "Tasks:",
    "Literature Review: Understand and summarize existing work in XAI and applications of SAM.",
    "Incorporate saliency maps and predictions to guide SAM.",
    "Evaluate the approach based on suitable metrics.",
    "Integrate the approach into Label Studio.",
    "Write a scientific report on your experimental results.",
    "Contact: Aray Karjauv (aray.karjauv@tu-berlin.de)",
    "Topic 6: Survey: Retrieval-Augmented Generation",
    "Retrieval-Augmented Generation",
    "(RAG) is the process of optimizing the output of a large language model, so it references an authoritative knowledge base outside of its training data sources before generating a response. Basically RAG integrates retrieval mechanisms with generative models, enabling more context-aware and informed text generation. This project focuses on evaluating the state-of-the-art methods in this domain, mainly on the embedding and retrieval side.",
    "Tasks:",
    "Literature review of the state-of-the-art methods for RAG (Keyword search/BM25, semantic search/document embedding, synthetic document or query generation methods, etc.).",
    "Implement some of these methods (ideally one per student).",
    "Evaluate and compare the methods.",
    "Optionally, compare the performance of multiple LLMs for the text generation.",
    "Optionally, propose your own approaches.",
    "Write a scientific report on your experimental results.",
    "Contact:",
    "Tolga Akar (tolga.akar@tu-berlin.de)",
    "Topic 7: Evaluation of LLMs' Generated Text Using Zero-Shot Principles via LLMs",
    "In contemporary research, the assessment of text produced by expansive language models involves quantitative analysis across various dimensions, including accuracy, grammatical, congruence, semantic depth, word frequency, relevance, and answerability, among others. Given that distinct models specialize in evaluating specific attributes, deploying multiple pre-trained models for comprehensive text evaluation emerges as a resource-intensive endeavor. This data science initiative aims to appraise expansive language models through the application of expansive language models themselves, adhering to zero-shot learning methodologies. This approach necessitates supplying the text alongside the desired attribute for assessment, in conjunction with a spectrum of numerical values ​​or a set of categorical classes for text evaluation or comparative analysis between texts. Consequently, the emphasis is on leveraging expansive language models for the evaluation of similar models, circumventing the need for model fine-tuning and instead capitalizing on the strategic formulation of prompts to assess diverse attributes through zero-shot learning techniques. This endeavor requires the compilation of datasets wherein texts have previously been evaluated by humans, facilitating subsequent comparison between human assessments and those conducted by several expansive language models, such as ChatGPT, GPT4, OpenChat, LLama, Flan-T5, and others. The primary objective is to harness expansive language models as surrogate human evaluators for content generated by similar models.",
    "Details",
    "Tasks:",
    "Research on evaluation metrics in the NLP domain",
    "Finding human-evaluated text datasets",
    "Conducting zero-shot learning evaluation of various LLMs for each text property",
    "Comparison of the evaluation for each property and each model with the human scores",
    "Visualization of the comparison",
    "Writing a comprehensive text of the experimental results including a literature review",
    "Contact: Pedram Babakhani (pedram.babakhani@tu-berlin.de)",
    "Topic 8: Evaluation of Generative Visual Counterfactual Explanations",
    "Counterfactual explanations are a widely used form of explanation for machine learning algorithms. In counterfactual explanations, based on various objectives, an alternative data instance is sought that leads to a different prediction by the ML model. This explanation is very accessible to humans because it provides them with actionable recommendations on what they need to change to obtain a different desired prediction. At the same time, they gain an understanding of the behavior of the ML model. Humans generate counterfactuals based on semantic changes whereas conventional counterfactual XAI methods only do minimal changes. Generative counterfactual methods, with VAE or GAN, could offer an alternative. These methods generate counterfactuals based on the learned latent space, which, as arguments, aligns with human concepts.",
    "Tasks:",
    "Generate extensive scientific literature review of generative visual counterfactual methods",
    "Implementation of popular algorithms",
    "Conduct user experiments to compare generative counterfactual explanations and human counterfactuals",
    "Write a small research paper about the results",
    "Contact: Nils Ole Breuer (nils.breuer@gt-arc.com)",
    "Topic 9: Survey: Reviewing Current Approaches for Visual Reasoning in Pre-trained Vision Language Models",
    "Large language models (LLMs) are trained on massive amounts of written data, allowing them to understand and respond to language. In contrast, vision language models (VLMs) can see and read. They analyze images and understand text, letting them answer questions about a scene, describe what they see in a picture, or even translate between visuals and words.",
    "Visual reasoning is a crucial superpower for VLMs. It allows you to go beyond simply identifying objects in an image or understanding the meaning of words. VLMs can use visual cues, like size, position, and interaction between objects, to make logical inferences and answer complex questions.",
    "For example, approaches like Visual Chain-of-Thought Prompting can be used to enhance visual reasoning capabilities.",
    "This project focuses on reviewing and analyzing the latest pretrained VLMs, and the approaches used for visual reasoning, aiming to explore potential new approaches.",
    "Tasks:",
    "Research on the state-of-the-art VLMs, approaches, and benchmarks for visual reasoning.",
    "Use available implementations, and implement approaches from the literature (one per student).",
    "Setup a system to evaluate the approaches.",
    "Evaluate and compare the pretrained VLMs and approaches.",
    "Optionally, identify gap and propose own ideas.",
    "Report: Write a scientific report on your experiments and results.",
    "Contact: Abdullah Kiwan (abdullah.kiwan@gt-arc.de)",
    "Course Requirements",
    "Basic knowledge in Machine Learning (eg Foundations of Data Science, Machine Learning 1 or 2, Machine Intelligence 1 or 2, or equivalent)",
    "Interested in scientific work",
    "Further, specific requirements are topic dependent",
    "Module information",
    "Credit Points: 9",
    "Master Course",
    "Module Description:",
    "Link",
    "Responsible: Prof. Albayrak",
    "Course registration",
    "The class size is limited. If you are interested in taking this course, please attend the Introduction session on 17th of April, where we present the offered topics.",
    "After the Introduction session, apply for a topic using the",
    "Application Form",
    ". The application deadline is 18th of April, 12:00 pm (noon).",
    "Course times and deadlines",
    "General course time: Wed, 12-2 p.m",
    "Introduction Session: April 17, 12-2 p.m. via Zoom",
    "Zoom link: https://tu-berlin.zoom.us/j/63600139054?pwd=RmxRczM2SVJ6Znl3MFFhV2VWSlZyQT09",
    "Milestone 1 Presentations: May 15, 12-2 p.m.",
    "Milestone 2 Presentations: June 19, 12-2 p.m.",
    "Paper and Source Code submission:",
    "July 14, 11:59 p.m.",
    "Final presentation: July 17, 12-2 p.m.",
    "trainers",
    "Dr.-Ing. Andreas Lommatzsch (andreas.lommatzsch@tu-berlin.de)",
    "David Schultz (schultz@tu-berlin.de)",
    "Abdullah Kiwan(abdullah.kiwan@",
    "gt-arc.de",
    ")",
    "Aray Karjauv (Aray.Karjauv@gt-arc.de)",
    "Tolga Akar (",
    "tolga.akar@gt-arc.de",
    ")",
    "Pedram Babakhani (pedram.babakhani@tu-berlin.de)",
    "Nils Breuer (Nils.Breuer@gt-arc.com)",
    "Aktivität Ankündigungen auswählen",
    "Ankündigungen",
    "Forum",
    "Aktivität Diskussionsforum auswählen",
    "Diskussionsforum",
    "Aktivität Nachrichtenforum auswählen",
    "Nachrichtenforum",
    "Aktivität Group Forum auswählen",
    "Group Forum",
    "Aktivität Application Form auswählen",
    "Application Form",
    "Befragung"
]