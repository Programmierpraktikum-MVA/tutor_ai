[
    {
        "Course_Name": "[SS 2024] Bachelor's Thesis Colloquium in Data Management Systems",
        "Course_id": "37500",
        "Forums": [
            [
                {
                    "Forum_name": "Announcements",
                    "Forum_id": "1760952",
                    "Discussions": [
                        {
                            "Discussion_Name": "Meeting Tomorrow, Wednesday, July 10th at 14:00 in EN-719",
                            "Discussion_Id": "606558",
                            "Messages": [
                                {
                                    "Message_id": "p1088006",
                                    "Author": "Juan Soto",
                                    "DateTime": "2024-07-09T11:47:50+02:00",
                                    "Content": "Dear All, Below the presentations scheduled for tomorrow. See you then! -Juan 1. Roman Schmidtke, \"Main Content Extraction from Web Pages\" (Defense, Advisor: Prof. Dr. Stefan Jähnichen) Abstract. In order to equip a chatbot with knowledge so that it can answer questions, information is extracted from websites. Using this information, a chatbot generates answers based on the principle of retrieval augmented generation. This work presents a combination of main content extraction and chunking that improves the retrieval of information. In this method, not only plain text but also the structure, such as the arrangement of the headings of the corpus, is extracted. This is crucial for the chunking approach, where the extracted text is cut based on the structure of the web document. The overlaying headings are attached to each chunk, which improves the context and thus the information retrieval by the bot. The results of the main content extraction were evaluated by comparing this work’s solution with two algorithms, namely BoilerNet and DOM-Distiller. The evaluation showed a better Word Error Rate (WER) on three selected web pages. An average WER of 0.1 was achieved, compared to the second-best average of 0.67 and the least favorable average value of 1.22. 2. Jamy Zhou Hu, \"Classifying Questions into Information-seeking and Non-information Seeking Questions\" (Defense, Advisor: Prof. Dr. Stefan Jähnichen) Abstract. With the increasing importance of chatbots and their frameworks in businesses, the significance of their quality and accuracy grow larger as well. Due to in-built classifiers which need mostly extensive manual training, the performance and usage is very limited. In order for improvement, this paper proposes a multiclass message classifier which will be used in Rasa chatbots, that will label incoming user messages for further processing in the pipeline. The classifier will be trained and tested on the base of the multilingual model of Bidirectional Encoder Representations from Transformers (BERT) from huggingface. 3. Felix Wayß, \"Investigating efficient co-processing in multi-query stream processing\" (Defense, Advisor: Dwi Nugroho) Abstract. Due to the increasing popularity of the Internet of Things (IoT), there are more and more data streams, and with it the need to process them increases. Since the abolition of Dennard scaling, Central Processing Units (CPUs) are unable to keep up with this increasing need for computational power. Therefore, researchers are exploring alternative processors. One such alternative is the Graphics Processing Unit (GPU), which excels in parallel processing. However, leveraging the computing capabilities of the GPU in stream processing presents certain challenges. This thesis investigates how to efficiently employ the GPU in a stream processing system for multiple concurrent queries. This includes the design of a prototype that allows for the efficient execution of multiple concurrent streaming queries, as well as the scheduling or decomposition of these queries to maximize the system’s throughput. To achieve this, we optimize the query execution for each processor individually and take measures to avoid contention between different queries, allowing for efficient concurrent execution. Furthermore, we evaluate the performance for different co-processing approaches (e.g., CPU-only, GPU-only, Fine-grained, Unified Queue and Query Offloading). We conduct a comprehensive analysis of how certain query characteristics and especially the number of concurrent queries impact the system when executing selected NEXMark streaming benchmark queries. We found that for simpler query types, such as map or filter operations, the GPU-based co-processing approaches have a lower throughput than the CPU. However, for certain query configurations using the GPU, especially in a Unified Queue approach can yield a performance improvement over the naive CPU implementation. This improvement was observed both in scenarios involving multiple eager window hash join queries, where the throughput increased by up to 43%, and when these join queries were executed concurrently with simpler queries (e.g., map queries). In this configuration, the throughput was up to 21% higher. Furthermore, the characteristics that benefit the GPU the most, are a low selectivity and a batch size of around 2.5MB. 4. Ogün Isik, \"A Comparative Analysis of State-of-the-Art Federated Query Engines\" (Defense, Advisor: Harry Gavriilidis) Abstract. This thesis proposes a framework to build a benchmark for evaluating the performance of state-of-the-art federated query engines, using the TPC-H benchmark as a standard dataset. The focus is on query engines capable of processing queries across multiple data sources. With the new benchmark, we will have a set of metrics that help us to evaluate the performance of the query engine and make a comparison between execution plans to determine possible bottlenecks and areas of improvement. An interesting aspect of this analysis is uncovering the performance differences among the engines. This involves a detailed comparison of hardware utilization and query plans, providing insights into potential bottlenecks and limitations with certain workloads. The results of this benchmark aim to identify specific factors contributing to performance variations, to show how federated query engines are currently performing compared to others. The engines evaluated include Trino, Presto, Dremio, and Apache Spark. Some FQEs show varying outcomes, with no single engine consistently dominating across all queries, although one engine outperforms the others overall. Some engines failed to complete certain queries, and there were substantial differences in hardware resource utilization.  5. Ludwig Voß, \"Tuning/Using Extended Statistics for Better Cardinality Estimations in PostgreSQL\" (Proposal, Advisor: Stefan Halfpap)",
                                    "Response to": "Response to nothing"
                                }
                            ]
                        },
                        {
                            "Discussion_Name": "Presentations Tomorrow (July 3rd) at 14:00 in EN-719",
                            "Discussion_Id": "605078",
                            "Messages": [
                                {
                                    "Message_id": "p1085910",
                                    "Author": "Juan Soto",
                                    "DateTime": "2024-07-02T17:04:00+02:00",
                                    "Content": "1. Lennart Nissen, \"Community Search on Temporal and Dynamic Graphs\" (Defense, Advisor: Serafeim Papadias) Abstract. Community search has the goal of finding communities in graphs. These communities may only persist for a certain amount of time. This can be represented in a temporal graph which stores the information of when an edge between vertices occurred. One paper that discusses community search on temporal graphs is R. H. Li, et al. on \"Persistent community search in temporal networks\" [13], which we use as foundational work. However, we identified two areas that can be improved. Firstly, the paper notes that the problem is NP-hard. To mitigate the resulting performance issues, we aim to utilise parallelisation to reduce execution times. Secondly, the algorithms presented in the paper assume a static graph. However, as graphs can evolve over time as new data is inserted, communities too can change. To remedy this, we introduce a novel algorithm to dynamically update the foundational model. We also propose an alteration of our dynamic algorithm that increases performance further at a cost of accuracy. Our experiments show that the parallelisation can reduce execution time by over 50%. Additionally, the results show that the dynamic algorithm increases performance by up to 23% with only a few inserted edges. This performance increase diminishes with a larger number of insertions and falls behind the static algorithm at roughly 120,000 edges. On the other hand, the execution time of the alternate dynamic algorithm is only 2% of its competitors, which goes up to 4% at 120,000 inserted edges with a recorded loss in accuracy of less than 2% on average.  2. Yagiz Semercioglu, \"Incremental Community Detection via Label Propagation\" (Defense, Advisor: Serafeim Papadias) Abstract. This thesis addresses the problem of increasing the quality and consistency of the Label propagation algorithm which is utilized for detecting communities in dynamic graphs. LPA suffers from its inherit randomness and the ability to produce low-quality outcomes negatively impacts the accuracy of community detection in complex dynamic graphs. We propose a novel LPA approach that updates the dynamic graph incrementally and incorporates graph theoretical techniques, with a focus on seed selection and graph coloring. The solution involves constructing an oriented graph for the incremental updates and adapting seed nodes detected by the coloring-based seed selection algorithm to boost the accuracy of the initial label assignment. The studies conducted on real graph datasets, such as Facebook and Twitter, demonstrate significant improvements in the quality and consistency of our enhanced Label propagation approach. The enhancements are examined for their effectiveness using quality metrics such as Normalized Mutual Information (NMI) and F1-scores and Modularity. Although our approach has a bigger time complexity due to the OG updates in the pipeline, the base LPA algorithm is outperformed in community detection results and justifies this trade-off. In the conclusion of the thesis potential enhancements such as the parallelization of OG updates and searching for improvements to optimize the adaptation of seed nodes to the LPA algorithm are discussed.  3. Alexander Oelmann, \"Benchmarking of View Selection Methods\" (Defense, Advisor: Adrian Michalke) Abstract. As the amount of data continues to grow rapidly, databases are also getting larger. To ensure high performance when running ad-hoc analysis or applications that utilize these databases, it is crucial to minimize the processing time and processing cost of fetching the data. This is where Materialized Views come in, as they help reduce the query processing time and cost of a query workload. Manually selecting which views to materialize can be a very tedious and time-consuming task, which is why View Selection Algorithms are used to automate this process. There have been numerous proposed approaches to View Selection Algorithms, but they have not undergone a detailed evaluation of important metrics. To make an informed decision about which View Selection Algorithm a database administrator should select for their system, it is necessary to conduct a thorough evaluation of the View Selection Algorithms in terms of various performance metrics and resource constraints. For this reason, we propose a benchmark of View Selection Algorithms, which compares the algorithms by measuring the query processing time, query processing cost, view maintenance cost, and storage cost. We reimplemented two View Selection Algorithms: the Deterministic Multi-View Processing Plan (MVPP) and the Hybrid MVPP, and evaluated their performance using the benchmark. Through this approach, we can make statements on which algorithm is better suited to a specific scenario and how much views selected by View Selection Algorithms can improve the performance. Our assessment indicates that both of the proposed algorithms enhance the performance of the query workload significantly. They reduce query processing time by over 50% and lower query processing costs by over 70%. When comparing both algorithms, our evaluation shows that the hybrid MVPP is better at reducing query processing time and cost. Additionally, both algorithms decrease view maintenance costs by over 70% and reduce storage costs by over 20% when compared to the baseline of materializing all queries in the query workload. In terms of decreasing the view maintenance cost, our experiments show that the deterministic MVPP outperforms the hybrid MVPP, while both algorithms are similar in their storage costs. 4. Moritz Bostelmann, \"Latency and Cost Reduction in IoT Networks: Integrating Network Coordinate Systems into NebulaStream\" (Proposal, Advisor: Xenofon Chatziliadis) 5. Philipp Meran, \"CEP Operator Placement for Unified Fog-Cloud Environments\" (Proposal, Advisor: Arianne Ziehn) See you then, Juan",
                                    "Response to": "Response to nothing"
                                }
                            ]
                        },
                        {
                            "Discussion_Name": "Presentations Today at 14:00 in EN-719",
                            "Discussion_Id": "601971",
                            "Messages": [
                                {
                                    "Message_id": "p1081431",
                                    "Author": "Juan Soto",
                                    "DateTime": "2024-06-19T06:16:04+02:00",
                                    "Content": "1. Felix Lang, \"Continuous Query Execution Under Continuous Infrastructure Evolution\" (Defense, Advisor: Ankit Chaudhary) Abstract. Modern Internet of Things (IoT) applications produce vast amounts of real-time sensory data. Distributed Stream Processing Engines (DSPEs) face the challenge of handling these high-volume data streams while maintaining low latency requirements. Deploying operators to the edge or the fog can reduce data transfer costs and latency compared to processing data exclusively in the cloud. However, the movement of mobile devices in IoT deployments poses a challenge to continuous query execution at the network edge. Mobile devices will repeatedly drop existing network connections and establish new ones, leading to continuous changes in the network infrastructure. These volatile conditions can lead to data loss and query failure as network paths between deployed operators become unavailable. This thesis presents a solution for network-aware adaptation of running queries to continuous infrastructure evolution. Existing approaches are limited to edge-only deployments, rely on deploying operator replicas, or perform only device-local redeployment decisions. We propose a solution to incrementally adapt global operator placements to evolving network topologies. Based on these incremental placement decisions we redeploy operators in a unified edge-fog-cloud environment. Furthermore, we allow proactive operator redeployment based on predicted mobile device movement. We integrate our solution into the NebulaStream (NES) platform. Our evaluations show that the proposed solution improves latency by up to 56x over a naive baseline approach. Furthermore, our solution is able to handle a higher rate of mobile device reconnects compared to the baseline approach. 2. Joris Gabrisch, \"Concept Drift Detection in Business Process Event Streams\" (Defense, Advisor: Ariane Ziehn) Abstract. In Process Mining, Petri-nets are used to model the workflow of activities within business processes in an organization. These processes underlie continuous changes due to the environment in which the organization operates. These changes may lead to variations in the characteristics of the data, so-called concept drifts, which are contained in the logged execution data. Detecting and reacting to these concept drifts in near real-time is crucial for efficient operations and can provide not only process improvement but also cost reduction. Current methods that predict remaining times for still-running process instances assume a general stationary concept in the time perspective of the process to make accurate predictions. Not detected concept drifts in the data can lead to tremendous negative effects on the prediction accuracy from said approaches. In this work, we propose a novel online detection algorithm to detect such drifts in the time perspective of a business process. Our online algorithm extends the method of process histories, a drift detection method developed for the control-flow and data perspective of a business process but incapable of detecting concept drift in the time perspective. In order to extend process histories for concept drift from the time perspective, we introduce a time model that holds distribution estimators to model activity execution times using information from the directly-follows graph of the business process. Additionally, we develop discovery and conformance-checking methods for this specific time model to effectively detect concept drifts in the time perspective. We implemented a proof-of-concept prototype of our online algorithm using pyBeamline as a framework. We evaluate our algorithm using synthetic and real-world datasets using the Google Cloud Run Service for container hosting. Our evaluation shows that our algorithm detects three out of four concept drift types with an average accuracy of 80% within a broader range of parameters. In sum, our work shows that concept drift detection in the time perspective of a business process is conceptually possible and enables organizations to react to those concept drifts in a timely manner.  3. John Nguyen, \"Evaluating relational joins with SIMD instructions in Intel SGX enclaves\" (Proposal, Advisor: Kajetan Maliszewski)  4. Jan Meller, \"Post Query Processing Privacy Quality Assurance\" (Proposal, Advisor: Rudi Poepsel Lemaitre)",
                                    "Response to": "Response to nothing"
                                }
                            ]
                        },
                        {
                            "Discussion_Name": "Meeting Tomorrow, 22nd of May at 14:15",
                            "Discussion_Id": "595724",
                            "Messages": [
                                {
                                    "Message_id": "p1072188",
                                    "Author": "Juan Soto",
                                    "DateTime": "2024-05-21T15:32:27+02:00",
                                    "Content": "Dear All, We will meet tomorrow afternoon at 14:15 in EN-719. Reminder: Students currently working on a thesis with DIMA should be in attendance. Our agenda is as follows: 1. Kareem Rahman, \"Homogeneous Community Detection On Heterogeneous Information Networks: A Node Embedding Approach\" (Defense, Advisor: Papadias) Abstract. This thesis proposes an end-to-end pipeline to tackle the challenge of community detection (CD) on static heterogeneous information networks (HINs) using node embedding (NE) in conjunction with homogeneous modularity-based CD algorithms. It leverages NE techniques (i.e., JUST, Metapath2Vec) to transform an HIN into a weighted homogeneous network by calculating vector similarity distances in the latent low-dimensional embedding space for each node, and then projecting them as edge weights onto a topologically identical homogeneous counterpart of the HIN. A homogeneous modularity-based CD algorithm (i.e., Louvain, Leiden) can then run on the weighted homogeneous graph to identify community structures. This method attempts to both preserve the high-order semantic meaning and topological structure of the original HIN whilst circumventing the necessity for specialized heterogeneous CD algorithms.  Experimental analysis highlights this approach’s efficacy in identifying significant and nuanced community structures across 3 large datasets and 4 pipeline NE-CD variations; nevertheless, there was no best-performing variation overall, underscoring that the success of our pipeline is heavily context-dependent. Despite a computational bottleneck encountered during the NE phase due to the intensive skip-gram model computations, overall runtime of the pipeline remained within practical ranges. This robustness extends to the qualitative analysis of community outputs for a specific music dataset, validating the effectiveness of both JUST and Metapath2Vec in forming coherent communities. This adaptability suggests the pipeline’s capacity to accommodate diverse NE techniques without compromising community integrity or being dependent on metapaths. Importantly, this work demonstrates the feasibility of conducting CD on HINs using well-established homogeneous algorithms, simplifying the approach without the need for specialized heterogeneous algorithms. This thesis’ findings underscore the potential of this framework for real-world applications, opening avenues for future improvements in scalability and hyper-parameter sensitivity across the pipeline. 2. Hanna Riegel, \"Load Estimation in an IoT-based Data Management System\" (Proposal, Advisor: Kozar)  3. Magnus Kroner Mat, \"Using Metamorphic Testing to Find Logic Bugs in Stream Processing Engines (Proposal, Advisor: Chaudhary)  See you then, Juan",
                                    "Response to": "Response to nothing"
                                }
                            ]
                        }
                    ]
                }
            ]
        ]
    }
]