[{"lecture": "25797_62_course_video", "Timestamps": [{"text": "  In diesem Video moechte ich euch einen groben Ueberblick ueber das Thema Machine Learning geben, speziell im Kontext von den Methoden, die wir uns anschauen.  Genau, als wir ganz grob kommen, das Ganze unterscheiden und zapperscheiden und anzapperscheiden und zapperscheiden, dann kann man wiederum unterscheiden und Klassifizierung und Regierungsprobleme.", "start": 0.0, "end": 37.0}, {"text": "  Wir werden jetzt im Folgen ganz grob ueber diese Begriffe uebergehen. Wie gesagt, das ist nur ein grober Ueberblick und man kann jetzt endlich noch sehr viel mehr und intensiver mit den Themen beschaeftigen, als dass wir das in dem Video jetzt hier abdecken koennen und wollen.", "start": 38.0, "end": 47.0}, {"text": "  Beim Zapperscheid Learning geht es eigentlich darum, dass man Daten gegeben hat, zum Beispiel Bilder oder Messdaten von irgendwelchen Densoren.  Was sie den Datenpunten moechte, moechte man jetzt label hervorher sagen. Man hat einen Datenpunkt und man moechte jetzt den Datenpunten label zuweiden.", "start": 48.0, "end": 65.0}, {"text": "  Am Anfang hat man Daten mit bekannten Labels gegeben. Die kann man dann nutzen, Modellen zu entwickeln und zu trainieren.  Daher kommt auch Begriff ueberwachtes Lernen, wenn man waehrend des Trainings von dem Modell direkt ueberpruefen kann, ob die schon vorher gesattten Modelle mit den korretten Labels uebereinstimmen.", "start": 66.0, "end": 86.0}, {"text": "  Was genau diese Labels sind, wird jetzt noch ein bisschen klarer, wenn man die Unterteilung in Klassifizierungs- und Regierungsprobleme vornimmt.  Wir fangen an mit den Klassifizierungsproblemen. Da sagt man, dass die Labels diskrep, qualitativ sind.  Das heisst, man kann zum Beispiel dann ein Bild des Labelhund oder Katze zuweiden, abhaengig davon, welches Tier auf dem Bild zu sehen ist.", "start": 87.0, "end": 108.0}, {"text": "  In der Regel gibt es Algorithmen, die nicht direkt Hund oder Katze aussehen.  Wir arbeiten wie immer am Computer mit Praesentationen von Zahlen in Bits und Bytes.  Der Algorithmus wuerde dann zum Beispiel das Eingabe ein Bild bekommen, wuerde dann ein oder minus eins ausgeben, abhaengig davon, ob ein Hund oder eine Katze zu sehen ist.", "start": 109.0, "end": 141.0}, {"text": "  Man kann noch weitere Labels mit hinzunehmen, das ist kein Problem. Man koennte zum Beispiel auch allgemein sagen, man moechte Objekte erkennen auf Bildern und dann kann man noch durch Klassen definieren wie Lampe, Schiff, Haus, Tisch usw.  Das liegt komplett an der Aufgabe, die man loesen moechte.", "start": 142.0, "end": 162.0}, {"text": "  Ich habe hier ein paar einfache Algorithmen aufgelistet, die die Klassifizierung loesen koennen, zum Beispiel der Caneus-Nebel Algorithmus, mit dem wir uns speziell in dem Video noch etwas mehr beschaeftigen, weil wir den benutzen, um die Gesichtserkennung zu loesen.", "start": 162.0, "end": 172.0}, {"text": "  Hier gibt es die Fischerslinierte Spimmendenanalysis, das ist ein etwas aeterer Algorithmus, der aber schon etwas fortgeschritten und komplizierter ist.  Ein Algorithmus oder eine Methode, die sich von der Anseher alle schon mal etwas gehoert haben, sind die Neuroneinnetze.", "start": 173.0, "end": 188.0}, {"text": "  Den kann man auch ohne Weiteres zum Beispiel das Eingabe ein Bild geben und dann als Ausgabe zum Beispiel eben so ein Label fuer Hund oder Katze erwarten.  Ein wichtiger Bestandteil von den Trainingsalgorithmen zu Neuroneinnetzen ist das Stochastik-Gradient-Descent, also der gradienten Abstieg.", "start": 189.0, "end": 204.0}, {"text": "  Mit dem werden wir uns auch nochmal einen Rahmen fuer einen wissenschaftlichen Rechnung auseinandersetzen, dann im letzten Themenblock, wenn es um die Optimierung geht.  In der Regission haben wir hier kontinuierliche Label, das heisst ein Label koennte zum Beispiel alle Werte zwischen 100 und 200 von den Drehentzahlen annehmen.", "start": 205.0, "end": 230.0}, {"text": "  Bei der Klassifizierung haben wir ja wirklich einzelne festgesetzte Klassen, also in der Regel auch endlich viele Klassen, also Hund, Katze, Maus, Giraffe, was auch immer.  Und hier koennen wir aber wirklich alle Werte annehmen, also alle Werte zwischen 100 und 200.", "start": 230.0, "end": 246.0}, {"text": "  Das Beispiel koennte man als Eingabe zum Beispiel Sensordaten nehmen, Sensordaten von zum Beispiel welchen Wetterparameter, also Luftfreuchtigkeit.  Man koennte auch als Eingabe nehmen, wie bewirkt es ist, wie lange die Sonne am Tag scheint und so weiter und so fort, aus welchen Winke die Sonne scheint.", "start": 247.0, "end": 261.0}, {"text": "  Moechtet ihr dann daraus, den Parameter, um probieren, die Temperatur hervorzu sagen, vorherzu sagen.  Temperatur kann ja alle Werte zwischen, dann haben wir meinen unabbreiten Grad zwischen minus 20 und 45 Grad annehmen.  Und dann wollen wir also ein kontinuierliches Label finden, was genau die Temperatur entspricht.", "start": 262.0, "end": 283.0}, {"text": "  Genau, eine Methode, die auch zu der Regission zaehlt, habt ihr bereits kennengelernt und zwar die einfache linere Regition.  Da habt ihr durch eine Punktewolke eine Grade gelegt und das habt ihr geloest durch die Ausgleichsrechnung.  Also ihr habt eine gradengleichung euch angeschaut, MX plus N.", "start": 284.0, "end": 303.0}, {"text": "  Dann habt ihr gesagt, okay, wir haben jetzt ein ueberbestimmtes Gleichungssystem, wir wollen die gerade finden, die quasi all diesen Punkten moeglichst nah kommt.  Also moeglichst geringen Abstand zu einem Punkten hat, aber nicht den moeglichst geringen Abstand zu einem Punkten hat, aber die eben diese Punkteverteilung moeglichst gut beschreibt.  Und das haben wir geloest durch Ausgleichsrechnung.", "start": 303.0, "end": 322.0}, {"text": "  Das ist im wenigen auch ein Regisseilsproblem.  Also die Eingabe ist halt an X, also IDX-Werte von den Punkten.  Und die Ausgabe sind dann die zugehoerigen Y-Werte von den Punkten, jetzt im 2 Dimensionale.  Und eine Modell hier ist gerade eine Gartengleichung, die wir finden wollen.  In dieser Gartengleichung kann man dann einen X und ein Y geben.", "start": 323.0, "end": 354.0}, {"text": "  Dann kriegen wir einen beliebigen, kontinuierlichen Y-Wert raus, der dann eben beschreibt, wo genau auf der entlang der Y-Achse dieser Punkt liegen muss fuer ein gegebenes X.  Neuronale Netze hat sich eben schon mal angesprochen, die kann man auch verwenden, um Regisseilsproblemen zu loesen.", "start": 354.0, "end": 369.0}, {"text": "  Dann moechte ich kommen zu den zweiten grossen Teilen, in denen man quasi Maschinenlernung unterscheiden kann.  Und das waere das Ansaberweislernung, also das nicht ueberwachte lernen.  Hier hat man eben keine korrektere Ausgabe gegeben, als man kann jetzt nicht ueberwachen und sagen, okay, die Methode funktioniert jetzt schon korrekt oder nicht.", "start": 370.0, "end": 391.0}, {"text": "  Stattdessen moechte man, also was die Idee hinter uns hat bei Wise Learning ist, dass man Strukturen in den Daten filmen moechte.  Das heisst, man hat nur die Daten gegeben und jetzt sucht man eben Zusammenhaenge in diesen Daten oder Strategien, wie man die Daten unterteilen kann und so weiter.", "start": 392.0, "end": 409.0}, {"text": "  Ein klassisches Beispiel waere zum Beispiel die Hop-Komponenten-Analyse, mit der wir uns aktuell beschaeftigen.  Dann gibt es zum Beispiel auch die Independent-Komponenten-Analysis, wo man also statistisch unabhaengige Variabeln sucht, die Daten beschreiben.", "start": 409.0, "end": 428.0}, {"text": "  Dann gibt es das Clustering, das kennt je wahrscheinlich schon, zum Beispiel aus der Modul-Formationssysteme und Datenanalyse, da war das definitiv Inhalt.  Bei den Clustering, zum Beispiel in den K-Means Algorithmus, moechte man verschiedene Gruppen oder lokale Gruppen von Datenpunkten finden, also die Punkte zu Clustern zusammenfassen.", "start": 429.0, "end": 456.0}, {"text": "  Da gibt es auch dann noch weitere Algorithmen, die quasi K-Means erweitern und aehnlich funktionieren, zum Beispiel den Expectation-Maximisation-Algorithmus.  Auch hier gibt es noch viele weitere Methoden, die man unter Anthropowice-Learning verstehen kann.  Dann habe ich hier ein Link zu einer Modul von der Stanford-Universitaet verlinkt.", "start": 456.0, "end": 480.0}, {"text": "  Das Material koennt ihr euch gerne anschauen, wenn euch das Thema Machine Learning allgemein interessiert.  Ich habe ganz am Anfang angefangen, mir Sachen oder die Inhalte auf dieser Seite durchzulesen.  Wir wollen jetzt ganz kurz an den Anfang von den Kurs reinschauen auf den Link.", "start": 481.0, "end": 506.0}, {"text": "  Was hier noch mal relativ gut ein Ueberblick ist zu dem Thema Klassifizierung und speziell zu dem Thema K-Nivis Neighbor, das uns sehr interessiert fuer eine Gesichtserkennung.  Hier ist noch eine kurze Grafik, einen Text, kann euch in Ruhe durchleden.  Ich moechte ein paar Worte zu den Grafiken sagen.", "start": 506.0, "end": 522.0}, {"text": "  Wir haben hier dieses Bild fuer eine Katze und das Klassifizierungsproblem ist, dass wir diese Katze jetzt an Label zuweisen wollen.  Es ist der Computer, sie steht jetzt endlich an den Stoffen im Bild, nur eine Menge von Zahlen.", "start": 523.0, "end": 539.0}, {"text": "  Wir wollen jetzt in eine Funktion approximieren oder eine Funktion finden, die approximativ diese Menge an Zahlen, geordnete Menge an Zahlen, neben den Labelkatzen zuordnen.  In aller Regel beim Thema Machine Learning hat man keine eindeutige Ausgabe, die also konkret sagt, das ist eine Katze, sondern man bekommt zum Beispiel eine Wahrscheinlichkeitsverteilung zurueck.", "start": 540.0, "end": 560.0}, {"text": "  Hier waere die Wahrscheinlichkeitsverteilung, dass wir zu 82% Wahrscheinlichkeit in der Katze sehen, 15% Wahrscheinlichkeit ein Hund usw.  Aber wir koennen halt annehmen, die hoechste Wahrscheinlichkeit mit Abstand ist nicht schlecht fuer Katze, also wahrscheinlich sehen wir hier tatsaechlich eine Katze.", "start": 561.0, "end": 586.0}, {"text": "  Genau, jetzt hier haben wir nochmal einen Ueberblick, das sind zum Beispiel die Trainingsbilder, das heisst hier, das sind all die Bilder, die wir schon fuer Katze kennen, all die Bilder, die wir fuer Hunde kennen, all die Bilder, die wir fuer Kaffee kennen kennen und all die Bilder, die wir fuer Kopfbedeckung kennen.", "start": 587.0, "end": 606.0}, {"text": "  Und wenn wir jetzt zum Beispiel ein neues Bild haben und das jetzt einer dieser 4 Klassen zuordnen wurden, dann waere die trivialste oder simpleste Idee, die man haben kann, dass man einfach schaut, okay, welche dieser 4 Klassen kommt, dieses Bild am ehemaligen Nisten.  Und das ist genau das, was Niveau-Snebel macht.", "start": 607.0, "end": 629.0}, {"text": "  Als wir nehmen diese Werte von den Bildern, also jetzt entdecken hinter den Bildern, denn nur ein Haufen des Kreator-Wertren, die vergleichen wir und dann weisen wir abhaengig von den Vergleichswert, dann im Bild die Klasse zu, die halt deren Bilder, die den Objektor der Maehnliste sind.", "start": 630.0, "end": 645.0}, {"text": "  Also wenn wir ein Bild haben, als zum Beispiel hier, den Bild von dem Husky, der sehr aehnlich ist, dann wuerden wir sagen, okay, wahrscheinlich ist das ein Hund, weil dieses Bild von dem Husky eben auch zu der Klasse Hund gehoert.  Ja, hier ist jetzt eine einfache Methode, wie wir wieder vergleichen koennen.", "start": 646.0, "end": 659.0}, {"text": "  Da ist jetzt Jonas schon darauf eingegangen, soweit ich weiss, in den Videos vergleichen einfach die Bilder.  Nehmen wir zum Beispiel Element, also eine einfache Variante wert, das ist einfach elementweise, die einzelnen Pixel-Werte vergleichen und dann ueber alle Pixel-Werte aufzumieren und dann kriegen wir einen Wert, der quasi da wie aehnlich die E-Bedder sind.", "start": 660.0, "end": 685.0}, {"text": "  Wenn die Differenz halt sehr klein ist, dann koennen wir davon ausgehen, dass die Bilder sehr aehnlich sind, wenn die Differenz sehr gross ist, dann koennen wir davon ausgehen, dass die Bilder sehr unterschiedlich sind.  Und dann weisen wir halt eben die Klasse von dem Bild zu, was hier im Vergleichsoperator den geringsten Wert erzaehlt.", "start": 686.0, "end": 700.0}, {"text": "  Darauf gehe ich auch gleich nochmal speziell bei der Gesichtsklassifizierung und Gesichtserkennung ein.  Und da kann man das wahrscheinlich nochmal ein bisschen genauer erkennen, was hier passiert.  In dem Fall war das jetzt ja einfach eine Einstnorm, also fuer vergleichen wirklich Direkt Pixel fuer Pixel.", "start": 701.0, "end": 724.0}, {"text": "  Genauso kann man auch die A2 Norm betrachten, wo man dann quasi nochmal die einzelnen Differenzen, die einzelnen Pixel quadriert und dann am Ende die Wurzel zieht.  Das entspricht also quasi genau der Vektornorm, die wir auch kennen.", "start": 725.0, "end": 744.0}, {"text": " Was genau macht das Erkennung des Neighbor-Klassifahres?  Also die Idee ist quasi, dass wir elementweise die Pixel vergleichen bzw. einfach uns die Norm anschauen, also den Abstand zwischen zwei Punkten.  Und jetzt endlich haben wir dann den Punkt der Klasse zu, die am naechsten liegt.", "start": 745.0, "end": 759.0}, {"text": "  Wenn wir jetzt zum Beispiel hier, wo mein Kurs gerade ist, einen neuen Punkt haben und den jetzt klassifizieren wollen, dann schauen wir, was ist der naechste Punkt um den Punkt herum.  Und dann sehen wir, okay, das waere der blaue Punkt, also muss dieser Punkt hier wahrscheinlich auch zu den blauen Punkten gehoeren.", "start": 760.0, "end": 771.0}, {"text": "  Wenn wir hier liegen wuerden, dann waere der naechste Punkt ein gruener Punkt, also wuerden wir wahrscheinlich zu den gruenen Punkten gehoeren.  Hier in dem Bild hat man einmal die Grenzen abgezeichnet, welche Bereiche dann quasi zu welcher Farbe zugeordnet werden wuerden.", "start": 772.0, "end": 798.0}, {"text": "  Und dann sieht man hier relativ interessant, hier im dritten ist ein gruener Punkt, das heisst, der Bereich hier, bitten in den blauen Bereich, eigentlich, der wuerde jetzt den gruenen Punkt zugeordnet werden, wo hier der gruener Punkt hertern ist, obwohl das vielleicht ein Ausreisser ist von allgemein den gruenen Punkten.", "start": 798.0, "end": 808.0}, {"text": "  Bei den K-Nevis-Neber-Klassifier kann man erweitern, also hier, dass das einfach nur eine Nevis-Neber-Suche, dass auch das das hier mit den Gesichtsbuedern machen.  Dann aber auch, halt sagen, wir machen einen 5-Nevis-Neber-Church, da ist, wir gucken uns die 5 naechsten Punkte an und lassen dann die 5 naechsten Punkte darueber abstimmen, welcher Farbe der Punkt wird angehoert.", "start": 809.0, "end": 834.0}, {"text": "  Und dann sehen wir jetzt hier zum Beispiel, dass dieser gruene Punkt am Ende von dem blauen Punkt, sehr bereich hier drum herum, trotzdem nicht mehr als unklassifiziert wird, sondern jetzt auch das blaue.  Das sieht daran, dass fuer die Punkte hier in dieser Naehe wir uns jetzt die 5 naechsten Nachbarn anschauen und das waere zum Beispiel dieser eine gruene Punkt und 4 weitere blaue Punkte.", "start": 835.0, "end": 856.0}, {"text": "  Aber die 4 blauen Punkte ueberwiegen dann, das heisst, da die 4 blauen Punkte ueberwiegen, wuerden wir trotzdem die blaue Klasse zuweisen.  Das kann unter Umstaenden halt zu Fs-regelmaessigeren Klassifizierungsergebnissen fuehren, also wir vermeiden dann halt diese Ausreissung.  Wir haben von der Bildersuche, wollen uns jetzt aber erstmal auf die einfachen Nervoesnaebersuche beschraenken.", "start": 857.0, "end": 876.0}, {"text": "  Damit machen wir jetzt gleich weiter.  Und ein Gesichtserkennung faellt quasi klassisch unter dem Bereich SAPA-Reislerne.  Wir sagen einfach jedes Individuum, also jeder Mensch entspricht einer Klasse und wir weiden jetzt ein neues Bild bekommen, ein unbekanntes Bild von einem Menschen.", "start": 877.0, "end": 901.0}, {"text": "  Dann weisen wir die Menschen, dann haben wir das ist der Mensch, dessen Bilder diesen einen Bild jetzt am ehemaligen sind.  Das heisst, wir vergleichen jetzt endlich alle Bilder, die wir haben in unser Darbenbank und picken uns dann das naechste, das ehemalige Bild raus und dann sagen wir, okay, das muss in etwa der gleichen Mensch sein.", "start": 902.0, "end": 926.0}, {"text": "  Die bekannten Bilder habe ich hier bezeichnet, als i fuer Image von 1 bis k, das heisst wir haben k Bilder und die haben jetzt hier in dem Fall Enddimension.  Also Sie wissen ja, wir koennen Bilder auch einfach als Fektoren schreiben und das haben wir hier getan, dann haben wir Endeintraege.  Dann haben wir ein gesuchtes BDX, wir weisen jetzt das Bild mit den kleinsten Abstand zu.", "start": 927.0, "end": 947.0}, {"text": "  Das heisst, wir suchen den Index i von den K-Bildern, die wir haben, sodass x-i in der Norm moeglichst klein wird.  Also das ist ja genau der Abstand zwischen den beiden Bildern, also wie aehnlich die beiden Bilder sind, davon nehmen wir die Normen.", "start": 948.0, "end": 964.0}, {"text": "  Das heisst, wir messen hier quasi die Aehnlichkeit von den Bildern mit der E2 Norm und wir koennen auch einfach das Quadrat von dieser Norm nehmen, also die aeussere Wurzel von der Norm quasi weglassen,  weil die Quadratische Funktion ist monotom wachsen, genauso ist auch die Wurzelfunktion monotom wachsen.", "start": 964.0, "end": 977.0}, {"text": "  Da ist man keinen Unterschied, ob wir jetzt hier von der Wurzel das Minimum suchen oder einfach heben von den Quadrat.  Und ja, schlussendlich, was wir eigentlich machen, ist halt ueber die einzelnen Eintraege iterieren von diesen Bildern und dann die Differenz nehmen, die Quadrieren und ausdomieren,  das ist ja genau die Definition von der Norm, wir suchen halt das Minimum.", "start": 979.0, "end": 1008.0}, {"text": "  Um dieses Minimum zu finden, muessen wir bei K-Bildern, also bei 100 Bildern, ja ueber 100 Bilder miteinander vergleichen, also wir muessen 100 Bilder miteinander hier vergleichen.  Und fuer jedes Bild, muessen wir bei 108.000 x 128 Pixeln und insgesamt ueber 16.000 Pixeln, muessen wir insgesamt mAk, also ueber 1,5 Millionen mal diese Pixel vergleichen und das Quadrat hier ausrechnen.", "start": 1009.0, "end": 1040.0}, {"text": "  Und das ist natuerlich eine ungeheure Anzahl, dafuer, dass wir eigentlich mit 128 Pixeln relativ kleine Bilder haben und auch nur insgesamt 100 Bilder haben.  Das heisst, bei typischen Datenbanken in dem Bereich Maschinenlearning hat man weit aus mehr Bilder und man hat unter Umstaenden auch groessere Bilder, dann wuerde der Aufwand hier um quasi all diese Normen auszurechnen, explodieren.", "start": 1041.0, "end": 1060.0}, {"text": "  Es stellt sich die Frage, wie wir das loesen koennen und da gibt es zwei verschiedene Ansaetze, die mir jetzt konkret einfallen.", "start": 1061.0, "end": 1080.0}, {"text": " Einer waere zum Beispiel, dass man eine geometrische Datenstruktur aufbaut, in der man dann nicht mehr jedes Bild vergleichen muss, also nicht mehr alle 100 Bilder vergleichen muss, sondern man baut sich quasi so eine Art Suchbaum,  dann muss man zum Beispiel nur noch 50 mal hier vergleichen, weil insgesamt eigentlich 100 Bilder.", "start": 1081.0, "end": 1091.0}, {"text": "  Genau, das ist auch im Bereich der Computergrafik, zum Beispiel relativ ueblich, der Verwendet man diese geometrische Datenstrukturen auf, wenn man schnell sehr aehnliche Punkte finden muss in einen dreidimensionalen Raum.  Damit wollen wir uns jetzt hier aber nicht beschaeftigen, wir beschaeftigen uns quasi mit einer anderen Loesungsmoeglichkeit und die finden wir eben in der Hauptkomponentenanalyse.", "start": 1092.0, "end": 1112.0}, {"text": "  Die Hauptkomponentenanalyse ist ein klassisches Beispiel fuer Anzupper-Wise-Learning und dieses Anzupper-Wise-Learning bedeutet ja, dass wir eine Struktur in den Daten finden wollen.  Und jetzt endlich werden wir die Struktur ausnutzen und dann unsere Klassifizierung effizienter zu machen.  Da wissen wir ja, dass wir gewisse Regemaessigkeiten in natuerlichen Gesichtsbildern haben.", "start": 1113.0, "end": 1131.0}, {"text": "  Also, die sind ja nicht voellig zufaellig und einfach gar rauschen, dann gibt es bestimmte Regemaessigkeiten.  Natuerlich, die Bilder haben immer eine gewisse Struktur, und es reicht, wenn wir nur Gesichtsbilder betrachten, dann ist die Struktur sogar noch eingeschraenkt.", "start": 1132.0, "end": 1152.0}, {"text": "  Und jetzt koennen wir halt sagen, da wir diese Struktur haben, wissen wir, wir koennen die Gesichtsbilder mit weniger Parameter, als mit all diesen Pixelmen beschreiben.  Naemlich mit den Parametern, die wir brauchen, um mit den Hauptkomponenten eine Linearkombination zu finden, die den Bild moeglichst leicht kommt.", "start": 1153.0, "end": 1172.0}, {"text": "  Heisst, wir koennen den Gesichtsbilder einfach mit den Gewichten der Hauptkomponenten mit hoechster Variant, sondern in den signifikantesten Hauptkomponenten beschreiben.  Und wenn wir jetzt die Bilder nur noch bezueglich dieser Parameter betrachten, dann koennen wir auch nur noch diese Parameter betrachten, vergleichen.  Also, das ist das, was wir hier quasi machen wollen.", "start": 1173.0, "end": 1189.0}, {"text": "  Wir nehmen unsere Menge an Bildern, i1 bis ik, und wir davon die Hauptkomponenten bestimmen.  Das ist quasi also dieser Ansperrweis-Learning-Schritt.  Dann bekommen wir hier die reduzierten Bilder nur noch dargestellt anhand der Hauptkomponenten, i1 bis ik, und da sagen wir halt, okay, hier haben wir unter Umstaenden nur noch p Parameter, anstatt von n Parameter.", "start": 1189.0, "end": 1213.0}, {"text": "  Und dadurch koennen wir jetzt hier den Vergleicheffizienten gestalten.  Damit wir vergleichen koennen, muessen wir natuerlich auch in der Gesucht des Bild-X in die bezuegliche Hauptkomponenten von den Bildern ausdruecken, als auch x.  Fuer x nehmen wir den Dimensionsreduktionsvor, dass wir hier dieselben Dimensionen haben.", "start": 1214.0, "end": 1240.0}, {"text": "  Jetzt koennen wir die Normen nicht ausrechnen, dann muessen wir halt unter Umstaenden nur noch p Mak\u00b2 anstatt von m Mak\u00b2 ausrechnen.  Heutzutage wuerde man auch die Gesichtserkennung nicht mehr mit den klassischen Caneal vs. Neighbor-Eigurypnuss in der Dimensionen-Reduktion durchfuehren.  Stattdessen koennte man modernere Methoden verwenden.", "start": 1244.0, "end": 1260.0}, {"text": "  Eine andere Variante, die noch mal vorgestanden wurde, sind die Fischer-Faces.  Es hat also gewisse Aehnlichkeiten zu der Fischer-Linear-Diskriminantenanalyse, die wir eigentlich benutzen wuerden zur Klassifizierung.", "start": 1261.0, "end": 1278.0}, {"text": "  Damit kann man aber auch eine gewisse Art von Dimensionsreduktionen durchfuehren, die unter Umstaenden sogar besser funktionieren kann als die Variante, die wir uns jetzt hier anschauen.  Das wollen wir uns aber nicht weiter beschaeftigen.  Wahrscheinlich die modernste Methode waere, dass man direkt Konvolution in den Narbon Networks verwenden wuerde, um direkt die Kassifizierung zu lernen.", "start": 1279.0, "end": 1295.0}, {"text": "  Konvolution in den Narbon Networks lernen selber Faltungsfilter.  Mit Faltungen werden wir uns im naechsten Teamlock an den Rahmen von der Fourier-Transformation beschaeftigen.  Diese Filter nehmen jetzt endlich auch eine Art Dimensionsreduktions vor, die aber gelernt ist und speziell fuer die Daten angepasst wird.  Das war es so weit zum Thema Machine Learning.", "start": 1296.0, "end": 1317.0}, {"text": "  Das war wie gesagt ein kleiner Ausblick.  Ich finde das relativ interessant, dass die Methoden, die wir hier anwenden, ganz klare Parallelen haben oder eigentlich schon zum Machine Learning mitgezaehlt werden koennen.", "start": 1317.0, "end": 1327.0}]}]