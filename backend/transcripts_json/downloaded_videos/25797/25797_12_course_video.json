[{"lecture": "25797_12_course_video", "Timestamps": [{"text": "  Zusaetzlich zu dem Video ist Frank Gabriel, moechte ich in diesem Video noch mal zwei geometrische Interpretationen zeigen,  und zwar einmal zu der Definitilvermatrizen und dann nochmal gemeinsam ausgleichen.  Fangen an mit der Definitilvermatrizen und dazu schauen wir uns diese metrische Matrix A an.", "start": 0.0, "end": 25.0}, {"text": " Weil A symmetrisches muss A auch quadratisch sein und dann schreiben wir halt,  dass es eine MMM-Matrix aus den Rehenzahlen sein soll.  Und diese Matrix A heisst das Positiv Definit, wenn fuer alle Vektoren X aus dem R hoch N,  ausser dem Null-Vektor, gilt, dass X Transponiert mal AX groesser als Null ist.", "start": 25.0, "end": 43.0}, {"text": "  Wir wollen uns speziell in dem Video halt anschauen, was dieses X Transponiert mal AX groesser als Null geometrisch bedeutet.  Das ist echt equivalent dazu, dass wir sie schreiben koennen oder sagen koennen, dass alle Eigenwerte groesser als Null sind.  Und da A halt eine symmetrische Matrix ist, wissen wir, dass es N, Rehelle, Eigenvektoren und Eigenwerte geben muss.", "start": 43.0, "end": 66.0}, {"text": "  Dann kann man halt sagen, hier alle diese N Eigenwerte sollen groesser als Null sein, dann ist A Positiv Definit.  Die positive Semi-Definitheit erlaubt das jetzt zu sagen, OK, X Transponiert mal AX ist groesser als Null.  Also da erlauben wir halt, dass wir auch genau Null haben.  Also nicht stritt groesser als Null, auch groesser als Null, analog halt bei dem Eigenwert groesser als Null.", "start": 66.0, "end": 91.0}, {"text": "  Und genau analog zu den ersten beiden Faellen koennen wir dann halt von Negativer Definit, bzw. den Negativer Semi-Definit sprechen,  weil kleiner oder kleiner gleich als Null sind, sonst also wenn die Eigenwerte kleiner oder kleiner gleich als Null sind.", "start": 91.0, "end": 110.0}, {"text": " Wenn keiner dieser oberen Faelle zutrifft, oder in anderen Worten, wenn es einen X in den Y aus dem R hoch N,  verschieden von dem Null-Vektor gibt, so dass X Transponiert AX groesser als Null ist,  und Y Transponiert mal A, Y kleiner als Null ist,  und wenn wir halt mal groesser, mal kleiner als Null sind, dann muss A halt oder dann nehmen wir A in Definit.", "start": 110.0, "end": 124.0}, {"text": "  Genau, hier koennen wir auch erlauben, dass groesser gleich ist.  Analog dazu halt wieder fuer die Eigenwerte, wenn ein Eigenwert groesser Null ist und ein Eigenwert kleiner als Null ist, dann ist A halt in Definit.  An der Stelle moechte ich noch einmal ganz kurz den Unterschied zwischen Positiver Definit und Positiver Semi-Definit hervorheben.", "start": 125.0, "end": 145.0}, {"text": "  Semi-Definit erlauben wir auch, dass ein Eigenwert genau gleich Null ist.  Bei der genauen Positiven Definit fordern wir, dass sie immer groesser Null sind, hier kann es auch passieren,  dass ein Eigenwert gleich Null ist.", "start": 145.0, "end": 173.0}, {"text": " Und wenn das auftritt, dann gibt es einen zugehoerigen Eigenvektor V,  so dass A mal V, der genauer Lambda mal V sein muss, nach Definitionen der Eigenwerte und Eigenvektor,  das ist ja genau Null mal V, weil dieser Eigenwert der Eigenwert ja Null sein soll, also haben wir hier den Null-Vektor,  das bedeutet, dass V mal A auf Null abbildet, V also in dem Kern von A liegt.", "start": 173.0, "end": 192.0}, {"text": "  Versteht mal, V ist Element, von V ist Element von dem Kern von A  und wir wissen wieder aus der Linie an Algebra, dass wenn der Kern von A nicht leer ist, also wenn der Vektor enthaelt,  dann muss der Rang von A kleiner als N sein, also A hat dann keinen vollen Rang.  Das hier darum bedeutet, dass sich ein Gleichungssystem A x gleich B nicht unbedingt eindeutig loesen laesst.", "start": 192.0, "end": 224.0}, {"text": "  Genau, weil es gibt halt Vektoren x, die auf den Null-Vektor abbilden, also A ist quasi eine singulaere Matex  und die hat dann dadurch dieses Gleichungssystem mit einem allgemeinen Kern der Loesung  und das ist ganz interessant im Hinterkopf zu erhalten, wenn wir ueber die Cholesky-Zerlegung nachdenken.", "start": 224.0, "end": 242.0}, {"text": "  Cholesky-Zerlegung, wenn wir ja A zerlegen in einer unteren, eine obere Dreiecksmatrix, A wird uns also L transponiert,  mit der koennen wir dann unser Gleichungssystem halt unter Umstaenden schneller oder schnell fuer verschiedene B loesen  und genau, da haben wir gesagt, okay, das funktioniert halt immer dann, wenn die Matrix positiv definit und symmetrisch ist", "start": 242.0, "end": 268.0}, {"text": " und wenn die Matrix das positiv semi-definit ist, also wenn wir zum Beispiel halt auch eine Eigenwert gleich Null haben,  dann macht das ja eigentlich sowieso nicht mehr so viel Sinn, weil wir wollen diese Cholesky-Zerlegung benutzen  und ein Gleichungssystem eindeutig zu loesen am Ende und wenn wir jetzt am Ende ein Eigenwert gleich Null haben,", "start": 268.0, "end": 287.0}, {"text": " dann wissen wir halt, dass wir in der Gleichungssystem ohnehin gar nicht richtig loesen koennen,  so wie wir es gerne wollten mit einer eindeutigen Loesung.  Also in dem Fall ist die Cholesky-Zerlegung wahrscheinlich sowieso nicht sehr hilfreich.", "start": 287.0, "end": 308.0}, {"text": " Jetzt wollen wir uns, wie gesagt, einmal speziell anschauen, was fuer diese Term X transponiert mal AX, geometrisch bedeutet,  dafuer wechsle ich mal auf eine neue Seite und als kurze Wiederholung,  wir haben ja das Galaprodukt nochmal uns angeschaut, der Lina-Wiederholung U mal V, Galaprodukt von U mal V", "start": 308.0, "end": 321.0}, {"text": " und das haben wir auch geschrieben oder haben gesehen, dass er das auch schreiben kann, also U transponiert mal V.", "start": 322.0, "end": 345.0}, {"text": " Und ein Beispiel haben wir halt 2-dimensionale Vektoraum, welche U, Ups, ein Vektor,  dann kann die Norte und Ursprung aus, wir haben U, haben V und dazwischen gibt es noch ein Winkel  und dann haben wir halt auch gesagt, okay, geometrisch bedeutet, dass gerade sie jetzt einfach Cosinus  von dem Winkel zwischen den beiden Vektoren mal die Laenge von den beiden Vektoren.", "start": 345.0, "end": 357.0}, {"text": "  Galaprodukt, genau der Cosinus von dem Winkel zwischen den beiden Vektoren mal die beiden Laenge  und wenn wir das jetzt mal anschauen, dann wissen wir auf jeden Fall, dass Laengen immer U ist ja gleich 0  und das wird gleich interessant sein, weil wenn wir das X transponiert mal AX, hier mal hinschreiben,  dann sehen wir, dass es irgendwie gewisse Aehnlichkeiten hat zu den U transponiert mal V,", "start": 357.0, "end": 379.0}, {"text": " weil es ja eigentlich nur ein Skalaprodukt ist.  Das A mal X ist wieder ein Vektor und X transponiert ist ein Vektor.  Aner Worten oder eindeutig aufgeschrieben, haben wir einfach nur das Skalaprodukt zwischen X und X abgebildet durch A.  Das ist nichts anderes als ein Skalaprodukt zwischen dem Vektor X und dem Vektor X, nachdem er abgebildet wurde auf A.", "start": 379.0, "end": 408.0}, {"text": "  Und hier kennen wir halt eine geometrische Veranschaulichung, das entspricht den Cosinus in dem Winkel  zwischen dem Vektor X und A mal X mal die Laenge von dem Vektor.  Und bei der positiven Definitheit fordern wir jetzt, dass das Ganze groesser als 0 sein soll.  Und jetzt schauen wir uns das Ganze mal an.  Wir wissen wie gesagt, dass diese Laengen auf jeden Fall groesser als 0 sind.", "start": 408.0, "end": 438.0}, {"text": "  Wenn X, also X soll bei der positiven Definitheit sowieso nie der 0-Vektor sein,  kann jetzt aber passieren, dass A halt nur positiv semi-definit ist.  In dem Fall wuerde es halt einen Eigenwert gleich 0 geben,  sodass ein Eigenvektor gibt, sodass A mal dieser Eigenvektor halt genau 0 ergibt, also den Vektor mal 0.  Und in diesem Fall wuerde dieser Termin 0 werden, dieser Teil.", "start": 438.0, "end": 458.0}, {"text": "  Und dann haetten wir hier wieder genau 0.  Aber grundsaetzlich kann das hier erstmal immer, also es ist immer nicht negativ.  Das wissen wir schon mal.  Dann haben wir hier diesen Cosinus stehen.  Wir wissen der Cosinus, das ist auf jeden Fall immer in dem Intervall von minus 1 bis 1.  Schauen wir uns den Cosinus mal noch mal ein bisschen genauer an.  Hier soll 1 sein.", "start": 458.0, "end": 493.0}, {"text": "  Dann sagen wir mal, hier ist minus Pi, minus Pi halbe und Pi halbe.  Und dann haben wir jetzt hier einen Teil von den Cosinus.  Wir wissen, hier haben wir genau 0, den Koordinaten Ursprung.  Hier haben wir wie gesagt Pi halbe.  Und hier an der Stelle haben wir der minus Pi halbe.  Das entspricht quasi genau minus 90 Grad und 90 Grad.", "start": 506.0, "end": 530.0}, {"text": "  Und was wir jetzt sagen koennen, wenn dieser Winkel Alpha ist in dem offenen Intervall,  fuer minus Pi halbe bis Pi halbe liegt.  Und dann ist der Cosinus von Alpha in den Fall groesser als 0, in zwei echt groesser als 0.  Wenn wir hier das abgeschlossen an der Wahl genommen, dann waeren wir nur groesser als 0.  Dann koennen wir auch hier genau die Nullstelle von den Cosinus erreichen, genau gleich 0.", "start": 530.0, "end": 560.0}, {"text": "  So mit den offenen Intervall wissen wir, dass sie auf jeden Fall groesser als 0 sind.  Also, wir wissen, wenn dieser Winkel zwischen den Vektoren hier zwischen minus 90 und 90 Grad liegt,  dann ist das hier auf jeden Fall groesser als 0.  So, jetzt koennen wir uns nochmal anschauen, was es geometrisch bedeutet.  Dafuer wieder als Beispiel ein zweidimensionaler Vektoraum.", "start": 560.0, "end": 600.0}, {"text": "  Und jetzt schnappen wir uns mal den Vektor X hier.  Und dann haben wir uns mal vor, wir multiplizieren den jetzt mit dieser Matrix A.  A ist eine Matrix A, kann skalieren und irgendwie rotieren.  Das heisst, wir rotieren unseren Vektor, dann skalieren wir ihn noch ein bisschen und dann kommen wir hier raus.  Das ist hier so jetzt mal A mal X an.", "start": 604.0, "end": 629.0}, {"text": "  Und jetzt nehmen wir das Galaprodukt X mal AX, das Galaprodukt zwischen dem urspruenglichen Vektor und dem abgebildeten Vektor.  Die Laengen von den beiden Vektoren machen nur was aus, wenn A keinen vollen Rang hat.  Also wir bei dem Null-Vektor rauskommen koennten, dann wird das Ganze halt null.", "start": 631.0, "end": 651.0}, {"text": " Ansonsten ist eigentlich fuer das Vorzeichen nur entscheidend dieser Cosinus,  weil hier wissen wir ja zumindest, dass es immer nicht negative ist.  Das heisst, Vorzeichen haengt eigentlich ab von den Cosinus von dem Winkel hier.  Und jetzt haben wir ja gesagt, okay, das ist immer groesser Null, wenn A der Winkel zwischen minus 90 Grad und 90 Grad liegt.", "start": 651.0, "end": 674.0}, {"text": "  Das heisst, wir wissen, A rotiert maximal 90 bzw. minus 90 Grad, wenn dieses Galaprodukt groesser als Null ist.  Also wenn A positiv definit ist, dann soll das groesser als Null sein.  Das heisst, der Cosinus muss sich zwischen 90 und minus 90 Grad abschwieren.  Das heisst, die Matrix A kann um maximal 90 bzw. minus 90 Grad rotieren.", "start": 674.0, "end": 695.0}, {"text": " Oder in anderen Worten, wenn wir uns mal hier den Hyprom anschauen,  heisst wir teilen unseren 2-Dimensionen in einem Vektorraum mal auf,  haben wir hier einen Hyprom und wir haben da einen Hyprom.  Und diese Matrix A bittet jetzt immer nur auf den Hyprom auf, in denen dieser Vektor sowieso schon liegt.  Das heisst, wir rotieren halb maximal bis hier oder maximal bis da.", "start": 695.0, "end": 715.0}, {"text": "  Also maximal quasi hier in diesem Radius.  Wenn wir jetzt stattdessen sagen, dass das Ganze hier kleiner Null sein soll,  dann wuerde das bedeuten, dass die Matrix immer um mindestens 90 oder minus 90 Grad rotiert.  Also wir bilden immer auf genau den Hyprom ab, in denen der Vektor mal mit tan nicht liegt.  Ich denke, das ist ganz interessant, das im Hinterkopf zu behalten.", "start": 716.0, "end": 739.0}, {"text": "  Und wir haben halt gefordert, okay, fuer die Scholeskiz Erlegung, wenn wir Symmetrie haben,  wir wollen positive Definitivitaet haben, aber man weiss wirklich gar nicht, was das bedeutet.  Man weiss nicht, was bedeutet diese Eigenschaft von dieser Matrix.  Und mir persoenlich faehrt das halt immer leichter, wenn ich diese geometrische Veranschauung habe.", "start": 739.0, "end": 762.0}, {"text": "  Ich weiss, die Scholeskiz Erlegung funktioniert halt immer nur fuer Matrizen, die nur in einen gewissen Rahmen motieren.  Also immer nur in den Bereich von 90 bis 90 Grad.  Okay, soviel zu der Definitivitaet von Matrizen.  Jetzt moechte ich wie gesagt nochmal eingehen auf die Ausgleichsrechnung.  Und dafuer habe ich eine kleine Zeichnung mir nochmal ausgedacht, die ich euch gerne zeilen moechte.", "start": 762.0, "end": 785.0}, {"text": "  Und dann wird hoffentlich nochmal klar, was bei dieser normalen Gleichhang eigentlich passiert,  wenn wir damit halt ein ueberbestimmtes Gleichungssystem loesen.  Schauen uns jetzt erstmal an, eine Ebene in dreidimensionalen Raum.  Also diese Ebene hier aufgespannt werden von zwei Vektoren.  Jetzt die Koordinatenachsen, dann haben wir die Z-Achse, die X-Achse und jetzt die Tierhaltene Ebene.", "start": 785.0, "end": 826.0}, {"text": "  Wir sagen mal, das ist genau die Ebene, die XY-Ebene.  Diese XY-Ebene wird jetzt von zwei Vektoren aufgespielt.  Damit die beiden Vektoren A1, wenn wir den ersten und A2, wenn wir den zweiten,  damit die Vektoren hier diese ganze Ebene wirklich aussparen muessen, die Linie unabhaengig sind.", "start": 826.0, "end": 847.0}, {"text": "  Heisst, wenn wir jetzt beide genau die gleiche Richtung oder die Gegengesetzerichtung zeigen und zeichnen wuerden,  dann koennen wir natuerlich nur auf dieser Garten hier abbilden.  Also dann haetten wir nur diese gerade, die die ganze Ebene haben, das heisst A1 und A2 muessen unabhaengig sein.", "start": 847.0, "end": 867.0}, {"text": "  Und alle die Vektoren, die jetzt in dieser Ebene liegen, sind ja genau die, die wir linearkombinieren koennen durch A1 und A2.  Das heisst, alle Vektoren, die linearkombinieren koennen.  Also A1 mal servimal x1.  Ich schreibe jetzt hier in Vektor-Fallueberung zu betonen, dass das ein Vektor ist, mal ein Skalar.  Plus der andere Spalten-Vektor mal ein Skalar.", "start": 867.0, "end": 889.0}, {"text": "  Das sind genau die Vektoren, die halt in dieser Ebene liegen.  Und jetzt gucken wir uns das hier mal an.  Da habe ich hier schon x1 und x2 geschrieben.  Und jetzt endlich ist das hier wieder nichts anderes, das ist ein Matrix-Vektor-Produkt.  Da koennen wir A1 und A2 eine Matrix schreiben.  Und dann ist A mal x genau die Menge der linearkombinierationen der Vektoren, die in dieser Ebene liegen.", "start": 889.0, "end": 928.0}, {"text": "  In anderen Worten, wenn wir ein Matrix-Vektor-Produkt haben, dann koennen wir auf genau den Spalten-Raum von A abbilden.  Also wir koennen halt alle Spalten von A-Linearkombinieren und das sind genau die Vektoren, auf die wir abbilden koennen.  Und genau, das ist jetzt hier in dem Fall nur ein Unterraum von dem R-Hochtrei, also eben diese Ebene nicht alles.", "start": 928.0, "end": 951.0}, {"text": "  Und wenn wir jetzt natuerlich noch einen anderen Vektor haben, der hier auch mit irgendwie in dem Raum liegt, sagen wir mal zum Beispiel A3.  Dann koennen wir halt sehr wohl sagen A mal x fuer irgendein x, die soll sein, mal A hoch 3, dann werden wir jetzt eindeutig loesen, weil A,  bei A3 liegt ja genau in diesem Spaltenraum von A.", "start": 952.0, "end": 976.0}, {"text": "  Also kann eine Linearkombination finden, also um welche Gewichte x1 und x2 oder x als Vektor, so dass A mal x genau A3 ist.  Das ist also eindeutig loessbar.  Aber wenn wir uns das mal irgendein anderen Vektor nehmen, zum Beispiel in den Vektor B, der eben nicht mehr in dieser Ebene liegt,  dann kann es keine Linearkombination geben, dass A mal x gleich B ist, funktioniert nicht.", "start": 976.0, "end": 1013.0}, {"text": "  Bei B liegt ja eben nicht in den Spaltenraum, also in den Unterraum, also koennen wir halt die Spalten von A nie so linear kombinieren,  dass sie genau bei B rauskommen.  Das heisst, wir haben hier ein unloesbares Gleichungssystem.", "start": 1013.0, "end": 1030.0}, {"text": " Da haben wir gesagt, okay, das kann halt um die haeufig vorkommen, weil wir arbeiten mit Messung und da haben wir,  arbeiten wir irgendwie numerisch, also wir haben Gleichkommazal, haben wir Messunggenauigkeiten und allein deswegen kann es halt schon sein,  dass wir gewisse Ungenauigkeiten haben, bzw.", "start": 1030.0, "end": 1042.0}, {"text": "also wir haben halt einfach mehr Gleichung als Variable,  dann Ungenauigkeiten und dann kann man das wahrscheinlich nie genau loesen, dieses Gleichungssystem.  So was haben wir also tun, was haben wir gelernt, wir haben gelernt, eine approximative Loesung zu finden.", "start": 1042.0, "end": 1062.0}, {"text": " Das heisst, wir haben irgendwie das Residium gebaut, das kennt ihr schon alles aus der Theorie A x minus B,  und wir wollen halt irgendwie minimieren fuer ein x genau dieses Residium, also diesen Abstand zwischen A x und minus B.  Das habt ihr gelernt, okay, diese Loesung hier, dieses x, es ist genau das x, was in dieser Ebene quasi, die wir erreichen koennen, die diesem B am naechsten kommt.", "start": 1062.0, "end": 1084.0}, {"text": "  Also genau, das koennte jetzt sein, zum Beispiel, den jetzt dieser Punkt, der jetzt der Punkt, der diesem B am naechsten kommt.  Der Punkt ist halt genau so gewaehlt, dass er quasi so hier liegt, dass das Residium genau orthogonal auf dieser Spalten Ebene liegt.  Also das ist irgendwie eine Ebene, eine Glatte, und das Residium steht jetzt genau orthogonal darauf.", "start": 1084.0, "end": 1111.0}, {"text": "  Das ist der Punkt, der dem B am naechsten kommt.  Neben Punkt nehmen wir jetzt einmal mal B, und genau, aus der Theorie wissen wir jetzt halt,  das ist halt tatsaechlich genau das B, was am naechsten kommt, das wollen wir jetzt nicht nochmal wiederholen.", "start": 1111.0, "end": 1138.0}, {"text": " Aber was jetzt eigentlich wirklich interessant ist, was wir jetzt naemlich machen koennen,  wir koennen jetzt ein x finden, so dass A mal x dieses B Strich ist.  Das funktioniert, das funktioniert sehr wohl.  Bei B Strich liegt er genau in den Spaltenrahmen, und das ist jetzt halt das, was dem am naechsten kommt.", "start": 1138.0, "end": 1156.0}, {"text": "  Das heisst x hier ist dann die Loesung, hier dieses Residium zwischen den, also A x minus B, das tersaettliche B minimiert.  Und wie haengt das Ganze jetzt mit der normalen Gleichungszenein?  Wir haben die normalen Gleichungen kennengelernt, also wir haben irgendwie ein unloesbares Gleichungssystem A x, gleich B.", "start": 1156.0, "end": 1177.0}, {"text": "  Und dann haben wir gesagt, okay, wir koennen irgendwie von der linken Seite A Transmitter dran multiplizieren,  dann kriegen wir Amp, Ta mal x, mal A mal B.  Das Ding haben wir irgendwie normalen Gleichungen genannt.  Und damit koennen wir jetzt irgendwie die approximative Loesung empfinden.", "start": 1177.0, "end": 1203.0}, {"text": "  Also irgendwie wird unser, ich hab hier noch einen Transpiniert, irgendwie wird unser B durch A Transpiniert so abgebildet,  dass wir dann den Spaltenrahmen von A Transpiniert mal A so linear kombinieren koennen, dass er genau bei A t B rauskommt.  So, das ist jetzt halt wieder relativ absackt und irgendwie mathematisch hergeleitet.", "start": 1203.0, "end": 1220.0}, {"text": "  Was bedeutet das geometrisch? Dazu koennen wir das Ganze mal umstehen und mal schauen, was hier rauskommt.  Das ist endlich, was wir ja dann haben, also eine Loesung x ist ja dann gegeben durch A t A invertiert und der Huber gezogen,  A Transpiniert mal A, invertiert mal A Transpiniert B.  Also ich hab das jetzt hier ruebergezogen und invertiert und dann haben wir hier eine Loesung x.", "start": 1220.0, "end": 1249.0}, {"text": "  Dieses x ist also quasi, wenn ich das jetzt wieder auf A raufwerfe, wenn ich jetzt A mal x rechne,  dann kriege ich ja genau diesen Punkt.  Also ich kombiniere jetzt die Spalten-Vektoren von A durch x, linear, also x sind halt genau die Gewichte einer Linearkombination,  so dass ich halt bei dem Punkt B, hier rauskomme.  Also ich kriege dann quasi genau diesen Vektor hier.", "start": 1249.0, "end": 1271.0}, {"text": "  Und das ist quasi dieses B-Strich.  Und dieses x ist halt gegeben durch halt hier diese abstrakte Gleichung jetzt, oder diesen Term hier.  Und jetzt machen wir mal Folgendes, wir schreiben einfach an der linken Seite A mal x ran.  Das soll ja genau unser B-Strich sein.", "start": 1274.0, "end": 1293.0}, {"text": " Also das ist ja, wir haben ja gesagt, dass genau die Gewichtete in Linearkombination,  dass sie genau bei dem B-Strich rauskommt.  Und genau, jetzt schreiben wir, also wir wissen ja x ist genau das hier.  Jetzt schreiben wir mal von der linken Seite hier noch ein A davor.  Dann kennen wir ja genau dieses A mal x.  Und dann haben wir halt A mal A20-A, minus 1, mal Artib.", "start": 1294.0, "end": 1314.0}, {"text": "  Und das Ding habt ihr jetzt bestimmt schon gesehen in dem Videos davor.  Und habt das hier Projektor genannt.  Und jetzt mit dieser geometrischen Veranschaulichung sehen wir auch, warum das Projektor heisst.  Weil was sie machen, wir haben hier irgendwie wieder eine Matrix.  Also das sind ja alles Matrizen.  Das ist eine Matrix, das hier ist eine Matrix, das ist eine Matrix.", "start": 1314.0, "end": 1336.0}, {"text": "  Das heisst ja Matrix-Vektor-Produkt, das heisst wir beben B ab auf irgendeinem anderen Vektor,  und zwar genau auf dem Vektor B-Strich.  Das heisst, diese Matrix projiziert dieses B in den Spaltenraum von A,  so dass wir eine Linearkombination von den Spalten finden koennen,  so dass wir halt genau bei dem B rauskommen.", "start": 1336.0, "end": 1358.0}, {"text": " Also in anderen Worten, was die normalen Gleiche macht,  ist dieses B in den Spaltenraum projizieren,  und dann halt die Loesung zu finden von dem projizierten B,  fuer die Linearkombination von dem projizierten B.", "start": 1358.0, "end": 1380.0}, {"text": " Genau, zwar jetzt vielleicht noch mal relativ viel Wiederholung,  aber mir persoenlich ist es sehr wichtig,  das nochmal mit dieser geometrischen Veranschaulichung hier zusammenzubringen,  weil das hat mir damals, als ich das Modul selber bedeckt habe, halt sehr geholfen.", "start": null, "end": 1380.0}]}]