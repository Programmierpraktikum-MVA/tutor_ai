[{"lecture": "25797_32_course_video", "Timestamps": [{"text": "  Hallo, ich bin Bruno.  Dieses Video wird ein kleiner Exkurs in die Melminsanal Analyse ist.  Wieso machen wir das?  Das ist der Fall daran, dass einerseits die Optimierung von einem in soenere Funktionen meistens nicht besonders das Stanz ist,  als hat man eigentlich schon mit der Extremwertbestimmung in der Schule schon gemacht.", "start": 0.0, "end": 23.0}, {"text": "  Und andererseits ist es, dass in der Praxis halt praktisch alle Probleme von mehr als einer Variante abhaengen wuerden.  Weiss ich nicht mehr von zuviel, aber von einfach abster hin und so.  Das heisst, bei der Optimierung ziehen uns meistens die von mehreren Varianten abhaengen.  Und auch bei uns unsere Anwendung ist die Ur-Faech-Medium.", "start": 23.0, "end": 42.0}, {"text": "  Also wir haben einige Stuetzpunkte gegeben, die koennen wir nicht aendern im Raum.  Stuetzpunkte.  Das ist eigentlich unsere Aufgabe, ist wir wollen hier so ein 3x-Netz durchlegen.  Weil wir die Anzeltreiche nicht aendern koennen.  Also nur so zahlend die Stuetzpunkte der 3x.  Die halten nicht diese Stuetzpunkte, die natuerlich fest sind.", "start": 42.0, "end": 74.0}, {"text": "  Ja, ist die Frage halt, was ist die minimale Flaeche von dieser Flaeche, die aufgespannt wird.  Ja, also wie lange ist diese Fah minimieren?  Wenn wir eine Flaeche haben, das koennen wir zum Beispiel machen.  Wir haben so einen Punkt, den koennen wir in den 2x nach hinten verschieben.  Wenn wir ein neues 3x bekommen, dann wirst du das nicht mehr das haben.", "start": 74.0, "end": 93.0}, {"text": "  Wenn wir die auch irgendwie dahingehen, dann koennen wir zum Beispiel sagen,  wahrscheinlich waere die Flaeche groesser, waere das keine gute Wahl gewesen.  Aber dann koennen wir jetzt sowas machen, weil die Stuetzpunkte verschieben,  wir koennen nicht verschieben wie viele wir haben, oder welche 3x, mit welchem verbunden sind.", "start": 93.0, "end": 109.0}, {"text": "  Und was man auch dazu sagen kann, ist, dass natuerlich jeder Punkt hier 3x-Naten hat.  Also haben wir sozusagen 3 Variable-Vorpunkt.  Also haben wir 5 mehr Variable-Vorjabeln.  Dann finde ich mal, wenn alle ein bisschen an Funktionen.  Was wir aber sagen koennen, wir bilden auf dem Skala ab, wie einfach unsere Flaeche.  Das wird auch generell natuerlich unsere Funktion sein.", "start": 110.0, "end": 131.0}, {"text": "  Also bei uns ist jetzt diese Anwendung, die unsere Verbenden sind alle nicht festen,  die Punkte sind unsere 3x.  Und dafuer wird es in der Regel erstens viele geben, und 2x hat jeder Punkt 3 Variable.  Und wir beachten halt nur Funktionen der Form f geht von r auch n auf r.  Wir bilden immer auf dem Skala ab, ueber auf dem Zahl, nicht wieder auf dem Vektor zum Beispiel.", "start": 131.0, "end": 151.0}, {"text": "  Und deshalb bei uns die Flaeche, einfach einfach am Zahl.  Jetzt haben wir ein paar Beispiele dafuer betrachten, denn wir haben Funktionen in dieser Form.  Zum Beispiel haben wir jetzt f von xy, das ist gar nicht x, es ist xy.  Das ist vielleicht eines einfachen Beispiele.  Wir koennen auch sozusagen hier noch andere Funktionen mit reinnehmen.  Zum Beispiel haben wir Betragsfunktionen.", "start": 154.0, "end": 172.0}, {"text": "  Also, wir g von xy ist Betrag von y, mal Betrag von y.  Wir haben hier so ein Pseudopolinom, wir haben wie x\u00b2y von 3x.  Und dann ist hier m, zum Beispiel das geometische Mitte definiert als Funktion von 3 Parametern.  Also xyz wird abgebildet auf dritte Wurzeln aus x mal y mal z.  Und hier muss ich schon mal die Kenntmann ja, also koennte man es auch als ein Melvensohn als Funktion betrachten.", "start": 172.0, "end": 203.0}, {"text": "  Und hier auch dieses Punkt 2 vom R auf 4 auf R ist sozusagen das Skala-Produkt fuer zwei Vektoren.  Da groessert es, der denke ich 2.  Wir haben hier die Eintraege x1 ist 2 und y1 ist y2.  Und jetzt spielen wir ab auf x1 mal y1 plus x2 mal y2, also die Element-Weite-Multifikation.", "start": 203.0, "end": 221.0}, {"text": " Ja, beide Definitionen sind jetzt nicht unbedingt die nuetzlichsten,  weil ich wahrscheinlich eher generell fuer Ende definieren, wie es immer gemacht wurde.  Aber gleich wieder denken, dass man eigentlich auch schon indirekt Funktionen von mehreren Variabeln nutzt hat immer.  Und das sind nicht so so natuerlich sind.", "start": 221.0, "end": 239.0}, {"text": " Ja, jetzt ist natuerlich unsere grosse Frage, wie optimieren wir diesen?  Ja, das ist etwas, was wir machen wollen, wir wollen ja sonst mit diesem Funktionen erstmal nicht viel machen,  aber wir wollen halt fuer den Wert finden, fuer die die optimal sind.", "start": 239.0, "end": 253.0}, {"text": " Wenn wir jetzt rausfinden wollen, wie wir diese mehreren Funktionen optimieren,  dann gehen wir nochmal zurueck auf die Einimensionaloptimierung, die man schon aus Annalena oder auch der Schule kennt.", "start": 253.0, "end": 271.0}, {"text": " Also was wir machen ist, wir haben eine Funktion gegeben, f von x geht von R nach R, also einimensional,  was wir tun wollen ist, wir wollen f optimieren, und das bedeutet bei uns arg mit f von x,  also wir wollen den Wert fuer x finden, fuer den f im Enimal, also fuer uns wird immer ein optimal Minimum sein.", "start": 272.0, "end": 278.0}, {"text": "  Wir wollen jetzt endlich nicht den minimalen Wert von f haben, sondern wir wollen das Argument bekommen fuer das f minimal ist.  Was war da immer der Ansatz? Auch schon in der Schule?  Wir wollen fuer die Nullstellen von der Ableitung von f von x berechnen.", "start": 278.0, "end": 294.0}, {"text": " Ja, wieso ist das? Wir koennen uns vorstellen, wenn wir unsere Funktion haben und die verlaeuft irgendwie nach unten,  dann geht die hier nach unten und umhoert sich auch herunter zu gehen, geht dann wieder nach oben.  Dann werden wir natuerlich hier fuer unser Minimum, hier fuer unser Minimum.", "start": 294.0, "end": 308.0}, {"text": "  Ja, was jetzt unser Erkenntnis ist, ist, dass hier die Ableitung irgendwie negativer, weil hier irgendwie nach unten,  das heisst hier ist die Kleinernull, hier ist irgendwie groessernull.", "start": 308.0, "end": 332.0}, {"text": " Ja, und was koennen wir jetzt halt hier sagen? Aus dem Zwischenwaertssatz wollen wir folgen,  dass hier halt Nullstellen ist, also f von f von x berechnen, ja, und intuitiv ist das auch direkt unten,  intuitiv ist das auch direkt unsere Nullstellen, unsere Option fuer unsere Funktion.  Ja, und deswegen nutzen wir diesen Ansatz.", "start": 332.0, "end": 341.0}, {"text": "  Was wir auch noch brauchen ist, die zweite Ableitung um zu pruefen, ob es tatsaechlich ein Optimus,  ob es ein Maximum, Minimum oder ein Wendepunkt ist.  Ja, was ist die zweite Abpunkt, das ist die Kruemung.  Wir koennen uns hier vorstellen, dass wenn es ein Minimum ist, dann haben wir so die Kruemung nach oben ueberall,  da werden wir jetzt zahlen.", "start": 341.0, "end": 358.0}, {"text": "  Da sind wir jetzt oben gekruemmt, weil wir von am tiefsten Punkt sind,  da sind wir fuer eine positive Kruemung, und dann auch noch dazu, wenn wir jetzt ein Maximum haetten,  dann waere zur Kruemung nach unten, also negative Kruemung, deswegen wuerde man danach hier keiner Null gucken.  Aber das heute alles war jetzt bekannt aus der Schule.", "start": 358.0, "end": 386.0}, {"text": "  Ja, und was jetzt auch wichtig ist, diese Nullstellen, die wir bekommen, sind nicht notwendigerweise globale Optionen,  das ist ja minima, ja, einfach weil, was wir ueberpruefen, ist eigentlich eine lokale Eigenschaft,  wir koennen ja eine Funktion haben, die so verlaeuft.", "start": 386.0, "end": 401.0}, {"text": " Ja, das sind natuerlich hier die Ableitung 0 und auch hier die Ableitung 0,  ja, aber natuerlich ist das nur ein Lokales Maximum, Minimum,  und das hier vielleicht ein globales Funktion, das so verlaeuft, das ist erlaubt.  Deswegen ist es fuer uns schoen, wenn es f-convex ist, weil dann kann es sowas hier nicht geben.", "start": 401.0, "end": 418.0}, {"text": " Ja, haetten wir so einfach eine Funktion, die sagen, einer Parabe aehnelt,  wo wir jetzt einen Punkt haben fuer dieses Optimales, ja, und dann wissen wir auch,  dass das gleich das auch globale Optimum ist.", "start": 418.0, "end": 433.0}, {"text": " Wenn wir natuerlich jetzt diese verschiedenen Nullstellen gegeben haben, koennten wir einfach jeder ausprobieren,  und das nicht, dass wir wie endlich wieder sind, und herausfinden,  welcher Funktion wird der Dicht der kleinste ist, und das waere dann unser globales Optimum.", "start": 435.0, "end": 443.0}, {"text": " Ja, und wie gesagt, bei uns erlaubt man mal ein Minimum, ja, und moechten wir da wirklich etwas maximieren,  ja, zum Beispiel, wenn wir mal den Gewinn von irgendwas maximieren,  dann wuerden wir einfach minus f von x minimieren,  und dann koennt ihr mir vorstellen, dass das irgendwie so eine Spiegel an der Upsernax ist,", "start": 443.0, "end": 455.0}, {"text": " wenn wir eine besondere Funktion haben, und waere dann minus die Funktion hier so, ja.  Koennt natuerlich jetzt, denn das hier maximieren, koennen wir einfach das minimieren, ja.  Ja, aus diesem Ansatz sehen wir jetzt irgendwie, dass wir Abletzungen brauchen von uns Optimierung.", "start": 459.0, "end": 480.0}, {"text": " Also moechten wir fast viel Abletzung mit Mais-Missionalen haben,  und dafuer gehen wir auch erstmal nochmal zurueck zu den Abletzungen mit einem Missionalen,  ja, wir aendern uns da definiert man.  Ja, und was war unsere Abletzung?  Ja, unsere Abletzung war irgendwie einfach die Steilung an dem Punkt,  bzw. die Aenderung des Rates der Funktion, ja, so was meines Intuitiv definiert.", "start": 480.0, "end": 493.0}, {"text": "  Und wie haben wir die dann zusammenbestimmt?  Ja, die Idee war da einfach, wir betrachten das Verhalten von der Funktion,  wenn wir den Parameter um einen kleinen Wert veraendern, ja.", "start": 493.0, "end": 510.0}, {"text": " Aber wenn wir einen kleinen Wert weitergehen, wie verneckt ist unsere Funktion?  Ja, und die Kleine wie diesen Wert waehlen,  das so zu naeher wird diese Veraenderung halt an die tatsaechliche Abwertung an diesem Punkt kommen.  Ja, das koennen wir auch leicht dann so grafisch betrachten.  Ja, also haben wir jetzt eine Funktion gegeben, das ist hier x hoch 3, minus 2, x hoch 3, minus 1.", "start": 510.0, "end": 527.0}, {"text": "  Ja, jetzt wollen wir hier die Abwertung von x0 bestimmen, wobei x0 gleich eins ist, ja, wir sehen es hier in eins.  Und was wir jetzt erst machen, ist, wir waehlen einen h,  da waere jetzt hier h ist gleich eins, und waehlen wir den zweiten Punkt, das ist x0 plus h, das ist jetzt hier zwei.", "start": 527.0, "end": 549.0}, {"text": " Und jetzt legen wir einen 3 durch diese zwei Punkte, ja, wie wir hier sehen,  und haben wir hier einmal die Differenz unserer y-Werte,  als diese Seite das ist delta y, und haben wir hier h, ja, die Laengel, die ist in der Weihz quasi,  die ist in der Weihz, jetzt koennen wir auch delta x nennen, der unterschiedliche x-Werte,  aber das ist natuerlich gleich h, das schreiben wir jetzt noch.", "start": 549.0, "end": 573.0}, {"text": "  Und den Seiten, die uns wirklich interessiert, ist die hier, ja, diese Schraege, und das ist dann genau delta y durch h,  ja, unsere Steigung, uns drei x hier ist delta y durch h.", "start": 573.0, "end": 596.0}, {"text": " Ja, und wir koennen gleich eins zeichnen, ja, sehen wir jetzt hier, diese gerade, unsere Steigung ist drei x hier,  und die Idee ist jetzt, wenn wir dieses h klein waehlen, dann wird diese Steigung immer naeher an diese sichere Ableitung unserer Funktion an den Punkt x0 kommen.", "start": 596.0, "end": 602.0}, {"text": "  Ja, dafuer zeichnen wir die jetzt auch mal ein, das ist hier in gruen, und wir sehen das bei h gleich eins, der uns nicht noch ziemlich gross ist, ja,  also irgendwie ist unser, unsere sichere Ableitung hier negativ, ja, aber unsere durchliche Ableitung in diesem drei x hier ist noch positiv,  das ist wenn wir h fuer klein erwehen.", "start": 603.0, "end": 628.0}, {"text": "Ja, so waehlen wir jetzt h etwas kleiner, zum Beispiel 0,9,  und sehen wir jetzt, ist ein bisschen naeher angekommen, ja, vorher war es irgendwie hier so in der Art, ja, wir sind ein bisschen naeher angekommen, aber wir haben auch ziemlich weit entfernt.", "start": 628.0, "end": 644.0}, {"text": " Ja, waehlen wir jetzt zum Beispiel h, 0,5, dann sehen wir, wir sind schon mal negativ, ja, wir sind schon mal im richtigen Bereich,  und wenn wir jetzt noch kleiner werden, zum Beispiel 0,25, sind wir schon sehr nah an der Ableitung, 0,1, noch naeher dran,", "start": 644.0, "end": 652.0}, {"text": " und damit 0,1,1 sind wir schon quasi fast bei der richtigen Ableitung, ja, wir sehen in dem Fall, dass unser Verfahrensrecht nicht gegen die Ableitung kompagiert.", "start": 653.0, "end": 668.0}, {"text": " Ja, und jetzt ehrlich ist das auch die Definition der Ableitung, und ablaesst mich genau dann, wenn wir h wie die ich klein waehlen,  dann haben wir genau die durchliche Steichung dieses drei x als unsere Ableitung, ja, also, da haben wir uns auch definiert durch den Grenzwert von diesem h gegen 0,", "start": 668.0, "end": 679.0}, {"text": " ja, was hier f von x plus h minus f von x, ja, das war unser delta y, ja, und dann halt genau durch h wie wir auch berechnet haben,  ja, und das ist dann, der, der, der, wer unsere Ableitung, die Steichung an diesem Punkt,  und was jetzt schoen ist, wir koennen uns dann genauso auch im Melvensohn an vorgehen, also, was wir jetzt endlich machen werden,", "start": 679.0, "end": 697.0}, {"text": " ist, wenn wir im Melvensohn an den Look vorgehen, nur dass wir halt, wenn wir eine Funktion haben, die von mehreren Varianten abhaengen,  also f von x y, dann machen wir das separat einmal halt, wie x plus h passiert da,  und dann hat y und h passiert da, ja, wir betrachten die jeweils separat, ja, also, wie, wie veraendert sich die Funktion,", "start": 697.0, "end": 717.0}, {"text": " wenn man x ein bisschen aendert, wie veraendert sich wenn man y ein bisschen veraendert, ja,  und dann koennen wir die irgendwie nach haf zusammen tragen, ja,  wichtig ist halt dann dabei, dass es jede andere Variable, die wir halt nicht mit h veraendern, natuerlich dann konstant ist,  noch als solches verhandelt wird.", "start": 717.0, "end": 739.0}, {"text": "  Damit kommen wir auch zum Begriff der Parzellableitung, ja, Parzell abgenommen, deswegen, weil wir immer nach einer der Variable ableiten,  nicht nach allen gleichzeitig, ja, haben wir jetzt eine Funktion gegeben, vom r auch n nach r,  wo wir jetzt die Parameter als ein Vektor darstellen, ja, dann nehmen wir eine Ableitung von f nach einer Variable", "start": 739.0, "end": 761.0}, {"text": " in xi, eine Parzellableitung von f, ja, wichtig, wir haben ja eine Variable xi, nicht mehrere, ja,  und dafuer schreiben wir dann auch hier mit diesem, diesem Dell, einfach ein nd, ja, als d benennen, ja, df nach dx, i,  ja, auf eine Parzellableitung von f nach xi, ja, wichtig ist dann einfach, wenn wir nach xi ableiten,", "start": 761.0, "end": 785.0}, {"text": " dann werden alle anderen Variable in x, j, wir haben eine konstante Behandelung, ja, also multiplizieren wir mit den anderen Variable in x, j,  dann bleibt ihr halt stehen, falls unser xi nicht null wird und sonst f hat z weg, wenn wir mit der dien, dann f hat sie auch weg, ja,", "start": 785.0, "end": 799.0}, {"text": " es ist genauso, jetzt wuerde da einfach irgendeine Zahl stehen, ja, und sonst gibt es ja einfach keinen Unterschied zum eindemissionalen  ableiten, ja, wenn man ableiten im eindemissionalen kann, dann kann man auch Parzell ableiten, ja, wir werden jetzt auch keine sozusagen  komplexeren Funktionen, wie Boegerhypn, Exponenzialfunktion und sonst was betrachten, ja, es ist kein grosses Problem sein,", "start": 800.0, "end": 822.0}, {"text": " ja, am besten, wenn wir einfach einen Boeschel betrachten, ja, wir jetzt eine einfache Funktionen geben, also f von x, y,  jetzt gleich x, y, jetzt haben wir davon die Parzellableitung berechnen, wie machen wir das,  wir werden jetzt erstmal die Parzellableitung nach x berechnen, das koennen wir gucken, okay, wir muessen jetzt das hier nach x", "start": 822.0, "end": 840.0}, {"text": " ableiten, ja, was passiert, wenn wir x nach x ableiten, da kommt irgendwie eins raus, ja, und jetzt muessen wir hier diesen Teil  plus y noch ableiten, und das ist jetzt genau so, dass wir hier so was stehen wie plus 3 oder plus 4 oder so was, ja,  es faehrt natuerlich alles weg, es wird einfach zu null, ja, so wird das hier weg, es ist einfach null, also hin und wieder raus,", "start": 840.0, "end": 865.0}, {"text": " ja, es gibt einiges, zu den Fragen, was fuer unsere Abwaelzungen nach y, ja, wir sehen, offensichtlich kommt bei y wieder eins raus,  und dieses x faellt weg, ja, also kriegen wir auch fuer die Abwaelzungen nach y eins raus, also ueber das Stimmen hier die Abwaelzungen nach x  und nach y ueberein, ja, sind beide eins, ja, wenn ihr ein paar interessante Beispiele, da haben wir hier g von x, y, z,", "start": 865.0, "end": 892.0}, {"text": " es ist gleich x mal y plus y mal z hoch 3 plus 2 z, ja, sonst auch weiter nicht wild, ja, moechten wir noch x ableiten,  dann kriegen wir, da kriegen wir es y raus, ja, wie kommen wir darauf, ja, irgendwie hier nach x ab, faellt dieses x ja weg,  wir kriegen ein eins, ja, wir eins mal y, also y, ja, jetzt sehen wir, hier kommt kein x vor, und hier kommt auch kein x,", "start": 892.0, "end": 915.0}, {"text": " also koennen wir die auch wegsteichen, also kriegen wir hier einmal y, also y raus, ja, jetzt nach y, wir leiten diesen Term noch y ab,  es kommt daraus, jetzt y wird wieder zu eins, also kriegen wir hier nur x, ja, jetzt haben wir diesen y-Term, genauso analog wie hier,", "start": 915.0, "end": 937.0}, {"text": " dieses y wird zu eins, also bleibt z hoch 3 stehen, und dieses 2 z hat kein y, also faellt das weg, also kriegen wir einfach nur x plus z hoch 3 raus,  ja, und jetzt noch zu letzt nach z, was passiert da, dieser erste Term, es haelt kein z, also faellt es da weg,", "start": 937.0, "end": 956.0}, {"text": " jetzt muessen wir hier ableiten, ich muessen wir hier z hoch 3 ableiten, das kommt daraus, na ja, 3 z hoch 2, ja, dann koennen wir hier so sagen 3,  wir haben jetzt 2, und jetzt muessen wir noch 2 z ableiten, und da faellt euch auf das z weg, wir beiten die 2, also unser Ergebnis sein 3 y z quadrat ist 2,", "start": 956.0, "end": 978.0}, {"text": " ja, wie man vielleicht merkt, wenn man weiss, wie man Funktionen generell ableitet, dann ist Partieableitung eigentlich nicht mehr,  man muss nur aufpassen, dass man nicht irgendwie faeltscherweise irgendwie die Variabeln vertauscht, ja, vor allem wenn es irgendwie Variabeln-Indizies oder so was waeren,", "start": 978.0, "end": 993.0}, {"text": " ja, aber sonst muss man wirklich nicht mehr machen, ja, was jetzt aber jetzt nur haben ist die Endungsrate von immer einer Variabel,  ja, aber sie haben irgendwie immer nur die Ableitung nach x, jetzt haben wir die Ableitung nach y, und wir haben die Ableitung nach z, separat,", "start": 993.0, "end": 1003.0}, {"text": " aber wir haben irgendwie noch nicht die Endungsrate der gesamten Funktionen, wir wollen ja eigentlich die Ableitung von unserer Funktion haben,  nicht nur von jeder einzelnen Variabel, ja, und damit gehen wir jetzt ueber zum Gradienten, ja, der Gradienten spricht dann unserer tatsaechlichen ersten Ableitung unserer Funktion im Medi-Missionen,", "start": 1003.0, "end": 1027.0}, {"text": " ja, koennen wir kurz ueberlegen, wie der wahrscheinlich definiert sein koennte, ja, wir haben jetzt irgendwie schon die einzelnen Richtungen unserer Funktionen geben, ja,  also hier noch x-Richtung, hier noch y-Richtung, hier noch z-Richtung, jetzt haben wir die irgendwie zusammenfuegen zu einer Richtung von unserer ganzen Funktion, ja,", "start": 1027.0, "end": 1041.0}, {"text": " aber wir wollen jetzt irgendwie kombinieren, und da waere vielleicht irgendwie ein intuitiver Ansatz, dass man die halt in Vektor schreibt,  und das wird jetzt der Ansatz der, das waere der Gradienten sein, ja, also der Gradienten spricht der ersten Ableitung im Medi-Missionen, ja,", "start": 1041.0, "end": 1063.0}, {"text": " und es hat der Vektor der einzelnen Partie in der Funktion f, ja, also wir schreiben fuer den Gradienten hier, grad f von x, wird meistens mit diesem gespiegelten Data,  ja, das nennt sich nabla dargestellt, ja, nabla von f von x, und das ist halt einfach ein Vektor, wobei die Ithekomponenten halt die Itheparzellableitung der Funktion ist,", "start": 1063.0, "end": 1084.0}, {"text": " also nach xi, ja, und das ist natuerlich dann wieder ein Vektor, also auch den LRN, ja, und sonst ist da nicht viel mehr bei, also wenn man ueber den Ableiten kann,  dann kann man ein paar C ableiten, und dann kann man auch leicht den Gradienten bestimmen, ja, wie dann einfach das in der ersten Komponenten leiten wir noch x1 ab,", "start": 1084.0, "end": 1101.0}, {"text": " dann wuerden wir noch x2 ableiten, und an der letzten Endenkomponenten leiten wir noch xn ab.", "start": 1101.0, "end": 1121.0}, {"text": "Was man jetzt erstmal sagen kann, aber ist halt, dass der Gradient selber eigentlich wieder eine Funktion ist,  also wenden wir sozusagen den Gradienten auf eine Funktion ab und nicht auf einen Punkt oder so, ja, dann wird hier natuerlich wieder bei den Patient-Appelts und eine Funktion rauskommen,  also unsere einzelnen Komponenten wieder Funktionen, ja, also koennen wir das natuerlich wieder auswerten an irgendeinen Punkt, und da ist halt selber eine Funktion, die halt von einem Vektor auf einem Vektor abbildet,", "start": 1121.0, "end": 1130.0}, {"text": " das passiert nicht ganz mit dem Format von den Funktionen, die wir vorher betrachtet haben, aber da ist natuerlich jetzt keine Funktion, die wir optimieren, ja.", "start": 1131.0, "end": 1147.0}, {"text": "  Wo man mal die Situation des Gradienten sagen kann, ist halt, dass der Gradient an einer Stelle x1 bis xn hier in die Richtung der groessten Steigung zeigt, ja, da kann man zum Beispiel sagen, wenn man jetzt zum Beispiel optimieren will, also man will minimieren,", "start": 1147.0, "end": 1157.0}, {"text": " dann wuerde man wahrscheinlich in die Gegensatzrichtung des Gradienten gehen, wollen wir mehr nicht ansteigen, sondern wir sozusagen abfallen, ja, und die Laenge des Gradienten, ja, das ist jetzt wieder ein Skalader,", "start": 1158.0, "end": 1172.0}, {"text": " an dieser Stelle ist die Steigung der Funktion, wobei hier anzumerken ist, dass wir spaeter sehen werden, diese Laenge nicht unbedingt mehr benutzen werden, ja, und das ist meistens eher die Richtung der Steigung mehr als die Steigung der Funktion an diesem Punkt.", "start": 1173.0, "end": 1186.0}, {"text": "  Ja, am naechsten ist es wahrscheinlich wieder ein Beispiel zu betrachten, ja, also hier ist nochmal die Definition von Gradienten, und wir machen unser einfaches Beispiel f von xy, das kann ich x plus y, ja, natuerlich kennen wir jetzt die Abwaltung schon, ja, wir machen das jetzt,", "start": 1187.0, "end": 1216.0}, {"text": " wir wissen, dass die beiden eins sind, also sonst da Gradient von dieser Funktion einfach der Vektor 1, 1. Ja, was man jetzt hier vielleicht auch schon sich ueberlegen kann, ist, was das mit der Optimum der Funktion zu tun haben koennte, ja, dass der Vektor irgendwie konstant ist, weil er es hinterher jetzt nicht von x oder y hat, also das ist immer 1, 1, egal welchen Wert wir einsetzen, und man kann halt irgendwie sich ueberlegen, man hat im einemimensionalen die 1.", "start": 1217.0, "end": 1238.0}, {"text": "Abwaltung vielleicht 0 gesetzt, also koennte man ja meinen, dass man im imimensionalen gleich 0 Vektor setzt, ja,  das koennte man ja auch tun, und dann koennen wir sehen, dass natuerlich die Gleichung 1, 1 ist gleich 0 Vektor, ja, Keiloesung haben wird, ja, das wuerde nicht funktionieren, ja, also haben wir kein Optimum, ja, diese Funktion hat kein Optimum, das uebliche und intuitiv ist, weil die x plus y irgendwie wie eine, wie eine Grade ist, kann man sich vorstellen, wie eine Grade ist,", "start": 1238.0, "end": 1267.0}, {"text": " wenn sie wirklich eine Ebene sein, ja, aber eine Grade hat ja auch im Allgemeinen kein Optimum oder Minimum.", "start": 1267.0, "end": 1286.0}, {"text": "Ja, betrachten wir nochmal ein, was ist das anderes Beispiel, ja, also g von xy ist 3x\u00b2 plus 4xy, jetzt muessen wir erst wieder die einzelne Patientabwaltung bestimmen, ja, jetzt koennen wir kurz ueberlegen, was unsere Patientabwaltung nach x, ja, wir muessen fuer x ableiten, dann kommen diese 2 runter, also haben wir eine 6, 2 faellt weg, also wir sind 6x,  und seiten wir noch ab, also faellt dieses x weg, also nehmen wir 4y, ja, dann wird unsere Abwaltung nach x sein, 6x plus 4y, ja, und jetzt muessen wir noch y ableiten, faellt das natuerlich einfach weg, ja, dann faellt dieses y weg, also nehmen wir einfach 4x raus.", "start": 1287.0, "end": 1306.0}, {"text": "  Jetzt haben wir den Gradienten davon, das ist nicht einfach, beschreiben wir es einfach im Vektor, also kriegen wir jetzt Gradienten von g von xy und einfach 6x plus 4y und 4x, ja, wir sehen natuerlich jetzt hier, dass der Gradient selber in einer Funktion ist, aber wir haben natuerlich wieder Abhaengigkeiten von den Parametern haben.", "start": 1306.0, "end": 1335.0}, {"text": "  Spass haben wir, koennen wir jetzt auch den Gradienten an einer bestimmten Stelle erbrechen und davon den Laengen nehmen, ja, jetzt wollen wir jetzt hier die Laenge von Gradienten an dem Punkt 1 minus 1 haben, das sind unsere Patientabwaltungen ein, von 1 minus 1 waere anders aus, also kriegen wir den Vektor 2v und davon ist der Laengen halt ungefaehr 4,48, ja, also hat unsere Funktion an dem Punkt 1 minus 1 die Steigung 4,48, ja, viel mehr ist es auch nicht, ja, das Besteilung ist,", "start": 1336.0, "end": 1347.0}, {"text": " der Verbrechen des Gradienten sollte kein grosses Problem sein und wie wir jetzt gesagt haben, die Sachen bauen vielleicht faehrt aufeinander auf, ja, beim Ableiten kann und sollte Patientableiten kein Problem sein und auch Gradienten bestimmt kein Problem sein.", "start": 1347.0, "end": 1370.0}, {"text": "  Jetzt noch einige Visualisierungsmoeglichkeiten, ja, meistens hat man so eine Levelsetz, ja, wie wir hier sehen, sind ja diese Linien und die Linien beschreiben halt, dass Gradient hier konstant ist, dann habe ich mir vergessen, dass das da war.", "start": 1370.0, "end": 1399.0}, {"text": "  Hier jetzt noch zwei Beispiele zur Visualisierung von mehr dimensionellen Funktionen und Gradienten, ja, das hier ist ein Konturplott oder die Konturlines von einer Funktion, ja, die Idee, weil der Funktion hier ist, dass die so ein bisschen geformt ist wie so Berge, ja, dass es doch nicht so gibt fuer sie sein, ja, jetzt haben wir uns hier vorgestellt, dass hier die Funktion so ein Hohlwert hat, oder hier niedrigere Aussen, ja, jetzt nehmen wir das Beispiel auch Hohlwert, ja, das ist das Beispiel,", "start": 1400.0, "end": 1429.0}, {"text": " hier ist der Hiking genannt, unser Punkt hier ist unser Bergsteiger, ja, und was man hier vor allem bemerkt, sind diese Linien, was wir hier nicht beschreiben, ist das eine Punkte, wo die Gradienten den gleichen Wert immer haben, also sie sind hier konstant an diesen Linien, ja, es werden die auch Hoeheninien genannt, denn hier ist die Funktion sozusagen ueberall gleich hoch, ja, das heisst nicht mehr, wie auch Levelsetz, ja, weil es dann ueberall hier, das ist dann die Hoehe gleich, also, Level gleich ist, ja,", "start": 1430.0, "end": 1459.0}, {"text": " und was wir hier auch noch koennen, ist die Farbe der Linien, das ist vielleicht in diesem Punkt nicht so, als echtliches, dieses Niederhaendler, wo jetzt hier bedeutet, dass es Hohlwerte annimmt, und wir sehen hier ein bisschen blau, die noch mit dem Durchen vielleicht schon irgendwie ueben liegt, sondern die dringenden Werte, ja, und was jetzt hier noch ist, ist unser Punkt hier, ja, unser Bergsteiger, wir sehen hier der Gradient hier, welche Richtung wir zeigen, wir wissen ja, der Gradient zeigt in die Richtung der groessten Steigung, ja, so koennen wir uns vorstellen, dass hier der Bergsteiger hochgeht, ja, das ist der Bergsteiger, wo jetzt mit dem Gradient zu diesem Gipfel laufen.", "start": 1461.0, "end": 1478.0}, {"text": "  Ja, und dann ein weiteres Beispiel ist aehnlich, ja, hier haben wir so kurze nische Kreise, was wir auch noch sehen, neben diesen Linien, die wir auch vorher hatten, also den Kartollinien, diese Hoehenlinien, haben wir hier noch diese Pfeile, weil die sind vielleicht ein bisschen schwer zu sehen.", "start": 1479.0, "end": 1503.0}, {"text": "  Ja, und was wir an diesen Pfeilen sehen koennen, ist, dass irgendwie der Gradient ueberall, sagen wir nach Aussensteiger, so von diesem Zentrum weg, als wir auch sehen koennen, ist, dass die Pfeile etwas groesser werden, also hier ist es in dieser Kleinen, ja, dann sind sie etwas groesser, also, jetzt geht es mir mit dem Fragmaessig zu, was wir an den Plaetzen, den ich sehen koennen, ist, dass er irgendwie zeigt alles von dem Zentrum weg,", "start": 1503.0, "end": 1526.0}, {"text": " also koennen wir uns vorstellen, dass das Zentrum hier das Optimum ist, ja, also, ueberall ist die Steigung sozusagen von diesem Punkt weg, ja, also koennen wir hier sogar wahrscheinlich davon ausgehen, dass die Funktionen konvex ist, ja, wir wahrscheinlich erwarten, dass das eine konvexer Funktion ist, zumindest in dem Bereich, den wir betrachten, ja, wir erwarten, dass dieser Punkt hier halt ungefaehr unser Optimum ist, unser globales Optimum.", "start": 1527.0, "end": 1548.0}, {"text": "  Ja, und hier auch noch sehen kann, die verschiedene Farben, also hier werden jetzt zum Beispiel diese niedrigeren, wenn es dunkleren, blau-toene niedriger Werte, ja, und diese helleren, rot-toene hoehere Werte, ja, wir wuerden uns vorstellen, dass das so eine Parabelarbeit in drei Dimensionen ist, ja, hier waere dieser Punkt, hier, ja, dann werden wir hier aussen irgendwo hier, ja, wenn das so macht.", "start": 1549.0, "end": 1550.0}, {"text": "  Gut.", "start": 1550.0, "end": 1578.0}, {"text": "  Dann haben wir jetzt unsere erste Abletzung, ja, wenn wir uns in die Vorschrift in die Optimierung einwiesen haben, dann brauchen wir jetzt auch die zweite Abletzung, ja, damit wir auch dann ueberpruefen koennen, ob unser brechender Wert tatsaechlich ein Optimum ist, ja, und dann welcher Typ, ja, mit der zweiten Abletzung ueberpruefen wir auch, was in der Extremstelle ist, ja, also, Maximum-Optimum, ja, Maximum-Minimum, ja, und dann welcher Typ.", "start": 1579.0, "end": 1584.0}, {"text": "  Und wir brauchen also auch noch die zweite Abletzung in der Funktion. Dazu kommen wir jetzt.  Jetzt kommen wir zur ersten Matrix. Ja, die erste Matrix ist eine Logo zur zweiten Abletzung im Mehrlebenden. Ja, ein Wiedernahmenschwungbrief ist eine Matrix sein und die geht eigentlich ganz einfach, ja, wir laden einfach nochmal ab, ja, macht ja irgendwie Sinn.", "start": 1586.0, "end": 1607.0}, {"text": "  Ja, wir laden halt einmal ab, dann haben wir die erste Abletzung, dann haben wir nochmal ab, dann haben wir die zweite Abletzung.", "start": 1608.0, "end": 1638.0}, {"text": "Ja, das sind unsere erste Abletzung, natuerlich nicht eine Funktion, sondern wir haben natuerlich irgendwie  eine N-Parteile-Abletzung, ja, in unserem Valianten, ja, und hier diese N-Parteile-Abletzung wollen wir jetzt nochmal ableiten, ja, noch hier diese Variabeln, also haben wir dann N mal N, also N-Quadra-Abletzungen, ja, und mit diesem wollen wir dann eine Matrix bilden, ja, natuerlich ein N-Kurz-N-Matrix, ja, die sind dann wie folgt aus, die erste Matrix Hf von X ist definiert durch, wie man hier sieht, ja, und es faellt erst mit etwas ueber Bewettung aus, aber eigentlich sagen wir mal, sehen wir mal, ich", "start": 1638.0, "end": 1665.0}, {"text": " will die Diagonalen, sind wir immer abgelaedet nach den, das war doch fuer gleich eine Variable, also irgendwie die Ithi Diagonaleintrag, sind wir irgendwie abgelaedet nach Ithius 1, ja, was wir auch zusammen beobachten koennen, theoretisch ist das, wie hier irgendwie immer unseren Gradienten einfach haben, der nochmal abgelaedet wurde nach der Spalte, also hier zum Beispiel nach, nach 1, dann hier nach, nach 2, hier nach N, ruecken wir jetzt aussehen, ja, so was wie Ithi Spalte.", "start": 1669.0, "end": 1683.0}, {"text": "  Ist einfach der Gradient abgelaedet nach XI plus 1, ja, das werde ich nicht vorkommen, wenn ich es mal bekomme, korrekt ist sozusagen, ja, das ist so eine Idee,  um es sich auch aus einfach sagen koennen, ist der Eintrag halt, also irgendwie Ithi, wenn wir Ithi haben, dann leiten wir einfach nach Ithius 1, Jthius 1 ab, ja, also hier,", "start": 1683.0, "end": 1712.0}, {"text": " 1, 2, dann gehen wir hoch bis 1, N, ja, und hier haben wir dann 2, 1, 2, 2, 2, N, und dann unten dann wie N, N, ja, und wie vorher auch, ja, es ist eigentlich nicht, nicht viel mehr als neues dabei, ja, wenn man normal abgelaedet kann, in einer Dimension, dann kann man halt bei Zerbplaenen, dann kann man die Gradienten aufstellen, dann kann man auch die Smass aufstellen, ja, so,", "start": 1713.0, "end": 1717.0}, {"text": " wenn man einmal das Konzept verstanden hat, dann ist das nicht viel mehr auf einmal erleichtert muss.", "start": 1718.0, "end": 1740.0}, {"text": " Was wir jetzt auslangen koennen, ist die Hessen-Malchischung schreibt, wie die zweite Abgleitung im Eindimensionen die Kruemung der Funktion, ja, und zwar haben wir die Kruemung von jeder Variabe in jede Richtung,  also auch sozusagen, sondern koennen wir das einfach in Quadrat haben, also die haben wir irgendwie von der ersten Variabe in die erste Richtung, dann von der zweiten Variabe in die erste Richtung und so weiter, ja, also es ist auch eine Logo zu", "start": 1741.0, "end": 1753.0}, {"text": " zweiten Abgleitung in den Einwitzenden an, ja, am besten berechnen dafuer wieder auf ein Beispiel, ja, wir haben ja auch unsere Funktion von vorher, hier kennen wir den Gradienten schon, also wir haben schon gegeben, dass die Abgleitung nach X,", "start": 1753.0, "end": 1782.0}, {"text": " dann gleich 6X plus 4 Y ist und die Ableitung nach Y ist gleich 4X, jetzt wollen wir noch die restlichen Patienten ableihen berechnen, verbleiten wir erst mal die beiden nach X nochmal ab und noch Y sind die Ablettraege, ja, wir kriegen natuerlich hier 6 weg und dann faellt die Skalizanz weg, also hier bei nur 6, ja, und hier faellt alles weg, weil natuerlich kein Y verstanden hat, das heisst, hier bin ich noch, ja, und dann haben wir noch unsere letzte beiden Eintraege, die nicht diagonal Eintraege, ja, was wir jetzt machen,", "start": 1783.0, "end": 1813.0}, {"text": " wenn wir das 4 raus bekommen, ist vielleicht noch Y, also faellt das weg und hier das Y, also kriegen wir 4, aber wie noch X abweiten, dann wird das auch 1, dann kriegen wir hier 4, ja, und damit koennen wir jetzt die Hessemassrichts auf, damit wir alle Beate berechnet haben, ja, aber dann gibt es sich hier die Hessematrix 6,4,4,0, ja, und was bemerken wir jetzt, ja, wir merken irgendwie, dass die Symmetrische ist, ja, es ist auch kein Zufall, ja, also oberkommens ist das, Haia fuer Symmetrische, ja, es ist kein Zufall, es wird immer der Fall sein, ja, und das sagen wir einfach, die Rheinung ist einfach, die Rheinung ist einfach, ja, die Rheinung ist einfach, ja, die Rheinung ist einfach, ja, die Rheinung ist einfach, ja, die", "start": 1813.0, "end": 1822.48}, {"text": " Rheinung ist einfach, das ist kein Roller, also ob wir erst noch X 1 abweiten, dann noch X 2, der erste noch X 2 abweiten, dann noch X 1, dann kommen wir gleich wieder raus, ja, das ist die Erkenntnis da.", "start": 1828.32, "end": 1842.84}, {"text": "  So, jetzt koennen wir zur Optimierung im Menue und Sondalen, unserem eigentlichen Ziel, ja, muessen jetzt die Sachen, die wir vorutiniert haben, zusammentragen und dann koennen wir ungefaehr so vorgehen, wie wir es auch schon im Eintritt anerkennen, ja, also koennen jetzt Analog,", "start": 1843.0, "end": 1855.64}, {"text": " zum einen in den Sondalen verhalten, Optimum bestimmen, ja, das wir gegeben haben ist eine, melde mir eine Funktion, also F vom R auch R nach R, und das naechste wollen wir irgendwie die erste Abteilung bestimmen, also bestimmen wir jetzt den Gradienten von der Funktion.", "start": 1856.24, "end": 1864.32}, {"text": "  Was wir tun ist, wir setzen den Gradienten wie extra 0 Wektor, ja, hier koennen wir so vergleichen, was irgendwie, als erstes Abteilung der X 0 ist,  jetzt koennen wir ja schon aus dem Einloesen an, was wir jetzt natuerlich machen muessen, ist, wir muessen weiterarbeiten bestimmen, setzen wir uns die Hesse Matrix,", "start": 1864.48, "end": 1883.8799999999999}, {"text": " und was wir jetzt tun ist, wir ueberpriefen ihre Definitivitaet, ja, sonst haben wir irgendwie geguckt, ist die Groesse der keine Null, die Abteilung, jetzt haben wir natuerlich ein einzelnes Skalar,  und zwar in der einzelnen Loesungsstellen X 7 6 N, die halt unseren Nullstellen unserer Abteilungen sind, ja,", "start": 1883.8799999999999, "end": 1898.6}, {"text": " und was wir jetzt sagen koennen, wenn unsere Hesse Matrix negativ definit ist, so handelt sich mein lokales Maximum von der Funktion, ja, wir koennen vergleichen mit  zweiter Abteilung kleiner Null, wenn es positiv definit ist, dann analogt da zu einem lokales Minimum, und wenn es indifinit ist, dann ist es ein Satelpunkt, ja, was hier wichtig zu sagen ist, ist, dass", "start": 1900.04, "end": 1919.0400000000002}, {"text": " keine notwendigen, sondern nur Hinrechnendedingungen sind, ja, also wir koennen es wie vorstellen, also H von  HPD  impliziert lokales extremer oder sowas, aber jetzt hier Minimum, ja, aber es ist nicht keine Beinuebung, also es ist nicht genau dann, wenn,  und das ist meine Implikation, ist wichtig, jetzt werden wir auch gleich an einem Beispiel sehen, die andere Richtung ist auch", "start": 1921.24, "end": 1951.24}, {"text": " ja, nur eine Implikation, denn es kann auch sein, dass die Hesse Matrix nicht PD ist, aber es trotzdem lokales Minimum ist,  wenn wir natuerlich so vorstellen, wie eine Funktion F von X Y,  einfach nur X hoch 4 oder sowas, ja, dann wissen wir natuerlich, das Optimum ist bei", "start": 1951.64, "end": 1976.04}, {"text": " 0, 0, ja, ein bisschen ja X hoch 4, wird immer positiv sein, aber halt, da kann es werden, dann kann es 0, ja, unsere Hesse Matrix wird  endlich so aussehen, koennen Sie auch gerne ueberpruefen, wir haben uns aus 12, X Quadrat, 0, 0, 0, ja, wenn wir jetzt den Optimumpunkt einsetzen,", "start": 1976.04, "end": 1995.24}, {"text": " 0, dann kommt hier natuerlich 0 raus, und diese Matrix ist die 0 Matrix und nicht positiv, definit, aber es ist trotzdem unser Optimum  und sogar unser gewales Optimum, ja, darf uns jetzt aufpassen,  ja, wir haben jetzt hier dieses Beispiel, ja, unsere Funktion ist X Quadrat plus Y Quadrat, ja, so irgendwie eine Parabel in 2 Dimensionen", "start": 1995.24, "end": 2020.44}, {"text": " koennen wir sich vorstellen, so wenn wir den Gradienten berechnen, ja, also natuerlich relativ leicht, wir beleiten hier nach X,  also koennen wir irgendwie 2X, das faellt weg, ja, und dann an der Look dazu kaemen wir halt 2Y und X faellt weg,  also koennen wir jetzt hier 2X, 2Y, also wie jetzt hier geschrieben, mit 2X plus 0Y und 0X plus 2Y,", "start": 2020.44, "end": 2040.44}, {"text": " irgendwie so klar sind, dass das halt auch in der Gleichung sind eigentlich, ja, jetzt koennen wir den unbekannten Weg,  dann koennen wir ein paar Meter X Y hier rausziehen und dann koennen wir damals einen LGS loesen,  ja, und zwar das folgende hier und zwar einfach 2 0 2 mal X Y ist gleich der 0 Wektor,  das ist natuerlich Trivia zu loesen, wir sehen direkt, unsere Loesung ist 0 0, ja,", "start": 2040.64, "end": 2061.64}, {"text": " das ist irgendwie auch intuitiv, wenn wir denken, dass es irgendwie eine Parabel ist, also wird ja 0 Punkt,  oder der Minimumspunkt auch bei 0 liegen, ja,  dann koennen wir auch die ersten Matrix berechnen, das ist in diesem Fall auch 0 0 2,  ja, wenn wir 2X nach X ableiten, dann gehen wir einfach 2 raus und genauso bei 2Y,", "start": 2061.64, "end": 2083.8399999999997}, {"text": " wenn wir halt 2X nach Y ableiten, dann haben wir natuerlich kein Y in dem Term, also kommt nur raus.", "start": 2083.8399999999997, "end": 2101.04}, {"text": " Also das ist unsere erste Matrix, das wir hier sehen koennen, die ist immer positiv definiert,  also da koennen wir gar nicht, ich habe ja keine Abhaengigkeit von X oder Y,  also koennen wir jetzt sagen, die ist immer positiv definiert, also auf definitiv der Punkt von unserem Optimum,  also geht das, ja, aber es ist eindeutig, dass es nicht notwendig ist,", "start": 2101.04, "end": 2105.04}, {"text": " also das impliziert nicht direkt, dass es ein Optimum ist, sondern nur andersherum,  wenn wir Optimum haben, dann wird es positiv definiert sein, andersherum nicht.", "start": 2105.04, "end": 2125.24}, {"text": " Ja, was ist jetzt unser Problem? Wahrscheinlich ist es nicht so schwer,  unser grosses Problem ist, dass wir das nur machen koennen,  das ist unser LGS, ja, wir haben ja kein LGS, ja, ein Linears-Gleichungssystem,  ja, und die wird linear sein, wenn die Ableitung von F linear ist,  weil wir das nur unsere Patient-Ableitung drinstehen haben.", "start": 2125.24, "end": 2134.24}, {"text": " Es wird aber fuer jede Funktion, die zu sagen, ein Grad,  dann fuer die Zeichen ja, groesser 3 hat, nicht passieren,  wenn wir 2,4 Betrachten, die Funktion G von XY ist X\u00b2Y,  ja, dann ist natuerlich die Ableitung nach Y gegen X\u00b2, und das ist nicht linear.  Ja, hier ist wichtig, nichts verwirrt zu sein mit dem, was wir in Interposition hatten,  das war nicht irgendwie missverstaendlich, missverstaendlich.", "start": 2134.24, "end": 2153.4399999999996}, {"text": "  Da hatten wir zwar auch X\u00b2 und so, aber wir haben die sozusagen  vorherbrechen und dann jetzt konstant ein Ligars-Gleichungssystem geschrieben.  Ja, hier haben wir tatsaechlich die unbekannte X\u00b2,  also das ist nicht mehr linear.", "start": 2153.4399999999996, "end": 2168.4399999999996}, {"text": " Ja, ich will auch im Eigenbau mit das Nicht-Defall sein,  also brauchen wir andere Methoden, also sozusagen NLGS loesen wird  fuer die meisten Funktionen nicht moeglich sein,  unter anderem weil wir irgendwie das LGS jetzt ausstellen muessen und so was.", "start": 2168.4399999999996, "end": 2180.64}, {"text": " Ja, deswegen wird unser Ansatz dann sein,  der Valiantenabstieg in dem naechsten Video kommt  und damit kann man das dann auch fuer quasi beliebige Funktionen loesen.", "start": 2180.64, "end": 2192.64}, {"text": " Ja, ob man sozusagen ein Global Option findet,  wird dann trotzdem noch ein Problem sein,  aber wir koennen auf jeden Fall dann optimal finden  mit diesem Ansatz auch fuer nicht-deniare Funktionen  oder Funktionen, deren Abwaelter nicht deniarens.", "start": null, "end": 2192.64}]}]