[{"lecture": "25797_28_course_video", "Timestamps": [{"text": "  Es geht um ein Ueberblick der Semesterinhalte dieses Kurses.  Das Modul ist auf sechs Kapiten aufgeteilt.  Die kommenden Wochen beschaeftigen wir uns mit Kleidkommazalen  und danach fangen wir mit der Loesung linearer Gleichungssysteme an.  Ich moechte in diesem Ueberblick nur grobskizzieren, worum es alles geht,  die wichtigen Begriffe erwaehnen und wichtigen Konzepte.", "start": 0.0, "end": 41.0}, {"text": "  Bei der Loesung lineare Gleichungssysteme befestigen wir uns zunaechst mit der Gaussillimination,  die wir auch selber implementieren.  Stellen danach fest, dass Gauss fuer unsere Anwendung nicht ausreicht,  da wir es mit einem sogenannten ueberbestimmten System zu tun haben.  Dafuer nehmen wir die Ausgleichsrechnung zur Hilfe  und eng damit zusammenhaengend ist die Scholeskie-Zerlegung.", "start": 41.0, "end": 69.0}, {"text": "  Das Beispiel ist Computertomographie.  Das Problem lautet wie folgt, gegeben ein Gegenstand,  wie koennen wir das Material, die Dichte des inneren Materials herausfinden.", "start": 69.0, "end": 101.0}, {"text": " In der Computertomographie schickt man Strahlen durch das Material  und indem man die Abschwaechung der Strahlen dann misst,  kann man eine grobe Abschaetzung machen von der Dichte des Materials  und grob eigentlich, dass diese Abschaetzung schon ganz fein aussehen.  Das ist dann zum Beispiel unser urspruengliches Material,  das Material, das wir zu Messen versuchen.", "start": 101.0, "end": 116.0}, {"text": "  Und dann, nicht dies hier waere, das Ergebnis unseres Verfahrens,  dies bestimmen wir, indem wir die Loesung einer Milliarden-Gleichungssystem suchen.  Je hoeher die Aufloesung, desto besser unsere Abschaetzung.  Im dritten Kapitel geht es um die Hauptkomponente-Analyse,  also Principle Component Analysis und die Singulaerwertserlegung.", "start": 116.0, "end": 153.0}, {"text": " Bei der Hauptkomponenten-Analyse handelt es sich im Groben darum,  eine Dimension-Reduktion zu machen.  Wir geben einen Datensatz, wie koennen wir die Daten in unserem Datensatz  komprimierter darstellen, auf eine andere Art und Weise repraesentieren,  wobei die wesentlichen Informationen behalten bleiben  und das ueberfluessige einfach geloescht oder weggelassen werden kann.", "start": 153.0, "end": 179.0}, {"text": "  Dafuer brauchen wir Eigenvektoren und um Eigenvektoren zu bestimmen,  ist die Singulaerwertserlegung hilfreich.", "start": 179.0, "end": 216.0}, {"text": " Zur Anwendung Eigenfaces, dies geht auf ein Pippe, der vom 1987 zurueck,  in dem es um Gesichtserkennung geht, also gegeben einen Datenbank,  von 100 Bildern, wir versuchen, wenn man uns ein neues Bild gibt,  um zu sagen, existiert dieses Bild oder dieser Person in unsere Datenbank  im Grunde zu erkennen, diese Person zu erkennen.", "start": 216.0, "end": 228.0}, {"text": " Und das machen wir eben durch diese Datenkomprimierung,  indem wir die Gesichter in unserer Datenbank in einer kleineren Dimension rekonstruieren,  koennen wir dann auch die neuen Gesichter in dieser kleineren Dimension auch rekonstruieren  und einen Vergleich in dieser komprimierten Darstellung durchfuehren,  was viel effizienter ist.", "start": 228.0, "end": 245.0}, {"text": "  Das lautet natuerlich jetzt alles vielleicht ein bisschen zu abstrakt,  aber ich moechte euch zumindest zeigen, was fuer Erfolg das bringen kann.  Also hier ein Query Image, also ein zuvor nicht gesehenes Bild,  wir rekonstruieren unser Bild in diesen komprimierten Raum  und vermuten, dass es dieses Bild hier in unsere Datenbank entspricht  und das scheint auch uns gelungen zu sein.", "start": 245.0, "end": 283.0}, {"text": "  Das naechste Beispiel ist uns misslungen, aber ich moechte euch trotzdem was Schoenes hier zeigen,  das waere dann ein erfolgreiches Beispiel, das Query Image,  rekonstruiertes Image, dann die richtig identifizierte Person  und es scheint mit der Mehrheit der Exemplaren geklappt zu haben.  Cool.", "start": 283.0, "end": 315.0}, {"text": " Kapitel 4, da beschaeftigen wir uns mit der Interpolation global,  sowohl global als auch lokal, da sind die wichtigen Verfahren,  die wir dabei kennenlernen, der Grunge und Splines  und wir machen das mit dem Beispiel von Strichfiguren,  und zwar Animationen dieser Figuren.", "start": 315.0, "end": 342.0}, {"text": " Die Idee ist, dass, um eine Animation zu machen,  koennen wir 24 Bilder pro Sekunde erstellen und dann sie alle nacheinander zeigen,  aber das ist ein bisschen aufwendig, wir koennen auch sagen,  ich erstelle ein Bild nur einmal pro Sekunde zum Beispiel  und dann zwischen einem Bild bei Sekunde A und einem Bild in Sekunde B", "start": 342.0, "end": 363.0}, {"text": " versuche ich die Bewegung zwischen den beiden angegebenen Positionen zu interpolieren,  sodass ich dann 24 Frames nicht selber modellieren muss,  nur einmal pro Sekunde und dann sie bei einer Glatte Art und Weise verbinden.  Wir koennen uns das dann anschauen mit dem Programm,  das wir dafuer implementieren werden,  und hier Cubic Animation.", "start": 363.0, "end": 403.0}, {"text": " Also dann ist das unsere animierte Strichfigur,  diese Kurven entsprechen dann den einzelnen Gliedern  und wir geben nur, sagen wir zum Beispiel,  an dieser Stelle und an dieser Stelle feste Positionen an,  der Rest wird dann interpoliert und fuer eine schoene Glattenbewegung.", "start": 403.0, "end": 430.0}, {"text": " Kapitel 5, da beschaeftigen wir uns mit der Fourier-Transformation,  und zwar der diskreten Fourier-Transformation,  mit dem Zweck Signalverarbeitung.  Dieses Zitat hier, die schnelle Fourier-Transformation,  die wir hier auch in dem Kurs kennenlernen werden,  die Fast Fourier-Transformation,  ist Herrn Gilbert Strang von MIT,  nach der wichtigste numerische Algorithmus unserer Generation.", "start": 431.0, "end": 456.0}, {"text": "  Und mit der Fourier-Transformation koennen wir Frequenzen manipulieren,  unter anderem, und das benutzen wir fuer akustische Signalverarbeitung.  Wir wollen insbesondere ein Filter auf ein Signal,  also auf eine Aufnahme, eine Aufzeichnung anwenden  und dabei nur die tiefen Frequenzen behalten.", "start": 457.0, "end": 484.0}, {"text": " Deswegen heisst es Tiefpass,  wir lassen die tieferen Frequenzen passen, passieren  und loeschen hoehere Frequenzen,  um das ein bisschen naeher zu zeigen.  Hier eine Aufzeichnung von...  Danke Express Dictate, das ist eine urspruengliche,  also originelle Aufzeichnung,  und dann eine gefilterte Aufzeichnung  mit Hilfe der Fourier-Transformation.", "start": 484.0, "end": 522.0}, {"text": " Und vielleicht noch ein Beispiel von einer Geige  und eine gefilterte Geige.  Sweet.  Das letzte Kapitel, da geht es um Optimierung  und mit der Optimierung haengt 0-Stellenbestimmung,  haengt zusammen,  dafuer lernen wir das Newton-Verfahren Canon  zur 0-Stellenbestimmung  und mithilfe dieses Verfahrens  koennen wir sogenannte Newton-Fraktale generieren,  das sind diese huebschen Bilder.", "start": 526.0, "end": 555.0}, {"text": "  Und dass die andere Anwendung waere dann,  oder das andere Verfahren,  das gradienten Abstiegsverfahren,  von dem manche von euch vielleicht schon mal gehoert haben  und das wird naemlich sehr oft  grundlegend in manchen Machine-Learning-Verfahren  bei einem tiefen neuronalen Netzwerk,  ist das, wie man Optimierung macht.", "start": 555.0, "end": 590.0}, {"text": " Und wir benutzen es fuer eine Anwendung von Minimalflaechen,  in der wir die gesamte Flaeche  eines geometrischen Objekts minimieren wollen.  Das ist das urspruengliche Objekt  und dann nach ein paar Iterationen  minimieren wir die gesamte Flaeche,  bis es dann so aussieht.  Hier noch ein Beispiel dafuer, in diesem Cube.  Das ist das Ergebnis  von mehreren Iterationen des gradienten Abstiegsverfahrens.", "start": 590.0, "end": 627.0}, {"text": "  Das ist das hier alles tolles machen in diesem Kurs.  Vielen Dank.", "start": 627.0, "end": 629.0}]}]