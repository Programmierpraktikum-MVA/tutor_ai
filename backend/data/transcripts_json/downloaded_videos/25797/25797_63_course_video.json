[{"lecture": "25797_63_course_video", "Timestamps": [{"text": "  Jetzt wollen wir uns mit der Singulaerwaertszidigung beschaeftigen.  Haeufig kuerzen wir die Singulaerwaertszidigung mit SVD ab.  Das steht fuer Singular Value Decomposition.  Hier sehen wir die Singulaerwaertszidigung einer recht eckigen Matrix A mit n Groesse m.  A wird in die Matrizen u, sigma und v transponiert zerlegt.  u ist eine Rotationsmatrix mit orthogonalen Spalten.", "start": 0.0, "end": 30.76}, {"text": "  Die Spalten von u sind die linken Singularvektoren.  Sigma ist eine skalierende Matrix und auf der Diagonalen von sigma stehen die Singularwaerter.  Der Rest sind Nullen.  Die letzte Matrix ist v transponiert.  Sie hat auch orthogonal Spalten und in ihren Zeilen stehen die rechten Singularvektoren.  Un, v, t sind beides orthogonalen Matrizen.", "start": 31.76, "end": 60.04}, {"text": "  Das Wichtige an der SVD ist, dass wir mit ihr jede beliebige Matrix in eine Rotationsmatrix,  eine skalierende Matrix und noch eine Rotationsmatrix zerlegen koennen.  Die SVD fuer eine recht eckige Matrix mit n, m hat etwas andere Dimensionen, ist sonst aber gleich  und ihr findet sie im Skript.  Auf diesem Bild sieht ihr reduzierte Form der SVD und die vollstaendige.", "start": 60.04, "end": 85.96}, {"text": "  In der vollstaendigen Form der SVD ist Sigma eine recht eckige Matrix und um oberen Teil  stehen auf der Diagonalen die Singularwaerter.  Diese sind in dem Bild als Liederstreifen dargestellt.  Der untere Teil der Matrix enthaelt nur Nullen und wenn wu mit sigma multiplizieren, entsteht  eine Reihe von Nullen, die fuer die weiteren Skalaprodukte keine Rolle spielen.", "start": 85.96, "end": 109.64}, {"text": "  Deshalb kann man die Nullen Matrix von Sigma entfernen und enthaelt so die reduzierte Form.  Die Singularwaerterlegung kann man auch mit NumPy berechnen.  Dafuer rufen wir numpy.line.svd mit unserer Matrix auf.  Als weitere Parameter koennen wir angeben, ob wir die volle oder die reduzierte Form haben wollen.  Die Funktion gibt uns ein Trippel mit drei Arrays zurueck.", "start": 110.6, "end": 141.64000000000001}, {"text": "  Im ersten steht u und im zweiten die Diagonalelemente von Sigma und im dritten steht vt.  Problematisch bei der Berechnung der SVD ist, dass sie sehr schnell sehr rechend aufwendig ist.  Hier sehen wir wie lange es dauert die SVD von zufaelligen Matritzen mit steigender Groesse  zu berechnen und ihr seht, dass es sehr schnell ansteigt.", "start": 144.36, "end": 165.4}, {"text": "  Jetzt wollen wir noch einmal ueber den Zusammenhang zwischen der Singularwaerterlegung  und der Eigenzerlegung reden.  Wenn wir von einer Matrix die SVD bilden und den AT einsetzen,  dann wird vtv in der Mitte des Terms zur Identitaet, da v autogonal ist.  Uebrig bleibt u, Sigma Quadrat und ut.", "start": 165.4, "end": 193.56}, {"text": " Wenn wir diesen Term mit der Eigenzerlelegung vergleichen, sehen wir, dass die Schwindel des  Verlegunges vergleichen, sehen wir, dass die Spalten von u, also die linken Singularvektoren,  die Eigenvektoren von AT enthalten.  Aehnlich ist es fuer ATA, nur dass hier die Spalten von v, also die rechten Singularvektoren,  die Eigenvektoren von ATA enthalten.", "start": 193.56, "end": 214.6}, {"text": "  Die Nicht-Null-Elemente von Sigma sind die Wurzeln von den Nicht-Null-Eigenwerten von ATA und AT.  Das waren die Grundlagen zur Singularwaerterlegung und in den naechsten Videos sehen wir verschiedene Anwendungen.", "start": 214.6, "end": 222.92}]}]