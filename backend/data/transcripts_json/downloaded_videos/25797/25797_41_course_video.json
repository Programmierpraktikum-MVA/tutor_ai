[{"lecture": "25797_41_course_video", "Timestamps": [{"text": "  Es geht weiter mit Optimierung. Wir machen jetzt wirklich Optimierung.  Wir beschaeftigen uns mit der Frage, wie man eine Funktion optimiert.  Noch mal zur Erinnerung, was wir wollen ist. Wir haben irgendeine Funktion F.  Wir gucken uns vor allen Dingen Funktionen an, die von dem R hoch N abbilden in den R.  Also eine Funktion von mehreren Veraenderlichen, die einen Wert annimmt.", "start": 0.0, "end": 53.5}, {"text": "  Wir suchen Orte in diesem Parameterraum, in denen diese Funktion moeglichst klein oder gross wird.  Wir schraenken uns ein auf die Frage, wo die Funktion moeglichst klein wird.  Weil offenbar gilt ein Maximum von der Funktion F ist das gleiche wie ein Minimum von der Funktion minus F.  Es genuegt sich einen der beiden Faelle anzuschauen und wir schauen uns nur den Fall von Minimum an.", "start": 54.5, "end": 93.5}, {"text": "  Was ist eigentlich ein Minimum? Dazu gibt es zunaechst einmal den Begriff globales Minimum.  Auch das schraenken wir ein. Wir interessieren uns nur fuer ein globales Minimum in irgendeinem Gebiet.  Das nennen wir Omega und Omega ist eine Teilmenge aus dem R hoch N.  Entweder der ganze R hoch N oder irgendein Gebiet aus dem R hoch N.  Und X-Sternchen ist ein solches globales Minimum, wenn gilt.", "start": 94.5, "end": 134.5}, {"text": "  Globales Minimum X-Sternchen aus Omega.  Und das hat die Eigenschaft, dass eben F an der Stelle X-Stern kleiner oder gleich ist als F an irgendeiner Stelle X.  Und X kommt aus Omega.  Ist jetzt irgendwie nicht weiter ueberraschend.  Okay, das ist das globale Minimum. Das globale Minimum ist offenbar nicht immer eindeutig.  Ja, es kann Funktionen geben.  Die sehen vielleicht so aus.", "start": 135.5, "end": 178.5}, {"text": "  Was weiss ich? Und die haetten dann hier drei Orte, an denen nimmt die Funktion ihren kleinsten Wert an.  Aber es gibt eben drei Stueck davon.  Ja, es muss nicht einen ausgezeichneten Ort geben, an dem die Funktion ihren kleinsten Wert annimmt.  Wir machen es uns leicht fuer heute und sagen, wir gehen mal davon aus, dass das normalerweise nur einer ist.", "start": 178.5, "end": 197.5}, {"text": "  Diese Charakterisierung zu erreichen ist unglaublich schwierig.  Deswegen konzentriert man sich typischerweise auf den Begriff des lokalen Minimums.  Also lokales Minimum.  Und das lokale Minimum, das Charakterisieren wir wie folgt.  Wir sagen, es existiert eine Zahl Delta, groesser als 0.  Und dann ist F an der Stelle X-Stern kleiner als,  ja, machen wir kleiner, als F an der Stelle X.", "start": 197.5, "end": 242.5}, {"text": "  Und es muss gelten, X und X-Stern sind nicht weiter als Delta auseinander.  Ja, machen wir hier, ein gleiches Signal.  Das heisst, es gibt eine kleine Umgebung der Groesse Delta.  Und wir sehen, hier diese Funktion hat mindestens mal drei lokale Minimum,  hier vielleicht auch noch eins, hier vielleicht auch noch eins.  Nehmen wir mal das hier.  Es gibt eine kleine Umgebung Delta.", "start": 244.5, "end": 266.5}, {"text": "  Und in dieser kleinen Umgebung Delta ist dieser Wert der Kleinste von allen.  Ja, das ist auch nicht.  Logisch, so.  Und jetzt ist die Frage, wie finden wir solche lokalen Minimum?  Zwei Fragen kommen jetzt auf.  Wir muessen heute uebrigens, wir muessen heute, wir muessen heute,  wir muessen die ganze Menge Vorueberlegungen machen, bevor wir aber irgendeinem Algorithmus ankommen.", "start": 266.5, "end": 287.5}, {"text": "  Jetzt kann man zwei Fragen stellen.  Erstens, wie charakterisieren wir lokale Minima?  Zweitens, unter welchen Umstaenden ist ein lokales Minimum auch ein Minimum in diesem Gebiet Omega?  Ja.  Und, okay, also das sind die zwei, die wir jetzt haben,  die sind die beiden, die wir jetzt haben,  und, okay, also das sind die zwei Bedingungen.", "start": 287.5, "end": 313.5}, {"text": "  Wir erinnern uns ein bisschen aus der eindimensionalen Analysis,  dass dieses lokale Minimum, das ist sozusagen das, was wir mitnehmen,  da wussten wir, na, die Dinger lassen sich charakterisieren,  indem wir sagen, wenn die Funktion stetig differenzierbar ist,  sagen wir mal zweimal stetig differenzierbar,  wir machen es uns leicht, wir nehmen an die Funktion ist zweimal stetig differenzierbar,", "start": 313.5, "end": 334.5}, {"text": " dann ist ein Punkt, ein lokales Minimum,  wenn die Funktion an der Stelle Ableitung 0 hat und zweite Ableitung groesser 0 ist.  Ja, und damit haben wir das vollstaendig charakterisiert.", "start": 334.5, "end": 364.5}, {"text": " Und die Frage ist jetzt,  erstens, ich sag mal zweitens,  wie funktioniert diese Charakterisierung,  wenn wir nicht mehr Funktionen haben, die von R nach R abbilden,  sondern Funktionen, die vom R auch N nach R abbilden,  es wird leider etwas komplizierter.", "start": 364.5, "end": 384.5}, {"text": " Und zweitens, wie kommen wir fuer ein gewisses Gebiet von hier nach hier?  Und der zentrale Begriff, um von hier nach hier zu kommen,  ist Konvexitaet.  Also, wenn F Konvex ist in diesem Gebiet Omega,  dann ist das lokale Minimum auch ein globales Minimum.  Und die Frage ist jetzt eben, was heisst das eigentlich Konvex?  Ja?  Also.  Typischerweise macht man das wie folgt.", "start": 384.5, "end": 448.5}, {"text": "  Wir sagen, eine Funktion F ist Konvex.  F ist Konvex, wenn gilt,  wir nehmen uns irgendwelche zwei Orte in der Funktion,  jetzt muss ich mal gucken, wie ich sie hier genannt habe.  X und Y, okay.  Also, wir nehmen uns irgendwelche zwei Orte X und Y aus dem R hoch N.", "start": 449.5, "end": 514.5}, {"text": " Und wir haetten gerne,  dass F an der Stelle 1 minus Lambda mal X plus Lambda mal Y,  in Beziehung steht zu den Werten F an der Stelle X  und F an der Stelle Y.  Ja, ich mache mein Bild.  Also, wir haben irgendeine Funktion.  Und die ist Konvex.  Und was heisst das?  Ich kann mir irgendwelche zwei Orte nehmen.", "start": 514.5, "end": 557.5}, {"text": " Und die Strecke, die die beiden Punkte auf der Funktion verbindet,  liegt oberhalb der Funktion.  Ja, das ist die Aussage.  Das heisst, wenn ich mir jetzt hier irgendein Ort nehme, den hier zum Beispiel,  dann ist der Funktionswert an dieser Stelle kleiner fuer Konvex  und kleiner gleich fuer Konvex und kleiner fuer Strengkonvex als dieser Ort.", "start": 557.5, "end": 585.5}, {"text": "  Ja, also, der Funktionswert, den ich hier hingeschrieben habe,  ist genau der.  Also, der Punkt, den ich da eben nochmal ausgemalt habe, ist der hier.  Und das soll jetzt also sein kleiner.  Und gleich lassen wir auch zu.  Dieser Ort soll kleiner sein als der hier.", "start": 585.5, "end": 622.5}, {"text": " Ja, und das ist also offenbar einfach,  und jetzt habe ich mich hier nicht genug Platz gelassen,  das ist 1 minus lambda mal f von x plus lambda mal f von y.  Ja, das ist die Definition von Konvexitaet.  Und die geht in allen, die geht auch fuer Funktionen mehrer veraenderliche.  Ja, ich nehme irgendwelche zwei Punkte auf dieser Funktion.", "start": 622.5, "end": 635.5}, {"text": "  Das kann ich auch machen, wenn die Funktion ueber dem R2 definiert ist.  Wenn ich hier so eine Funktion habe, kann ich mir hier ein Ort nehmen und da ein Ort.  Und die Verbindungsstrecke gibt mir Punkte, deren Werte alle groesser sind als das Ding hier.  Und die Beobachtung ist, wenn eine Funktion Konvex ist,  dann ist das lokale Minimum in dem konvexen Gebiet auch ein globales Minimum.", "start": 635.5, "end": 665.5}, {"text": "  Ja, oder anders gesagt, in so einem konvexen Gebiet gibt es nur ein lokales Minimum.  Ja, das ist die Idee.", "start": 666.5, "end": 695.5}, {"text": " Und die Frage ist jetzt fuer uns, fuer die Praxis so ein bisschen,  wie kann man konvexe Funktionen und konvexe Gebiete charakterisieren?  Also wie kann ich herausfinden, ob irgendwas konvex ist?  Ja, und da gibt es so ein paar Gebiete, also wann ist Omega-konvex?  Ich mache einfach mal ein paar Beispiele.  Zum Beispiel erstens Omega gleich R hoch N ist Konvex.", "start": 695.5, "end": 707.5}, {"text": "  Ja, das sind jetzt Beispiele fuer konvexe Gebiete.  Zweitens vielleicht, wenn ich sage, Omega ist so definiert,  dann sind X die erfuellen AX gleich B, das ist Konvex.  Ja, also der R hoch N ist Konvex, Linieare Unterraeume sind Konvex.  Und dann ganz wichtig, Halbraeume sind Konvex.  Was ist ein Halbraum?  Das sind X die erfuellen A T mal X ist kleiner gleich B.", "start": 710.5, "end": 759.5}, {"text": "  Ja, also ich nehme irgendeine Ebene im Raum und die eine Seite von der Ebene ist Konvex.  Und dann kann man jetzt aus diesen Dingern was bauen,  und wenn man sich merkt, dass der Schnitt von zwei Konvexenmengen,  also Omega und Omega-Strich sind beide Konvex,  dann ist auch der Schnitt von Omega und Omega-Strich-Konvex.", "start": 759.5, "end": 791.5}, {"text": " Ja, das heisst, insbesondere diese drei Sachen zusammen ergeben eben,  wenn ich einen Halbraum nehme, wenn ich vom R N so einen halben Raum abschneide  und dann nochmal halben Raum abschneide, nochmal halben Raum abschneide,  dann bleibt irgendwas uebrig, was Konvex ist.  All diese Dinge sind Konvex.", "start": 791.5, "end": 810.5}, {"text": " Ja, das sind einfach so ein paar Grundregeln und man stellt sich dann oft die Frage,  ist die Funktion, die ich hier behandle in einem gewissen Gebiet Konvex,  wenn ja, ist das die ideale Voraussetzung fuer Minimierung,  weil ich dann weiss, wenn ich ein lokales Minimum in dem Konvexengebiet finde,  habe ich das globale Minimum gefunden.", "start": 810.5, "end": 826.5}, {"text": "  Was ich auch weiss, ist, wenn ich in jedem Schritt von einem Punkt aus  den Funktionswert verkleinere, dann ist das ein sinnvoller Schritt.  Ja, und das ist ein Schritt, der mich dem Minimum naeher bringt.  Und wenn es keinen solchen Schritt mehr gibt, habe ich das Minimum gefunden  und wenn ich nach oben laufe wieder, habe ich auf jeden Fall irgendwas falsch gemacht.", "start": 826.5, "end": 847.5}, {"text": "  Ja, und okay. Also die Situation, die beste Situation,  die mir begegnen kann, um Funktionen zu minimieren,  ist, dass das Gebiet Konvex ist.  Und manchmal hat man das, manchmal hat man das nicht.  So.", "start": 847.5, "end": 879.5}, {"text": " Jetzt war die erste Frage,  also wie kommt man von lokal zu global  und da ist die Aussage, genau dann, wenn das Gebiet in dem Gebiet die Funktion Konvex ist,  komme ich von einem lokalen Minimum  und dann weiss ich, mein lokales Minimum ist ein globales Minimum.  Okay.", "start": 879.5, "end": 898.5}, {"text": " Zweiter Punkt war,  der zweite Punkt war,  wir wissen, lokales Minimum fuer Funktionen in einer Veraenderlichen  bedeutet, Ableitung an der Stelle x ist 0  und zweite Ableitung ist groesser 0  und die Frage ist, was bedeutet das fuer Funktionen in mehreren Veraenderlichen?  Und wir hatten damals letztes Mal diesen Begriff der patiellen Ableitung.", "start": 898.5, "end": 918.5}, {"text": " Ja, und was ist jetzt eine notwendige Bedingung,  dafuer, dass, also eine notwendige Bedingung,  dafuer, dass f ein lokales Minimum hat?  Und das ist jetzt offenbar so,  wenn ich mich entlang der Koordinatenachse x0 bewege  und ich bewege mich und die Funktion wird kleiner,  dann sollte ich mich weiter bewegen.", "start": 918.5, "end": 946.5}, {"text": " Wenn ich mich, wenn ich an einem Ort bin,  wo egal, ob ich jetzt weiter nach vorne laufe oder weiter zurueck laufe,  die Funktion immer groesser wird,  dann bin ich offenbar bezueglich dieser Achse x0 in einem Minimum.  Das heisst, notwendige Bedingung ist offenbar,  dass die patielle Ableitung von f nach x0, 1, 2, 3, 4 und so weiter,  die muss immer 0 sein.", "start": 946.5, "end": 970.5}, {"text": "  Also egal entlang welcher Koordinatenachse ich mich bewege,  es sollte so sein, dass die patielle Ableitung bezueglich dieser Richtung,  dieser Koordinatenachse 0 ist.  Das ist eine notwendige Bedingung.", "start": 970.5, "end": 1000.5}, {"text": " Jetzt koennte man noch fragen,  wie veraendert sich eigentlich die Funktion f,  wenn ich nicht entlang einer Koordinatenachse laufe,  sondern wenn ich entlang irgendeiner beliebigen Richtung,  sagen wir mal r laufe?  Wenn ich in einer Dimension mir eine Funktion anschaue,  dann gibt es nur Veraenderungen entlang dieser Achse.", "start": 1000.5, "end": 1013.5}, {"text": " Wenn ich mir eine Funktion anschaue, die ueber der Ebene definiert ist,  dann muss ich nicht entlang x0 laufen oder x1,  ich koennte auch irgendwie schraeg laufen.  Und ich koennte jetzt also fragen,  was passiert, wenn ich in Richtung r laufe?  Wie veraendert sich die Funktion,  wenn ich in Richtung r laufe?  Funktionen, ich lasse nur das von x weg,  wir sind an irgendeiner Stelle f von x.", "start": 1013.5, "end": 1040.5}, {"text": "  Und da ist jetzt die Frage, was ist das?  Wie veraendert sich die Funktion,  wenn ich in Richtung r laufe?  Und wir nutzen aus, das nutzen wir heute staendig aus,  das Ableiten eine lineare Operation ist.  Das heisst, wenn ich Richtung r laufe,  dann kann ich die Veraenderung der Funktion zusammenbauen  aus den verschiedenen Komponenten.  Das ist also r0 mal die Ableitung von f in Richtung x0.", "start": 1040.5, "end": 1079.5}, {"text": "  Und dann kommt einfach dazu die Veraenderung der Funktion,  die durch diese Komponente in Richtung x1 passiert.  Und dazu kommt die Veraenderung der Funktion,  jetzt habe ich hier das r2 vergessen, und so weiter.  Das heisst, die partiellen Ableitungen kann ich benutzen,  um mir zu ueberlegen, was passiert,  wenn ich in irgendeine Richtung laufe.", "start": 1079.5, "end": 1105.5}, {"text": "  Einfach, indem ich sage, naja, diese Richtung r setzt sich zusammen  aus irgendwelchen Komponenten entlang der Koordinatenachsen.  Und alles, was ich tun muss, ist aufwaddieren,  weil differenzierende Lineare Operation ist.  So, das kann ich auch anders schreiben.  Und das macht man auch typischerweise so.  Das ist also dieser Vektor r,  und der bildet ein Produkt mit einem Spaltenvektor.", "start": 1105.5, "end": 1135.5}, {"text": "  Und dieser Spaltenvektor, den schreibt man typischerweise so,  mit diesem Zeichen Nabla, das haben wahrscheinlich viele schon gesehen.  Und dieses Ding hier ist der Gradient von f.  Ja, also dieses Ding hier.  Ja, also es geht jetzt mal fuer einen Moment um Gradienten.  Also nochmal, in den allermeisten Faellen wird der Gradient  als Spaltenvektor verstanden, und so machen wir das auch.", "start": 1135.5, "end": 1178.5}, {"text": "  Also Gradient von f ist ein Spaltenvektor,  und dieser Spaltenvektor besteht offenbar aus den partiellen Ableitungen von f.  Das heisst, unsere notwendige Bedingung hier,  die koennen wir auch so schreiben, der Gradient von f muss 0 sein.  Das ist die notwendige Bedingung, und das Aequivalent dazu,  zu dieser einen dimensionalen Formulierung,  dass die Ableitung von f 0 sein muss.", "start": 1178.5, "end": 1210.5}, {"text": "  In mehreren Dimensionen heisst es dann, der Gradient von f muss 0 sein.  So, der Gradient von f ist aber noch aus anderen Gruenden interessant.  Der Gradient hat naemlich folgende interessante Eigenschaft.  Wir stellen uns mal folgende Frage.  Wir haben so eine Funktion, sagen wir ueber der Ebene.", "start": 1211.5, "end": 1248.5}, {"text": " Wir sind an irgendeiner Stelle, und wir fragen uns,  in welche Richtung muesste ich laufen,  damit die Funktion besonders schnell groesser wird?  Was ist die Richtung des steilsten Anstiegs?  Ich laufe auf einen Berg, und ich moechte sozusagen so steil wie moeglich hochlaufen.", "start": 1248.5, "end": 1269.5}, {"text": " Was ist die Richtung, die ich dafuer waehlen muesste?  Und jetzt ist es offenbar so, ich kann mir hier angucken,  dass die Funktion sich veraendert, wenn ich in irgendeine Richtung laufe.  Und es ist klar, wenn ich diesen Richtungsvektor R skaliere,  dann wird dieser Zahl einfach groesser.  Es genuegt sich, irgendeine Zahl, ein Vektor R zu nehmen,  und zu sagen, ich normiere den Mal.", "start": 1269.5, "end": 1293.5}, {"text": "  Also ich frage jetzt, in welche Richtung Q muss ich laufen,  so dass DQ maximal gross wird.  Aber ich sage, vorher ich beschraenke mich auf Werte Q, die die Laenge 1 haben.  Das ist auch so, wie ich die 1 schreibe, und die Betragstriche sieht das interessant aus.  Also das heisst, ihr Betrag von Q, ich schrabs anders,  dann sind nicht so viele Betragstriche da.", "start": 1293.5, "end": 1318.5}, {"text": "  Also schreiben wir mal, wir suchen irgendein Q,  das die Eigenschaft hat, dass QTQ1 ist.  Und wir haetten gerne, dass dieser Ausdruck maximal wird.  Was ist dieser Ausdruck? Das steht hier.  Wir haetten also gerne so was,  dass Maximum mit dieser Bedingung von QT mal Gradient F.", "start": 1318.5, "end": 1359.5}, {"text": " Ja, und was ist die Antwort?  Welchen Vektor Q muss sich nehmen,  unter allen Vektoren, die Einheitslaenge haben,  der diesen Ausdruck maximiert?  Ich habe also irgendeine Idee.  Ja, da ich hier Q transponiert habe, Gradient F.  Also einfach den Gradient.  Der Gradient ist so, den dein Vektor, den koennte ich mir zum Beispiel ueber 2 Dimensionen maximieren.", "start": 1368.5, "end": 1393.5}, {"text": " Kann ich mir den hinmalen?  Ja, das ist dann der Gradient.  So, und jetzt frage ich sozusagen,  welcher Vektor mit Einheitslaenge gibt das groesste Innenprodukt?  Naja, einer, der in die gleiche Richtung zeigt.  Wenn der irgendwie in die Richtung zeigt, dann wird mein Innenprodukt null.  Da habe ich irgendwas falsch gemacht.", "start": 1393.5, "end": 1412.5}, {"text": "  Also ich muss jede Komponente rausnehmen, die orthogonal steht auf diesem Vektor.  Ich muss also einen nehmen, der in diese Richtung zeigt,  damit das Skalaprodukt mir einfach nur noch die Laenge gibt  und nicht mehr kleiner wird, dadurch, dass der Winkel zwischen den beiden Vektoren ist.  Das heisst, Q ist einfach Gradient von F geteilt durch den Betrag von Gradient von F.", "start": 1412.5, "end": 1438.5}, {"text": "  Damit das ein Vektor wird, der Einheitslaenge hat.  Das heisst, der Gradient hat eine besondere Eigenschaft.  Nicht nur habe ich das an der Stelle, wo die Funktion ihr lokales Minimum annimmt, der Gradient verschwindet.  Und diese Null ist uebrigens eine Null in vielen Komponenten.  Also, die sieht so aus.  Gradient von F ist ein Vektor.", "start": 1438.5, "end": 1471.5}, {"text": "  Und die Bedingung ist, dass der Gradient von F der Null-Vektor ist.  Sondern ich habe auch, und das ist das Praktische jetzt fuer das Minimieren von Funktionen,  dass der Gradient in die Richtung zeigt, in die die Funktion am meisten ansteigt.  Und umgekehrt, also, wenn ich den Berg moeglichst schnell runter will,  dann laufe ich entlang von Minusgradient.  Das ist die Beobachtung.", "start": 1471.5, "end": 1497.5}, {"text": "  Wenn ich also ein Minimumsuche, ist es intuitiv betrachtet,  eine smarte Idee entgegengesetzt zu dem Gradienten zu laufen.  Und jetzt wollte ich auch folgen, das ein bisschen hinweisen.  Naemlich, dass man manchmal komische Funktionen hat  und sich ueberlegen sollte, wie man den Gradient ausrechnet.", "start": 1497.5, "end": 1536.5}, {"text": " Da hilft unglaublich oft ein bisschen Intuition,  weil die Funktion manchmal nicht so klar zeigt, was der Gradient ist.  Und zwar haben wir ja als Anwendungsproblem,  haben wir gesagt, was wir machen wollen, ist, wir wollen hier so eine Seifenhaut einspannen  und die wollten wir modellieren als Menge von Dreiecken und so weiter.", "start": 1537.5, "end": 1568.5}, {"text": " Das heisst, unsere Funktion fuer unser Anwendungsbeispiel  ist die Flaecheninhaltfunktion von diesen Dreiecken.  Und was wir also brauchen, um das zu minimieren,  ist der Gradient vom Flaecheninhalt von der Summe der Dreiecke.  Also, was ist die Flaecheninhaltfunktion, nennen wir die mal Grossf.  Die haengt jetzt ab von ganz vielen von diesen Orten,  also x0, x1, x2 und all diese xi, die sind aus r3.", "start": 1571.5, "end": 1610.5}, {"text": "  Und das ist einfach Summe der Flaecheninhalte  und die nenne ich jetzt einfach mal ai.  Also jedes Dreieck hat hier ein Flaecheninhalt  und offenbar bekomme ich die Gesamtflaeche, in dem ich einfach aufsummiere.  Ja, und jetzt kommt schon mal das erste Interessante hier,  die Linearitaet von dieser Funktion  und die Linearitaet der Gradientenfunktion.", "start": 1610.5, "end": 1640.5}, {"text": "  Was ich jetzt also brauche, ist den Gradienten von f.  Und was ich sofort sehe, ist,  das ist die Summe von den Gradienten von den einzelnen Felgen.  Das darf ich beim Ableiten.  Wenn ich eine Summe ableite,  dann ist meine Ableitung die Summe der einzelnen Elemente,  die eines der einzelnen Ableitungen.  Und ai haengt natuerlich auch ab von x0, x1 und so weiter.", "start": 1642.5, "end": 1687.5}, {"text": "  Das heisst, ich habe die Frage reduziert darauf,  was ist eigentlich der Gradient von so einem Dreieck,  bezueglich der Bewegung dieser Ecken.  Und das machen wir jetzt auch wieder einfach,  das ist offenbar die Summe ueber die Bewegung der einzelnen Dreiecken.  Das heisst, alles, was wir uns noch angucken muessen,  ist, ich habe hier so ein Dreieck, sagen wir mal, x0, x1, x2.", "start": 1687.5, "end": 1717.5}, {"text": "  Das sind drei Orte im R3,  an der Tafel sind es erstmal drei Orte im R2.  Und ich kann jetzt also fragen,  was ist die Ableitung der Flaecheninhaltsfunktion bezueglich einer dieser drei Ecken?  Und dann kann ich die zweite Ecke machen,  dann kann ich die dritte Ecke machen,  aber die beeinflussen sich nicht.  Mein Gradient hat so viele Eintraege, wie hier Variablen sind,  dreimal Anzahl der Ecken.", "start": 1717.5, "end": 1753.5}, {"text": "  Der Gradient dieses Dreiecks, der hat im Grunde auch so viele,  die meisten beeinflussen das Dreieck, nicht nur die drei.  Wenn das hier ein Ort im R2 ist, sagen wir mal,  und das im R2, und das im R2 ist der Gradient von diesem Dreieck,  bezueglich dieser Variablen in sechs elementiger Vektor.", "start": 1753.5, "end": 1775.5}, {"text": " Und jetzt nehme ich eben nur diese Ecke  und dann frage ich mich, was sind die zwei Eintraege, die zu x0 gehoeren?  Und jetzt ist also meine Frage, was ist der Gradient  Flaecheninhalt bezueglich dieser Ecke?  Ideen dazu.  Das muss also muessen, ja.  Zenkricht auch was?  Auf der Grundseite.", "start": 1775.5, "end": 1809.5}, {"text": " Der Gradient, also die Funktion Gradient, haben wir mal gesagt,  ist die Richtung des steilsten Anstiegs der Funktion.  Das heisst, ich kann jetzt also fragen,  in welche Richtung muss ich x0 bewegen,  sodass die Flaecheninhaltsfunktion am schnellsten waechst?  Ja, und das ist offenbar richtig, das geht dann,  wenn ich mich  orthogonal zur Grundseite bewege.", "start": 1809.5, "end": 1837.5}, {"text": "  Warum? Man kann es auch vielleicht noch begruenden.  Ich wuerde so sagen,  wenn ich mich parallel zu der Grundseite bewege,  dann veraendert sich der Flaecheninhalt nicht.  Und fuer diesen Vektor im R2  bedeutet es, der muss orthogonal stehen auf der Grundseite,  weil Bewegung entlang der Grundseite den Flaecheninhalt ueberhaupt nicht veraendert.", "start": 1837.5, "end": 1872.5}, {"text": " Und dann weiss ich, die maximale Veraenderung tritt ein,  wenn ich mich orthogonal dazu bewege.  Und jetzt im R3 muss ich mir noch was Zusaetzliches ueberlegen.  Also, wenn das Dreik im Raum liegt,  dann wuerde ich argumentieren, diese gradienten Richtung,  die muss in der Ebene von dem Dreik liegen.", "start": 1873.5, "end": 1897.5}, {"text": " Weil wenn das Dreik,  wenn das hier mal so ein Dreik ist,  wenn ich mich jetzt in diese Richtung bewege,  das heisst, das Dreik so ein bisschen in diese Richtung kippt,  dann bewege ich mich sozusagen,  wir gucken jetzt mal auf das Dreik drauf,  hier oben ist jetzt X0, hier unten sind jetzt X1 und X2.  Und die Orte, in denen das Dreik seinen Flaecheninhalt nicht veraendert,  sind jetzt so ein Kreis.", "start": 1897.5, "end": 1928.5}, {"text": "  Beziehungsweise, da ich es auch entlang dieser Richtung bewegen kann,  ist es ein Zylinder.  Die Orte fuer X0, auf denen sich der Flaecheninhalt nicht veraendert,  bilden einen Zylinder um diese Kante X1, X2.  Ist das klar?  Und in erster Ordnung, der Zylinder ist jetzt natuerlich gekruemmt,  aber in erster Ordnung ist das hier nochmal eine Richtung,  in der nichts passiert.", "start": 1928.5, "end": 1959.5}, {"text": "  Differenziell, in erster Ordnung fuer sehr kleine Bewegungen,  passiert in diese Richtung wieder nichts mit dem Flaecheninhalt.  Das heisst, der Gradient muss orthogonal auf diesem Zylinder stehen.  Das heisst, er liegt in der Ebene vom Dreik  und steht orthogonal auf der gegenueberliegenden Grundseite.", "start": 1959.5, "end": 1981.5}, {"text": " Und jetzt bleibt nur noch die Frage,  da wir den Gradienten eintragen in unseren Vektor  und den Gradienten und den Gradienten,  was ist deren Groesse?  Also ich kann die Groesse nicht frei waehlen,  denn die Bewegung von dieser Ecke in diese Richtung,  sagen wir mal mit einem Vektor der Laenge 1,  hat vielleicht einen anderen Effekt,  als die Bewegung dieser Ecke oder dieser Ecke mit der Laenge 1.", "start": 1981.5, "end": 2002.5}, {"text": "  Von daher ist jetzt die Frage,  was ist der richtige Proportionalitaetsfaktor fuer diesen Gradienten?  Was hat er fuer eine Laenge?  Ich kann dann den gesamten Gradienten mit irgendwas skalieren,  aber was waere eine bequeme Wahl hier?  Wie stark veraendere ich den Flaecheninhalt dieses Dreiecks,  wenn ich hier an dieser Ecke,  nicht diese Ecke in diese Richtung bewege?  Hat jemand einen Vorschlag?", "start": 2002.5, "end": 2043.5}, {"text": " Was ist der Flaecheninhalt dieses Dreiecks?  Was waere eine Formel fuer den Flaecheninhalt des Dreiecks?  Grundseite mal Hoehe durch 2, das finde ich gut.  Also diese Grundseite,  x1 minus x2, mal die Hoehe halbe.", "start": 2043.5, "end": 2082.5}, {"text": " Und was ich im Grunde mache,  wenn ich mich auf diese Richtung festlege,  jetzt mache ich so etwas wie eine Richtungsableitung,  jetzt kann ich auch die Veraenderung ausrechnen,  wenn ich mich in dieser Richtung bewege,  habe ich ein eindimensionales Problem,  naemlich entlang der Hoehe.  Was ich veraendere, ist nur die Hoehe.", "start": 2082.5, "end": 2094.5}, {"text": " Das heisst, der richtige Faktor ist der,  den ich bekomme, wenn ich diesen Ausdruck nach der Hoehe ableite,  und was passiert dann?  Dann verschwindet hier einfach das Habe,  dass eine lineare Funktion ist in der Hoehe.  Das heisst, der Gradient,  ein sinnvoller Gradient bezueglich dieser Ecke,  den bekomme ich,  wenn ich diese Seite nehme  und um 90\u00b0 in der Dreieckebene drehe.", "start": 2094.5, "end": 2126.5}, {"text": "  Denn der Gradient, die Laenge des Gradienten,  ist proportional zur Laenge dieser Seite.  Das heisst, die drei Gradienten fuer so ein Dreieck bekomme ich,  indem ich diese Seite nehme  und in der Dreieckebene um 90\u00b0 drehe.  Welche Operation macht das fuer mich?  Ja?  Aber es geht einfacher.  Wenn Sie das jetzt programmieren wollten,  dann muessen Sie diese Transformationsmatrix entwerfen.", "start": 2126.5, "end": 2165.5}, {"text": "  Und was ein bisschen unschoen daran ist,  dass dieses Dreieck irgendwo im Raum liegen kann,  das heisst, Sie muessen um die richtige Achse drehen.  Das heisst, Sie brauchen eine Rotationsmatrix, 90\u00b0,  die um die richtige Achse dreht.  Es gibt eine geometrische Operation im R3,  die das macht.  Die gibt Ihnen diesen Vektor.  Vorschlaege, ja?  Das Cross-Product, das auf Deutsch Kreuzprodukt.", "start": 2165.5, "end": 2198.5}, {"text": "  Das Kreuzprodukt mit der normale, dieses Dreiecks.  Und wie bekommen Sie die normale, das Dreiecks?  Cross-Product.  Sie rechnen also erst die normale aus.  Die normale dieses Dreiecks,  kommen Sie, indem Sie das Kreuzprodukt ausrechnen  und dann normieren.  Und dann bekommen Sie den Gradienten bezueglich der Ecken.  Dann haben wir mal bezueglich irgendeiner Ecke X, I.", "start": 2198.5, "end": 2251.5}, {"text": "  Ist dann einfach die gegenueberliegende Seite.  Machen wir es mal konkret.  Das ist fuer X Null.  Ist also N Kreuz X 1, minus X 2.  Das Kreuzprodukt mit einem Vektor.  Das Kreuzprodukt von zwei Vektoren  gibt Ihnen einen Vektor, der orthogonal steht.  Dadurch, dass wir den hier normiert haben,  den normalen Vektor,  hat das Ergebnis die Laenge von dem einen Vektor, den Sie da reintun.", "start": 2251.5, "end": 2293.5}, {"text": "  Das heisst, wenn Sie hier die Oberflaechennormale haben von dem Dreik und die Laenge von dieser Oberflaechennormale ist 1  und Sie bilden das Kreuzbrueck mit dieser Seite, dann bekommen Sie einen Vektor, der orthogonal steht auf diesen Dingen und auf diesen Dingen.", "start": 2293.5, "end": 2310.5}, {"text": "  Alle Vektoren in der Ebene des Dreiks stehen orthogonal auf der Oberflaechennormale und der Vektor, den Sie bekommen, steht zusaetzlich noch orthogonal auf dem.  Dadurch, dass der normalen Vektor die Laenge 1 hat, hat dann auch dieser Vektor die gleiche Laenge wie das hier und das ist okay.", "start": 2310.5, "end": 2327.5}, {"text": "  Also Sie koennten hier noch ein halb davor schreiben, weil wir das hier so vorgesehen haben, aber es ist letztlich egal, wenn Sie es an allen Stellen gleich machen.  Was ich gerne damit zeigen wollte ist Folgendes.  Ich glaube, das ist eine gute Methode, um den Gradienten von dieser Flaecheninhaltsfunktion auszurechnen.", "start": 2328.5, "end": 2355.5}, {"text": "  Wenn Sie das direkt da machen, wenn Sie sagen, ich habe hier ein Dreieck und ich gehe hier in irgendeine Formelsammlung und suchen mir eine Funktion,  die den Flaecheninhalt von diesem Dreieck ausrechnet und dann stosse ich auf, wie heisst die?  Es gibt so eine, die aus den drei Seitenlaengen den Flaecheninhalt ausrechnet, Hyron heisst die, glaube ich.", "start": 2355.5, "end": 2383.5}, {"text": "  Hyronische Formel fuer den Flaecheninhalt, dann da braucht man irgendwie den halben Umfang und dann sagt man irgendwie okay, fuer ein Dreieck ABC ist der Flaecheninhalt,  jetzt sage ich, der halbe Umfang S ist A plus B plus C halbe und dann ist der Flaecheninhalt die Wurzel aus S mal S minus A mal S minus B mal S minus C oder so.  Ja, das ist der Flaecheninhalt.", "start": 2383.5, "end": 2408.5}, {"text": "  Ja, und jetzt koennen Sie eben sagen, A, B und C sind Funktionen von X0, X1, X2 und wenn Sie das ableiten, dann ableiten Sie aber ziemlich lange,  bis Sie bei irgendeinem Ergebnis ankommen und das ist voellig hoffnungslos.", "start": 2408.5, "end": 2429.5}, {"text": " Und es lohnt sich darueber nachzudenken fuer diese Gradienten, was ist eigentlich hier die Konstellation, was ist das fuer ein Problem,  in welche Richtung veraendert sich der Funktionswert gar nicht, wir haben uns im Grunde ueberlegt, was die Gradienten sein muessen,  weil wir uns ueberlegt haben, was die Bewegungsrichtungen fuer X0, X1, X2 sind, so dass sich hier gar nichts tut fuer den Flaecheninhalt.", "start": 2429.5, "end": 2442.5}, {"text": "  Und dann habe ich am Ende eine einfache Formel, um den Gradienten auszurechnen.  Okay, ja, und der Gradient gibt mir die Richtung, in die ich diese Ecken bewegen muss, so dass der Flaecheninhalt kleiner wird.  Und der Gradient bezueglich einer dieser Ecken ist jetzt eben einfach die Summe ueber alle anhaengenden Dreiecke.", "start": 2444.5, "end": 2468.5}, {"text": "  Ja, ich kann jetzt also fuer so eine Ecke mir den Gradienten ausrechnen, aber die Ecke haengt ja nicht nur an einem Dreieck,  die haengt ja an vielen Dreiecken und das ist einfach die Summe dieser Vektoren.  Ja, und dann habe ich fuer diesen Ort einen Vektor gefunden, eine Bewegungsrichtung, die den gesamten Flaecheninhalt von diesen,  in dem Fall fuenf Dreiecken minimiert.", "start": 2468.5, "end": 2498.5}, {"text": "  Frage, letzte Frage zu dem Thema, Verstaendnisfrage.  Wenn diese sechs Punkte alle in der Ebene liegen, was ist dann der Gradient bezueglich dieser Ecke?  In welche Richtung zeigt der Gradient bezueglich dieser Ecke?  Ja?  Null Vektor.", "start": 2498.5, "end": 2552.5}, {"text": " Es muesste der Null Vektor sein, ja, denn wenn die alle in einer Ebene liegen,  dann ist, also ich kann den jetzt bewegen, wie ich will, in der Ebene und der Flaecheninhalt aendert sich nicht.  Das heisst, der verschwindet.  Gut.", "start": 2557.5, "end": 2580.5}, {"text": " Ja, das heisst eben auch fuer unser Seifenblasenproblem genau das Richtige,  wenn ich hier in diesen Ring irgendwelche Dreiecke einspannen wuerde  und jetzt danach frage, wie muessen die sich bewegen, damit die Flaeche moeglichst klein wird,  dann kriege ich eben einfach eine Ebene und wie die Ecken in der Ebene liegen, ist egal.  Ja, das ist immer die gleiche kleine Flaeche.  Okay.", "start": 2580.5, "end": 2596.5}, {"text": "  So, also Gradient ist ein wichtiger Begriff.  Und man muss sich ueberlegen, wie man ihn ausrechnet.  Jetzt geht es weiter.  Fuer die Charakterisierung hatten wir,  hatten wir gesagt, lokales Minimum in einer Dimension bedeutet,  Ableitung ist Null, zweite Ableitung ist positiv.", "start": 2601.5, "end": 2627.5}, {"text": " Und das war dann auch hinreichend, wenn die zweite Ableitung positiv ist,  fuer eine Dimension, dann wussten wir, wir haben lokales Minimum.  Und die Frage ist jetzt, wie machen wir hier weiter?  Das heisst, wir muessen uns die zweiten Ableitung anschauen.  Bloederweise gibt es ziemlich viele zweite Ableitungen.", "start": 2627.5, "end": 2649.5}, {"text": " Ja, ich kann zum Beispiel,  ich kann zum Beispiel F Ableiten nach X Null und dann nochmal nach X Null.  Und dann, wenn ich das hier in der Ecke fahre,  dann habe ich das,  dann nochmal nach X Null.  Oder ich kann F Ableiten  erst nach X Null und dann nach X 1.  Ja, oder ich kann  erst nach X Null und dann nach X 2 Ableiten.  Oder ich kann die Reihenfolge vertauschen.", "start": 2652.5, "end": 2693.5}, {"text": " Und kann jetzt  so rum Ableiten.  Also erst nach X 1 und dann nach X Null.  Ja, es gibt also, wenn ich eine Funktion im R N habe,  gibt es N-parzielle Ableitung  und es gibt N-quadrat zweite parzielle Ableitung.  Und dieses Ding hat einen Namen, das bildet also eine Matrix.  Und es heisst Hessematrix.  So.", "start": 2693.5, "end": 2734.5}, {"text": " Und jetzt ist die Frage,  welche Bedingungen muss die Hessematrix erfuellen,  also die gesamten zweiten Ableitung,  damit wir,  wenn wir die notwendige Bedingung erfuellen,  ja, also wenn wir einen Punkt  gefunden haben, in dem der Gradient verschwindet.", "start": 2734.5, "end": 2758.5}, {"text": " Und jetzt ist die Frage,  welche Eigenschaften muss diese Hessematrix haben,  muessen die zweiten parziellen Ableitungen haben,  damit es ein lokales Minimum ist.  So.  Dazu,  wie machen wir das?  Dazu schreiben wir uns jetzt mit diesen Begriffen  die Taylor-Entwicklung von der Funktion an.  Ja, die Taylor-Entwicklung um die Stelle A.", "start": 2763.5, "end": 2786.5}, {"text": "  Letztes Mal irgendwie mit den Vorzeichen so viel Fehler gemacht.  Das ist also dieser lineare Teil  und dann kommt der Quadratische,  offenbar von den zweiten Ableitungen ab.  Das ist die  die Taylor-Entwicklung um die Stelle A herum.  Da tauchen eben auch,  tauchen eben auch die ersten Ableitungen hier auf,  als Gradient, und die zweiten Ableitungen in der Hessematrix.", "start": 2795.5, "end": 2833.5}, {"text": "  Man kann es auch mit Summen hinschreiben  und so, das ist jetzt einfach mit der Notation,  die wir uns jetzt ueberlegt haben fuer parzielle Ableitungen und so.  Also das Gradientenzeichen,  wir sind Gradientenvektor, die Hessematrix,  und so ist das die kurze Schreibweise.", "start": 2833.5, "end": 2854.5}, {"text": " Und jetzt kann man sich ueberlegen,  wenn die Funktion, jetzt nehmen wir mal an,  wir haben den lokalen,  wir haben die notwendige Bedingung erfuellt.  Wir haben also eine Stelle gefunden, an der gilt fx Stern,  der Gradient ist da null.  Und jetzt gucken wir uns an, was in kleiner Entfernung  um diese Stelle D herum passiert.", "start": 2854.5, "end": 2892.5}, {"text": " Also dann haben wir hier,  und wir entwickeln um die Stelle x Stern herum.  Jetzt haben wir hier x minus a,  a ist jetzt also x Stern,  und wir gucken an die Stelle x Stern, also haben wir hier D,  T mal den Gradienten f an der Stelle x Stern,  und hier hinten den Teil mit der Hessematrix,  das ist jetzt DT Hessematrix an der Stelle x Stern mal D.", "start": 2893.5, "end": 2931.5}, {"text": " Das ist die Tellerentwicklung an der Stelle,  an der wir die notwendige Bedingung fuer ein Minimum gefunden haben,  und wir variieren um diese Stelle herum  mit unten einem kleinen Vektor D.  Und was sehen wir jetzt?  Wir fragen uns, ob diese Funktion ein lokales Minimum ist.", "start": 2932.5, "end": 2958.5}, {"text": " Erst mal sehen wir,  dieser Teil hier ist null,  weil wir ja gesagt haben, wir haben so ein x Stern gefunden,  und da verschwindet der Gradient.  Und jetzt haben wir hier also den Rest stehen,  und jetzt ist die Frage,  welche Eigenschaften muessen da sein,  damit unabhaengig davon, was wir fuer ein kleines D waehlen,  die Funktion in x plus D immer groesser ist als in x Stern.", "start": 2959.5, "end": 2977.5}, {"text": "  Und ich schreibe die Bedingung einfach mal hin.  Was heisst das?  Sobald D irgendeinen Wert annimmt, der nicht null ist, haette ich gerne,  dass dieser Ausdruck groesser ist als f von x Stern.  Das heisst, die Aussage ist,  wir haetten gerne das DT mal die Hessematrix,  mal D, die mal groesser null ist,  egal was wir fuer ein kleines D waehlen.", "start": 2978.5, "end": 3014.5}, {"text": " Und wie heissen solche Matritzen, die das erfuellen?  Positiv, in dem Fall definit oder semi-definit,  wenn wir nur das fordern.  Das heisst, die Bedingung,  die wir aus der einen dimensionalen Analysis kennen,  dass wir sagen, die zweite Ableitung,  die fuer die Uebergabitte groesser als null sein  oder groesser gleich null zumindest, ist jetzt,  diese Bedingung lautet jetzt, ja, lokales Minimum.", "start": 3015.5, "end": 3042.5}, {"text": "  Lokales Minimum bedeutet, die Matrix H ist P  und dann sagen wir mal S in Klammern D.  Ist eine positiv semi-definite Matrix.  Idealerweise ist sie eine positiv-definite Matrix.  So uebersetzen sich diese Bedingungen.  Jetzt kann man noch fragen,  wann ist eine Funktion lokal-convex?  Wer kann das sagen?  Ja, ich bin an irgendeiner Stelle X.", "start": 3043.5, "end": 3076.5}, {"text": " Was ist die Aussage dafuer,  dass zumindest in einer infinitesimalen Umgebung  die Funktion convex ist?  Genau das.  Convex heisst dann von dem Ort aus,  waechst sie in alle Richtungen.  Das heisst, die zweiten Ableitung haben diese Eigenschaft.  Ja, das heisst, wenn sie von irgendeiner Funktion  in einem Gebiet nachweisen wollen,  dass sie convex ist,  dann ist der erste Impuls immer.", "start": 3077.5, "end": 3104.5}, {"text": "  Wir schauen mal,  wenn wir die Hesse Matrix hinschreiben koennen,  ob die vielleicht positiv definit ist.  Wenn Sie zeigen koennen,  dass Ihre Funktion in einem gewissen Gebiet  positiv definite Hesse Matrix hat,  dann wissen Sie, die Funktion ist convex.  Meistens ist das nicht so einfach.  Die Tele-Dricklung ist eine Ahnung.  Ja.  Wie viele Sicherheitsprinzipien es ist,  ist es convex.  Das...", "start": 3105.5, "end": 3134.5}, {"text": "  Ne, also...  Ich mache mal ein Beispiel fuer das,  was ich gesagt habe,  mit Konvexitaet.  Ich versuch das mal...  Also, nehmen wir mal an,  wir haben die Funktion  x\u00b2 plus y\u00b2.  F von x, y  ist x\u00b2 plus y\u00b2.  Ja, dann ist der Gradient von F.  Machen wir gleich mal einen kleinen Test.  Gradient von F, erste Komponente.  Partielle Ableitung noch x, ja.  2x.  2. Komponente, 2y.  Ja.  So.  Hesse Matrix.", "start": 3137.5, "end": 3177.5}, {"text": "  Hesse Matrix ist immer symmetrisch,  wenn die Funktion zwar mal stetig differenzierbar ist,  weil es dann egal ist, ob ich zuerst nach  der einen und dann der anderen,  oder umgekehrt bin,  dann ist es immer simetrisches.  Das ist das, was ich gesagt habe,  das ist das, was ich gesagt habe.  Also, wenn und dann der anderen  oder umgekehrt Richtung Ableite.  Ja.", "start": 3178.5, "end": 3200.5}, {"text": " Also, hier oben steht jetzt  die Partielle Ableitung nach x,  nochmal nach x,  abgelitten.  Ja, und das ist dann einfach 2.  Hier steht  x nach y.  Da steht y nach x.  Und hier unten steht  y nach y.  Das ist die Hesse Matrix.  Ja.  Und diese Hesse Matrix  ist positiv definit  ueberall.  Und was daraus folgt,  ist, diese Funktion ist convex ueberall.  Ja.", "start": 3201.5, "end": 3248.5}, {"text": " Das heisst, ja, f, also  h  ist pd, ja,  in dem gesamten R2  und damit  f  ist convex  im gesamten R2.  Ja.  Das ist also diese Strategie.  Bloederweise ist fuer alle Funktionen,  die uns wirklich interessieren,  die Hesse Matrix nicht konstant.  Ja.  Und dann wird es eben schwieriger.  Ja.  Also, wenn ich jetzt,  wenn ich jetzt mal mal ableite,  bekomme ich Konstanten.", "start": 3248.5, "end": 3283.5}, {"text": " Das heisst, die Funktion  ist dann eben  ist dann eben entweder im gesamten R2  convex oder nicht convex.  Und dann ist auch eigentlich nirgends convex.  Beispiel waere zum Beispiel,  Beispiel waere  diese Funktion.  Dann bekomme ich das hier  und das hier.  Und dann  ist die Matrix indefinit  und die Funktion ist einfach nirgends convex.  Ja.", "start": 3284.5, "end": 3324.5}, {"text": " Also  und diese Aussage hier jetzt,  ja, mit, wir haben ein lokales Minimum  an der Stelle, an der der Gradient 0 ist,  geht eben zusammen mit  dieser Aussage, es existiert ein Delta.  Also, das es dann war.", "start": 3326.5, "end": 3349.5}, {"text": " Wenn ich nachgewiesen habe,  dass F an der Stelle X Stern 0 ist  und ich nachgewiesen habe,  dass die Hesse Matrix positiv definit ist  an der Stelle X 0,  dann existiert auch ein Delta groesser 0  fuer das die Funktion kleiner ist  als alle in der Umgebung.  Das Delta mag sehr klein sein.  Also, so wird man,  so wird man hier diese Therme los.", "start": 3350.5, "end": 3363.5}, {"text": " Also, da passiert noch irgendwas,  aber es gibt irgendein Delta,  das klein genug ist.  Ja, weil,  das ist 0,  hier steht im Grunde D Quadrat  und dann kommt hier D hoch 3  und wenn D sehr klein ist,  dann kann ich, also ich kann D so klein machen,  dass D hoch 3 mal irgendeine Konstante,  immer kleiner ist als D Quadrat,  mal irgendeine Konstante,  das ist die Idee.", "start": 3364.5, "end": 3391.5}, {"text": " Okay,  aber jetzt,  jetzt brauchen wir doch noch irgendwie ein Verfahren,  oder nach dem ganzen,  nach dem ganzen Ueberlegen hier  und das Verfahren kriegen wir relativ schnell.  So, das Verfahren geht wie folgt,  wir ueberlegen uns an letzte Woche,  wir erinnern uns an letzte Woche  und da hatten wir ein Verfahren  um eine Nullstelle zu bestimmen  und das Verfahren hiess Newton Verfahren.", "start": 3392.5, "end": 3416.5}, {"text": "  Jetzt suchen wir einen Newton Verfahren,  um ein Minimum zu finden  und wir ueberlegen uns also,  wir gingen das Newton Verfahren fuer Nullstellen,  in Klammern jetzt, das ging so,  i x plus, also die i plus 1.  iteration war,  wir nehmen den Wert, den wir in der i-Iteration hatten  und ziehen davon ab,  diesen Bruch, ja,  den Bruch aus Funktionswert und erster Ableitung.", "start": 3417.5, "end": 3453.5}, {"text": " Und die Frage ist,  wie geht jetzt das Newton Verfahren,  wenn ich ein, ja, das war fuer Nullstellen,  wie geht jetzt das Newton Verfahren,  wenn ich damit ein Minimum bestimmen will  und die Ueberlegung ist,  was ist die notwendige Bedingung fuer ein Minimum,  die notwendige Bedingung fuer ein Minimum ist,  dass die Ableitung Null wird, ja,", "start": 3454.5, "end": 3472.5}, {"text": " das heisst, wir suchen im Grunde die Nullstelle der Ableitung,  hatte ich ja letztes Mal schon gesagt,  das ist die Strategie, ja.", "start": 3473.5, "end": 3495.5}, {"text": " Das heisst, das neue Newton Verfahren  in einer Veraenderlichen sieht so aus,  ach, der Teil wieder, ja,  das heisst, in einer Veraenderlichen,  das Newton Verfahren ist jetzt ganz einfach,  ich leite, ich setze hier einfach ein,  hier steht die Funktion,  die von der ich eine Nullstelle haben will  und jetzt will ich von der Ableitung eine Nullstelle haben,", "start": 3496.5, "end": 3500.5}, {"text": " das heisst, ich setze einfach die Funktion ein,  von der ich eine Nullstelle haben will  und das ist die Funktion F-  und jetzt muss ich F-Ableiten fuer den Nenner,  das heisst, hier steht die zweite Ableitung.  Das ist das Newton Verfahren,  um ein Minimum zu finden,  oder Maximum.", "start": 3501.5, "end": 3535.5}, {"text": " Und jetzt ist nur noch die Frage,  wie mache ich das in mehreren Dimensionen?  Ja, und im Grunde ganz genauso,  wir machen das einfach.", "start": 3536.5, "end": 3572.5}, {"text": " Das Ding hier, fuer mehrere Dimensionen  muss jetzt der Gradient werden,  das heisst, fuer mehr als eine Dimension  steht hier, okay, Xi plus 1 ist Xi minus,  das Ding wird der Gradient von F,  an der Stelle Xi  und das hier wird die Hessematrix  und ich muss durch die Hessematrix teilen.", "start": 3572.5, "end": 3589.5}, {"text": " Und das heisst, hier steht die Inverse  der Hessematrix an der Stelle Xi  und was man jetzt wieder macht,  ist man loest stattdessen fuer den Schritt,  den man zu tun hat,  das heisst, man sagt, die Hessematrix  an der Stelle Xi mal den Schritt,  soll bitte sein, der Gradient von F an der Stelle Xi.", "start": 3590.5, "end": 3608.5}, {"text": " Ja, und das ist dann der Schritt, den ich machen muss,  jetzt habe ich wieder ein lineares Leichungssystem,  das kann ich loesen und dann kann ich einen Schritt machen.  So, das ist also das Newtonverfahren.", "start": 3609.5, "end": 3628.5}, {"text": " Was ich fuer das Newtonverfahren brauche,  also ich habe eine Funktion, die bildet ab vom R hoch N in den R  und was ich brauche, um an ein lokales Minimum zu finden  mit dem Newtonverfahren, ist die Moeglichkeit,  sowohl den Gradienten auszurechnen,  das ist der Vektor der ersten Ableitung,  als auch die Matrix der zweiten partiellen Ableitung  und dann loese ich hier ein lineares Leichungssystem", "start": 3629.5, "end": 3642.5}, {"text": " und dann habe ich einen Schritt und den kann ich machen  und dann mache ich so weiter  und wenn das Verfahren konvergiert, konvergiert es schnell.", "start": 3643.5, "end": 3668.5}, {"text": " So, was ist jetzt an diesem Verfahren  noch nicht manchmal, muss man jetzt sagen,  manchmal nicht besonders praxistauglich,  manchmal nicht besonders praxistauglich ist,  dass diese Matrix hier ziemlich gross sein kann  und es sein kann, dass auch dieses lineare Leichungssystem  haesslich gross ist.  Wir denken zurueck an unser Problem.", "start": 3669.5, "end": 3679.5}, {"text": " Also, wenn Sie das Newtonverfahren einsetzen koennen,  tun Sie das.  Es ist nicht so, dass damit irgendwas verkehrt waere.  Es ist nur in der Praxis oft schwierig,  zum Beispiel hier.  Sagen wir mal, wir modellieren unsere Seifenblase hier.  Hier sind diese Ecken  und damit sich da so einigermassen was bewegen kann,  sagen wir mal, wir machen 1.", "start": 3680.5, "end": 3708.5}, {"text": "00 oder so,  1.000 so kleine Ecken, die man bewegen kann.  Okay, und jeder hat 3 Freiheitsgrad, das heisst,  sind 3.000.  Das heisst, dann ihr gradienten Vektor ist ein Vektor aus dem R3.000  und die hessematrix ist eine Matrix aus dem R  hoch 3.000 mal 3.000.  Das heisst, die hessematrix hat knapp 10 Millionen Eintraege,  die Sie alle ausrechnen muessten.", "start": 3708.5, "end": 3740.5}, {"text": "  Und da muessen Sie das lineare Gleichungssystem noch loesen.  Dicht besetzt, 3.000 mal 3.000, das ist schwierig.  Und das ist das Problem in ganz vielen Faellen.  Man hat ziemlich viele Veraenderliche  und die bloede hessematrix ist ziemlich gross.  Wenn man das machen kann, das ist gut, keine Frage,  aber oft wird die hessematrix einfach zu gross.", "start": 3741.5, "end": 3767.5}, {"text": " Es lohnt sich dann nicht mehr, die auszurechnen  und auch das loesenes lineare Gleichungssystem dauert dann lange.  Und dann ist die Frage, was kann man dann noch machen?  So.  Und das ueberlegen wir uns jetzt noch schnell.  Was kann man machen?  Das ist unsere Regel.  Und ich sagte gerade, oft ist es so, dass wir nicht wirklich wissen,  wie wir die hessematrix ausrechnen sollen.", "start": 3768.5, "end": 3834.5}, {"text": "  Und wir machen jetzt ganz frech einfach Folgendes.  Wir sagen, wir haben Glueck in unserem Problem.  Und lokal betrachtet, wenn man ganz lokal im Kleinen schaut,  dann ist es vielleicht so, dass unsere Funktion an dem Tiefpunkt,  an der Stelle wo sie minimal ist, genau so aussieht.  Vielleicht ist das so ein Paraboluid.  Vielleicht sieht das Ding einfach so aus.", "start": 3835.5, "end": 3861.5}, {"text": "  Sagen wir mal, vielleicht noch z\u00b2 und so weiter.  Irgendwie in vielen Veraenderlichen, aber die sind alle an der Stelle  ungefaehr so parabeln in alle Richtungen.  Das heisst, die hessematrix sieht ungefaehr so aus.  Das heisst, was wir machen ist, wir nehmen an,  unsere hessematrix hat die Form.", "start": 3862.5, "end": 3887.5}, {"text": " Wir sagen also, wenn wir unglaubliches Glueck haben,  dann ist die hessematrix ein Vielfaches der Identitaet.  Fragezeichen, Ausrufezeichen, vielleicht.  So, und dann wird dieses Verfahren hier.  Was bekommen wir dann?  Dann haben wir xi plus 1 ist xi minus,  diese Matrix hier, s mal Identitaet, hoch minus 1, mal den Gradienten.  Und das ist xi mal 1 durch s, mal den Gradienten.", "start": 3888.5, "end": 3933.5}, {"text": "  Und manchmal schreibt man, statt diesem 1 durch s,  auch einfach delta mal den Gradienten.  Das ist also die Idee.  Wir sagen, wenn wir grosses Glueck haben, ist unsere Funktion ungefaehr isotrop.  Und dann machen wir als Schritt, einfach einen Schritt,  wie ich das vorhin ja schon sagte, entgegen dem Gradienten.", "start": 3934.5, "end": 3964.5}, {"text": " Wir machen also einen Schritt und wir laufen in die Richtung minus Gradient,  weil das die Richtung ist, in der die Funktion am schnellsten an Wert verliert.  Und deswegen heisst dieses Verfahren dann nicht ueberraschenderweise  Gradienten-Abstiegsverfahren.  Und das ist die Idee.  Wir sind an irgendeiner Stelle xi und wir laufen ein kleines Stueck,  kleines Stueck delta in Richtung minus Gradient.", "start": 3965.5, "end": 4002.5}, {"text": "  Und das ist im Grunde das, was man intuitiv vielleicht machen wuerde,  wenn man schnell den Berg runterlaufen will.  Man laeuft an jeder Stelle, man ist an irgendeiner Stelle, ueberlegt sich,  wo geht es am steilsten runter und laeuft in die Richtung ein kleines Stueck.", "start": 4003.5, "end": 4022.5}, {"text": " Warum nur ein kleines Stueck?  Weil der Berg vielleicht nicht einfach nur ein, was weiss ich, chronisches Ding ist,  sondern weil er nicht ein kleines Stueck gelaufen hat,  und ich bin ein kleines Stueck gelaufen, hat sich die Richtung des steilsten  Anstiegs und Abstiegs eben dann auch veraendert.", "start": 4022.5, "end": 4033.5}, {"text": " Und dann muss ich meine Richtung ein bisschen korrigieren, glaube ich,  wieder ein kleines Stueck und so weiter.  Und jetzt ist nur noch die Frage, wie waehlt man hier delta?  Fuer delta gleich null passiert nichts.", "start": 4034.5, "end": 4062.5}, {"text": " Und fuer delta zu gross ist auch nicht gut,  weil, wenn zum Beispiel meine Funktion so aussieht,  und ich laufe von hier ein kleines Stueck, dann ist gut,  aber wenn ich von hier bis dahin laufe, dann ist nicht so gut.  Also die Frage ist jetzt, wie waehlt man delta?  Und da gibt es verschiedene Moeglichkeiten.  Also das haben wir hier noch als Problem.  Das ist die Wahl von delta.", "start": 4063.5, "end": 4081.5}, {"text": "  Und erstens ist, man betrachtet es als Minimierungsproblem in einer Variablen.  Man sagt jetzt also, ich moechte gerne minimieren, man minimiere f von xi minus delta mal gradient von f.  Und zwar als Funktion von delta.  Und dann habe ich ein eindimensionales Minimierungsproblem.  Und dafuer gibt es Verfahren.  Machen wir naechste Woche, wuerde ich sagen.", "start": 4082.5, "end": 4132.5}, {"text": " Und die zweite Wahl, zweite Moeglichkeit ist,  Sie waehlen einfach irgendeinen Wert.  Und Sie waehlen, was weiss ich, delta gleich eins.  Und Sie ueberpruefen, ob das was gebracht hat.  Also wenn dann f von xi minus delta gradient von f kleiner ist als f von xi, dann gut, weitermachen.  Und wenn nicht, machen Sie delta irgendwie kleiner.  Zum Beispiel dann delta, 1,5 delta.", "start": 4133.5, "end": 4186.5}, {"text": "  Und wenn Sie ein kleines delta gefunden haben, dann ist alles gut.  Wenn Sie delta nicht mehr so kleiner machen koennen, dass das was bringt, dann haben Sie eh ein lokales Minimum gefunden.  Ja, das ist irgendwie eine halbwegs simple Strategie, um ein delta auszuwaehlen.", "start": 4187.5, "end": 4226.5}, {"text": " Also, genau, koennte man delta auch erhoehen?  Ja, die Frage ist sozusagen, wo bin ich zwischen diesen beiden Sachen?  Also ich koennte auch sagen, ich kann delta mal erhoehen, mal er niedrigen und so weiter, und immer versuchen es kleiner zu machen.  Und wenn ich das geschickt mache, dann habe ich im Grunde ein Verfahren implementiert, das genau das macht.  Also, und da kommen wir dann auch hin.", "start": 4227.5, "end": 4244.5}, {"text": "  Ich glaube, nur ich habe heute, heute, ah, es ist nicht ganz so einfach.  Es gibt ein Verfahren, das im Grunde versucht, Bisektion, wie wir sie kennengelernt haben, fuer Nullstellen zu uebersetzen in ein Verfahren, das einen Minimum findet.", "start": 4244.5, "end": 4262.5}, {"text": "  Und auch eben sagt, okay, wir probieren mal den Wert und so, und wenn der nicht hilft, dann probieren wir den Wert, und wenn der nicht hilft, probieren wir den Wert.  Und, genau, also man kann es auch erhoehen, man kann sich auch kompliziertere Sachen ueberlegen, als das, was hier steht.", "start": 4263.5, "end": 4282.5}, {"text": "  Aber da sich im Allgemeinen der Gradient aendert, wenn ich, wenn ich ein kleines Schrittchen delta gehe, kann man eben auch argumentieren, sobald ich irgendwas gefunden habe, was mich hier vorwaerts bringt,  ist es vielleicht auch eine gute Idee, den Gradienten neu auszurechnen.  Ja, gut.  Ja, das ist Ihr Verfahren sozusagen.  Das koennen Sie tun, um diese Seifenhaut kleiner zu machen.", "start": 4283.5, "end": 4311.5}, {"text": "  Und genauso geht es dann.  Sie bauen sich so ein Dreiecksnetz.  Die Ecken, die auf den Ringen liegen, die halten Sie fest.  Die Ecken, die irgendwo in der Luft liegen, fuer die rechnen Sie den Gradienten aus, das machen Sie fuer alle Ecken.", "start": 4312.5, "end": 4342.5}, {"text": " Dann bestimmen Sie sich ein kleines Delta, so dass, wenn die Position der Ecken plus Delta mal den Gradient in den Ecken einen kleineren Flaecheninhalt ergibt  und dann rechnen Sie wieder den Gradienten aus und machen das nochmal und nochmal und mal, bis die Ecken irgendwann sich nicht mehr richtig bewegen.  Und dann sind Sie fertig.  Das ist der Plan.", "start": 4343.5, "end": 4354.5}, {"text": "  Und alles andere habe ich jetzt beschlossen, erzaehle ich Ihnen naechste Woche dann.", "start": null, "end": 4354.5}]}]