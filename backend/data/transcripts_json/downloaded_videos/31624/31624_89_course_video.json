[{"lecture": "31624_89_course_video", "Timestamps": [{"text": "  Auf der Suche nach effizienten Algorithmen geht es haeufig darum, eine Loesungssuche,  die in ihrer direkten Implementation einen exponentiell wachsenden Suchbaum ergibt,  auf ein geringeres Wachstum zu begrenzen.  Der glueckliche Fall einer gaenzlich unverzweiften Suche eines 3D-Algorithmus gelingt nur fuer die wenigsten Probleme.  Sonst muessen andere Ansaetze her.", "start": 0.0, "end": 28.0}, {"text": "  In der letzten Woche haben wir das Brunch and Bound Verfahren besprochen.  Es kann angewendet werden, wenn man fuer jede Teilloesung abschaetzen kann, wie gut eine daraus resultierende Vollloesung im besten Fall sein kann.  So lassen sich aussichtslose Teilloesungen identifizieren und dann kann die Suche dort abgebrochen werden.  Heute geht es um das Konzept des dynamischen Programmierens.", "start": 28.0, "end": 60.0}, {"text": "  Eine Voraussetzung dafuer ist, dass sich die optimale Loesung eines Problems auf die optimale Loesung eines Teilproblems reduzieren laesst.  Diese Eigenschaft nennt man optimal Substructure.  Sie ist auch die Basis von die weite Konkur.  Bei der dynamischen Programmierung kommt noch eine weitere Voraussetzung hinzu.  Bei der Suche muessen an vielen Stellen gleichartige Teilprobleme auftreten.", "start": 60.0, "end": 82.0}, {"text": "  Diese Eigenschaft nennt man overlapping subproblems.  Die einfache Grundidee der dynamischen Programmierung ist nun,  diese vielen gleichen Teilprobleme, die an unterschiedlichen Stellen im Suchebaum auftreten,  nicht jedes Mal von neuem zu loesen, sondern nur das erste Mal dann die Loesung speichern und fuer zukuenftige Teilprobleme wieder abrufen.", "start": 82.0, "end": 112.0}, {"text": "  Diese Idee der Zwischenspeicherung von Teilloesungen hoert sich wahrlich nicht nach einem Geniestreich an.  Bei dem Beispiel der Fibonacci-Zahlen, das gerne zur Motivation der dynamischen Programmierung verwendet wird,  ist es so naheliegend, dass man darauf auch kommt, ohne vorher von dynamischer Programmierung gehoert zu haben.", "start": 112.0, "end": 129.0}, {"text": "  Bei anderen Problemen ist es aber gar nicht so einfach, sie so zu formulieren,  dass der Ansatz in Zwischenspeicherung sinnvoll greift.  Dann sind Kreativitaet und Problemverstaendnis gefragt und der Einsatz lohnt sich.  Wenn die dynamische Programmierung richtig zum Zukunft, kann der Effizienzgewinn enorm sein.", "start": 129.0, "end": 155.0}, {"text": "  In dem Beispiel, das in einem weiteren Video besprochen wird, kann die Laufzeit von exponentiellen auf quadratisches Wachstum reduziert werden.  Aber wie wird eine so drastische Reduktion des Suchbaums erreicht?  Bei Brunch and Bound werden aussichtliose Teilloesungen abgeschnitten.", "start": 155.0, "end": 176.0}, {"text": " Aber was macht die dynamische Programmierung?  Sie identifiziert gleiche Teilprobleme im Suchbaum und schiebt so gewissermassen den Suchbaum zusammen.  Das schauen wir jetzt uns am Beispiel der Fibonacci-Zahlen an.  Die Ente-Fibonacci-Zahl fn ist rekosiv definiert als die Summe von fn-1 und fn-2.  Als Anfangsfaelle sind f0 gleich 0 und f1 gleich 1 gesetzt.", "start": 176.0, "end": 204.0}, {"text": "  Schauen wir uns die rekosive Berechnung von f5 als Baum an.  f5 ist die Summe von f4 und f3.  f4 greift wiederum auf f3 und f2 zurueck.  f3 auf f2 und f1, f2 schliesslich auf f1 und f0.  Da sind wir bei den Anfangsfaellen angelangt und in backtracking-Manier koennte die Berechnung zu Ende gefuehrt werden.  Wir vervollstaendigen den Baum.", "start": 204.0, "end": 249.0}, {"text": "  Wir sehen, dass viele gleiche Teilprobleme an unterschiedlichen Teilen des Berechnungsbaumes auftreten.  Overlapping Subproblems, also gute Voraussetzungen fuer dynamische Programmierung.  Die Berechnungsstruktur mit dynamischer Programmierung kann folgendermassen dargestellt werden.  f5 greift auf f4 und f3 zurueck.  f4 auf f3 und f2, f3 auf f2 und f1 und f2 auf f1 und f0.", "start": 249.0, "end": 284.0}, {"text": "  Wir sehen, dass die mehrfach auftretenden Berechnungen bei dem Backtracking-Such bauen,  nur einmal bei der dynamischen Programmierung vorkommen.  Es ergibt sich eine lineare Berechnungsstruktur bei der dynamischen Programmierung,  waehrend der volle Berechnungsbaum exponentiell ist.  Dieses Beispiel macht auch den Unterschied zwischen dynamischer Programmierung und die Weiten Konker deutlich.", "start": 284.0, "end": 311.0}, {"text": "  Die Weiten Konker beruht nur auf der Zerlegung in Teilprobleme.  Optimus Substructure.  Bei den Fibonacci-Zahlen fuehrt dies zu dem kompletten Berechnungsbau.  Erst die Aussennutzung der ueberlappenden Teilprobleme,  Overlapping Subproblems mit der Zwischenspeicherung der Ergebnisse der dynamischen Programmierung,  fuehrt zu einer effizienten Loesung.", "start": 311.0, "end": 337.0}, {"text": "  Bei manchen anderen Problemen fuehrt auch schon die Weiten Konker zu effizienten Loesungen.  Man kann dynamische Programmierung als Erweiterung von die Weiten Konker auffassen.  Falls zusaetzlich zu der optimalen Substruktur auch ueberlappende Teilprobleme gegeben sind,  kann die dynamische Programmierung zum Einsatz kommen und bringt dann meist einen Effizienzboost.", "start": 337.0, "end": 365.0}, {"text": "  Genauso zu den Fibonacci-Zahlen und zwei weiteren anspruchsvolleren Beispielen finden Sie im Algorithm.  In einem weiteren Video wird ein Ansatz mit dynamischer Programmierung  fuer das Problem der laengsten gemeinsamen Teilfolge entwickelt.  Eine typischen Aufgabe in Bewerbungsgespraechen und Tests.", "start": 365.0, "end": 377.0}]}]