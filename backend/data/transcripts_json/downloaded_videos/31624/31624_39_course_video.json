[{"lecture": "31624_39_course_video", "Timestamps": [{"text": "  Hallo. Ganz am Anfang der Vorlesung hatten wir darueber gesprochen, dass es ja eine der Hauptaufgaben von Informatikern und Informatikerinnen ist, Probleme aus der echten Welt zu verstehen, abzubilden und zu loesen.  Heute moechte ich mit dir ueber ein kleines Werkzeug sprechen, das extrem wichtig dabei ist, diesen Job auch gut zu machen.", "start": 0.0, "end": 59.0}, {"text": "  Stell dir vor, du arbeitest in deinem ersten Job in einer Softwarefirma und hast also deine ersten Besuche beim Kunden gehabt, hast analysiert, was genau die benoetigen und hast zwei Alternativen, zwei Algorithmen festgestellt, die das Problem loesen koennten.", "start": 59.0, "end": 77.0}, {"text": " Die Frage ist, wie entscheidest du dich zwischen dem einen oder dem anderen?  Und du koenntest zum Beispiel sagen, in dieser Anwendung ist es kritisch, dass Dinge sehr schnell passieren und dann kommst du auf die Ideen, Test laufen zu lassen.  Hier hast du die Ergebnisse.", "start": 78.0, "end": 93.0}, {"text": "  Du testest die Software A oder die Software B fuer verschiedene Datensaetze, Datensaetze verschiedener Groesse, hier angezeigt durch N.  Und du siehst, wie lange Software A und Software B dafuer braucht.  Okay, das sieht ja mal so aus, als ob Software B einfach die bessere Software ist, weil es in jeder der Kategorien, die du hier getestet hast, schneller ist.", "start": 93.0, "end": 123.0}, {"text": "  Du koenntest also jetzt davon ausgehen, dass du dem Kunden Software B in das Produkt, was deine Firma produziert, einbaust und dass der Kunde damit happy ist.  Nun hast du aber vielleicht nicht bedacht, dass der Kunde, die dieses Programm benutzen wird fuer Datensaetze, die viel viel groesser sind, als die, fuer die du das getestet hast, zum Beispiel fuer N.  gleich 10 hoch 5.", "start": 124.0, "end": 141.0}, {"text": "  Klingt jetzt irgendwie ziemlich viel, ist aber letztendlich 100.000.  Also zum Beispiel gibt es ziemlich viele Doerfer und Staedte in Deutschland, die 100.000 ein, vielleicht nicht Doerfer, aber die 100.000 Einwohner haben.  Wenn man jetzt an die Stadtverwaltung, eine Software verkauft, dann muss man schon damit rechnen, dass da vielleicht 100.000 Datensaetze verarbeitet werden.", "start": 141.0, "end": 170.0}, {"text": "  Und jetzt moechte ich dir zeigen, was denn dann die Ergebnisse fuer die Laufzeiten von Software A und Software B waeren.  Naemlich einmal 10 hoch 5 Sekunden und einmal 10 hoch 7 Sekunden.  10 hoch 5 ist schon ziemlich heftig, das ist mehr als ein Tag, aber 10 hoch 7 ist noch viel heftiger, das sind fast vier Monate.", "start": 170.0, "end": 195.0}, {"text": "  Okay, das heisst also, dass wir, ja, also lass uns das vielleicht ganz kurz noch zusammenfassen.  Software A, also Software B, gewinnt in diesen vier Faellen, aber Software A gewinnt in diesem Fall.  Wie kann das sein?  Habe ich diese Zahlen einfach nur rein zufaellig gewaehlt? Nein, habe ich natuerlich nicht.", "start": 195.0, "end": 223.0}, {"text": "  Der Rechenzeit von Software A ergibt sich aus 1000n plus 100.000 und der Rechenaufwand von Software B aus n\u00b2 jeweils in Millisekunden ausgedrueckt.  Das heisst, irgendwie ist die Funktion A fuer kleine Zahlen wesentlich angenehmer, sorry, die Funktion B, fuer kleine Zahlen wesentlich angenehmer als Funktion A.", "start": 224.0, "end": 250.0}, {"text": "  Aber ab einer bestimmten Groesse aendert sich das und von da an, wie wir sehen, anhand des n\u00b2, wird das Ergebnis immer nur noch weiter schlimmer werden.  Okay, das heisst also, du haettest als Informatikerin oder als Informatiker mehr als diese Tests laufen lassen muessen, die Tests haben dir das falsche Ergebnis geliefert.  Du haettest genau das wissen muessen, was wir heute lernen.", "start": 251.0, "end": 272.0}, {"text": "  Und das ist gar nicht so kompliziert.  Wir brauchen natuerlich eine Art und Weise, wie wir die Funktion A und die Funktion B miteinander vergleichen koennen, um genau solche Ueberraschungen zu vermeiden.  Dann schauen wir uns doch erst mal an, wie den Funktionen wachsen.  Denn was wir hier machen, ist ja, wir nehmen n und schauen, wie waechst der Rechenaufwand, wenn n immer immer groesser wird.", "start": 273.0, "end": 311.0}, {"text": "  Das heisst, wir gucken uns den Rechenaufwand eines Programms, eines Algorithmus an, in Abhaengigkeit der Groesse der Eingabe zu diesem Algorithmus und die wird meistens durch n angezeigt.  Also, wir gucken uns hier mal ein paar Beispiele an.  Wir haben die gerade 100n, wo der Rechenaufwand also genau 100 mal die Groesse der Eingabe ist.  Wir haben dann 5n\u00b2, 0,5n hoch 3 und 2 hoch n.", "start": 311.0, "end": 340.0}, {"text": "  Und wir sehen, dass durch diese grosse Zahl 100 vor dem n, zwar diese lineare Funktion erst mal bis, weiss ich, 8 groesser ist als alle anderen Funktionen,  dass sich das aber relativ schnell aendert.  Und wir koennen sehen, dass es so zu sein scheint, dass n, also linear, langsam erwaechst als quadratisch, langsam erwaechst als kubisch, langsam erwaechst als exponentiell.  Und natuerlich genauso ist das.", "start": 340.0, "end": 371.0}, {"text": "  Wir haben das jetzt hier nochmal dargestellt, ohne irgendwelche Faktoren davor.  Und wir haben hier die 1, das ist also eine konstante Funktion, die ueberhaupt nicht waechst.  Wir haben hier ein Log zur Basis 2 von n, das waechst also stark lang, also sehr stark langsamer als die lineare Funktion n.  Und wir haben Wurzel von n, was auch langsamer waechst als n, aber staerker als log n.", "start": 372.0, "end": 410.0}, {"text": "  Dann haben wir n log n, das sind also n multipliziert mit log n, n\u00b2, 2 hoch n und dann noch steiler ist n Fakultaet.  Und das sind auch so ein bisschen die verschiedenen Kategorien von Funktionen, die wir betrachten werden, um abzuschaetzen, wie schnell eine bestimmte Funktion waechst.  Unser Ziel ist es, eine sogenannte Schranke festzulegen.", "start": 410.0, "end": 437.0}, {"text": "  Wir wollen sagen, dass eine Funktion, die die Laufzeit eines Algorithmus bestimmt, beschraenkt ist durch eine andere Funktion.  Beschraenkt kann sein entweder von oben oder von unten.  Und wir gucken uns jetzt erstmal eine oberische Schranke an.", "start": 437.0, "end": 465.0}, {"text": "  Und zwar sagen wir, dass die Funktion f in der Ordnung von g ist, oder man sagt auch f ist in o von g, das ist ein grosses o, genau dann und nur dann, wenn.  Und jetzt kommt eine Formel, die wir scheibchenweise analysieren, ist aber ganz einfach.", "start": 465.0, "end": 490.0}, {"text": "  Das gilt ganz genau, dass f in o von g ist, was bedeutet, dass f von g von oben beschraenkt ist, wenn es folgende Konstanten gibt, naemlich a und b, die muessen groesser 0 sein.  Und n0 aus n, das muesste eigentlich n plus sein, also das gilt auch hier, nur positive Zahlen.  Es muss diese 3 Konstanten geben, sodass die Funktion f of n kleiner gleich a mal g von n plus b ist.", "start": 491.0, "end": 524.0}, {"text": "  Jetzt ist auch klar, warum wir obere Schranke dazu nennen, weil wir sagen, f von n muss immer kleiner sein, also von oben durch g von n beschraenkt.  Wobei wir aber g erlauben, mit einer konstanten Multiplizitaet zu werden und eine weitere Konstante als Addition zu bekommen.  Und das muss gelten fuer alle n, die groesser sind als n0.", "start": 524.0, "end": 548.0}, {"text": "  Das heisst, damit wir davon reden koennen, dass eine Funktion g, eine andere Funktion f von oben beschraenkt,  das muss nicht am Anfang gelten, das muss nicht gelten fuer alle n, die kleiner sind als n0.  Und das muss auch nur ab n0 gelten gegeben, den Faktor a und den Summand b.  Okay, das heisst, diese Definition sagt uns genau, wann eine Funktion g, eine obere Schranke fuer f ist.", "start": 548.0, "end": 583.0}, {"text": "  Koennen wir uns ja mal ganz kurz angucken, wir hatten ja, ich glaube, so etwas wie a von n, ich weiss nicht mehr genau was,  es war aber, sagen wir mal, 1000 mal n plus 10.000.  Na gut, also wir koennen jetzt zum Beispiel sagen, klein a ist 1000 und klein b ist das.  Und dann wuerde a, koennten wir schreiben, a von n ist n o von n.", "start": 583.0, "end": 616.0}, {"text": "  Das heisst, die Funktion a von n waechst so schnell wie die lineare Funktion n  und ist von ihr von oben beschraenkt.  Das heisst, wir haben n a gleich 1000, b gleich 10.000 und dann gilt das fuer n 0 gleich 0,  weil wir hier ein gleich, kleine Gleich haben.  Okay, wir wissen also jetzt, dass wir vorher in unserem Beispiel am Anfang eine Funktion a von n hatten, die lineare waechst.", "start": 616.0, "end": 656.0}, {"text": "  Und linear ist natuerlich besser als quadratisch.  Okay, also diese eine Zeile ist, was ihr euch ungefaehr intuitiv merken muesst, um zu verstehen,  unter welchen Umstaenden eine Funktion f von der Funktion e, g von oben beschraenkt ist.  Der Vollstaendigkeit halber gibt es aber natuerlich auch noch andere Arten von Schranken.", "start": 657.0, "end": 684.0}, {"text": "  Es gibt also die Schranke von oben mit dem Kleine, das gleiche und von groesser und groesser gleich.  Die werden durch die Symbole, wie hier beschrieben, dargestellt.  Also, das heisst, was hier ist, wuerde da reingesetzt werden  und das entsprechende Symbol hier wuerde dann dort stehen.  Also, das heisst, wir koennen sagen, f ist gross-omega von g.  Ich schreibe das mal einfach hier drueber.", "start": 685.0, "end": 718.0}, {"text": "  Gross-omega von g, wenn, und jetzt muesste ich bei omega, muss also genau dieses Zeichen umgedreht werden.  Okay? Das heisst, wir haben fuenf Definitionen, gross-o, klein-o, gross-taeter, gross-omega und klein-omega,  die genau diese verschiedenen Arten von Schranken beschreiben.", "start": 718.0, "end": 747.0}, {"text": " Okay, wie kann uns das jetzt helfen?  Nun, wir haben mit dieser Formel eine Moeglichkeit, rauszukriegen, wie stark eine Funktion f waechst.  Natuerlich, ja, das haben wir, und wir wollen natuerlich jetzt gucken, welchen Algorithmus benutzen wir.  Das ist natuerlich der Algorithmus, bei dem diese Funktion am wenigsten waechst.", "start": 747.0, "end": 768.0}, {"text": "  Und somit haben wir eine Hierarchie von Funktionen, die die Laufzeit von Algorithmen beschreiben.  Unser liebster Algorithmus ist der, der in konstanter Zeit laeuft, also Order von 1, o von 1.  Denn das ist ein Algorithmus, der laeuft in konstanter Zeit.  Wie ihr euch vorstellen koennt, gibt es nicht sehr viele hilfreiche Algorithmen, fuer die das der Fall ist.", "start": 768.0, "end": 797.0}, {"text": "  Dann gibt es die naechste Klasse von Algorithmen, die laufen in o von log n.  Das habt ihr zum Beispiel, wenn ihr einen binaeren Suchbaum traversiert, um ein bestimmtes Element zu finden, das dauert log n.  Dann haben wir die linearen Algorithmen, die o von n sind.  Dann haben wir o von n log n, da gibt es eine ganze Menge von Such-Sortier-Algorithmen, die so funktionieren.", "start": 797.0, "end": 825.0}, {"text": "  Dann haben wir n\u00b2, natuerlich kommen danach die ganzen anderen Polenome, hoch 3 hoch 4 hoch 5 und so weiter.  Dann haben wir 2 hoch n und letztendlich n Fakultaet, und natuerlich wird das immer groesser.  Das heisst, wir koennten jetzt mal anfangen, uns ein paar Fragen zu stellen.  Wir hatten ja a von n, ich sage nochmal 1000n plus 10.000.", "start": 825.0, "end": 859.0}, {"text": " Und jetzt fragen wir uns, ist a von n in o von n Fakultaet?  Die Antwort ist ja.  n Fakultaet beschraenkt das Wachstum von a von n von oben auf eine nicht sehr sinnvolle Art und Weise,  weil n Fakultaet waechst total schnell, aber es beschraenkt a von n von oben.  Das heisst, im Grunde genommen hilft uns diese Aussage nicht viel.", "start": 859.0, "end": 888.0}, {"text": "  Wir wollen ja eigentlich die niedrigste obre Schranke finden, und das wissen wir ja schon, das ist o von n.  Ist a von n auch, das schreibe ich mal jetzt lieber hier oben hin,  ist a von n auch o ord von log n? Nein.  Denn wir werden kein a, b und n0 finden, so dass die Bedingung gilt.", "start": 889.0, "end": 926.0}, {"text": " Die lineare Funktion a von n waechst tatsaechlich schneller als log n,  und egal welche Konstanten wir finden, das funktioniert nicht.  Okay, das heisst also, wir koennen jetzt versuchen, die Laufzeit von Algorithmen zu beschreiben in dieser grossen o Notation.  Und wenn wir dann ein Algorithmus haben, der quadratisch ist und ein der n log n ist, dann sollten wir den der n log n ist vorziehen.", "start": 928.0, "end": 957.0}, {"text": "  Allerdings, nur dann, wenn wir wissen, dass wir auch tatsaechlich sehr grosse n verwenden wollen.", "start": 957.0, "end": 981.0}, {"text": " Wenn wir wissen, dass die groesste Eingabe, die in unseren Algorithmus jemals reinkommen wird, nur n gleich 10 hat,  dann ist diese asymptotische Analyse, also asymptotisch heisst, wie verhaelt sich der Algorithmus, wenn sich n unendlich annaehert,  ist diese nicht sehr hilfreich, denn mit dieser Big O Notation untersuchen wir genau das.", "start": 981.0, "end": 986.0}, {"text": "  Wie verhaelt sich die Laufzeit von Algorithmus, wenn sich die Groesse des Inputs unendlich annaehert?  Wenn wir wissen, es gibt nur Inputs der Groesse 12, dann koennen wir tatsaechlich dann zaehlen die Konstanten,  dann ist es wichtig, wie schnell etwas laeuft.  Das haengt natuerlich davon ab, welchen Prozessor habt ihr, wie viele Speicher habt ihr und so weiter und so fort.", "start": 986.0, "end": 1008.0}, {"text": "  Wenn es darum geht, einen ganz bestimmten Input zu berechnen, dann ist das nicht das richtige Werkzeug,  sondern dann solltet ihr einfach wirklich euer System Benchmarken.  Aber wenn n auch sehr gross werden kann, ist genau das das Werkzeug, was ihr verwenden sollte.", "start": 1008.0, "end": 1033.0}, {"text": " Und das Verrueckte bei den n\u00b2n\u00b2n\u00b2n ist, dass das so schnell waechst,  dass schon fuer sehr, sehr kleine n dieses Wachstum absolut relevant sein wird.  Also, sobald ihr n groesser 10 habt, muesst ihr euch ueber diese Sachen Gedanken machen,  weil 2 hoch 10 ist schon eine grosse Zahl.  10 Fakutet ist schon eine grosse Zahl, die tatsaechlich die Laufzeit von eurem Algorithmus beeinflussen kann.", "start": 1033.0, "end": 1055.0}, {"text": "  Okay, schauen wir uns das mal an praktischem Beispiel an.  Nehmen wir mal an, wir haben hier Quellcode, der die Matrix-Multipikation darstellt.  Also, Matrix-Multipikation, da haben wir 3 Matrizen.  Wir nehmen mal hier quadratische Matrizen, das macht es einfacher.  A, B und C, und die sind jeweils n mal n.  Die Bezeichnung ABC sind so genommen, dass sie auch den Quellcode entsprechen.", "start": 1055.0, "end": 1084.0}, {"text": "  Und das heisst, wir koennen uns mal den Quellcode angucken.  Das sind die I und die J Vorschleife, die im Grunde genommen die gesamte Ergebnis Matrix C durchgehen  und fuer jedes I und J ein Element der Matrix C berichten.  Zuerst wird innerhalb der zweiten Schleife, ich mache mal hier mit meinem Laser-Pointer,  also diese beiden Schleifen hier durchlaufen alle Elemente dieser Matrix.", "start": 1084.0, "end": 1122.0}, {"text": "  Wir setzen zuerst das Element auf 0  und dann haben wir die dritte Schleife, die K-Schleife, die im Grunde genommen  einmal diese Reihe mit dieser Spalte multipliziert.  Wir haben hier I und J, und I sind jeweils die Reihe in der Matrix A und die Spalte in der Matrix B.  So, das heisst, und das ist genau das, was in dieser Schleife hier passiert.", "start": 1122.0, "end": 1155.0}, {"text": "  Wir berechnen das mal das, um dieses Element herauszukriegen.  Okay, also so viel zu Matrix Multiplikation.  Jetzt ist natuerlich die Frage, wie lange dauert das?  Ach so, wir haben natuerlich noch K vergessen, K ist der Index, der entlang dieser beiden Pfeile berechnet wird.", "start": 1155.0, "end": 1187.0}, {"text": " So, was ist jetzt hier der Aufwand?  Wir haben natuerlich in der innersten Schleife, haben wir eine Lineare, also das hier ist Order von N.  Denn wenn N groesser wird, wird auch diese Schleife haeufiger durchlaufen.  Was in dieser konkreten Zeile passiert, ist eine Addition und eine Multiplikation.", "start": 1187.0, "end": 1207.0}, {"text": "  Und wir gehen jetzt einfach mal davon aus, dass diese primitiven Operationen in konstanter Zeit ausgefuehrt werden koennen.  Genauso wie der Zugriff auf die Indizes der verschiedenen Matrizen.  Das heisst, diese Zeile benutzt Constant Time.  Also schreibe ich noch mal dahin, das ist Constant Time, das Ganze wird Order N ausgefuehrt.", "start": 1207.0, "end": 1228.0}, {"text": "  Was passiert also daraus zusammen, wenn wir Order N mal etwas von konstanter Zeit ausfuehren,  ergibt sich daraus fuer das gesamte Ding Order N.  Okay, jetzt haben wir aber nochmal eine Schleife drum herum, jetzt renne ich ein bisschen, habe ich keinen Platz mehr.  Das hier ist ja auch nochmal Order N und das hier ist nochmal Order N.", "start": 1228.0, "end": 1256.0}, {"text": "  Das heisst, wir haben dreieinander geschachtelte Schleifen, die N mal durchlaufen werden.  Na gut, das heisst, der gesamte Aufwand ist Order N mal Order N mal Order N.  Und bei der Schachtelung ist es so, dass wir tatsaechlich das einfach zusammen multiplizieren koennen und deswegen sagen koennen, das ist Order N hoch 3.", "start": 1256.0, "end": 1282.0}, {"text": "  Die Matriksmultifikation ist also eine Operation, die quadratisch in N Berechnungszeit benoetigt.  Quadratisch ist schon nicht so gut, deswegen gibt es in der Linie nahe gebraucht viele, viele Tricks, um ganz, ganz grosse Matrizen schneller zu berechnen.", "start": 1283.0, "end": 1317.0}, {"text": " Insbesondere zum Beispiel die Internet-Suche basiert auf riesigen Matrizen, in denen jede Spalte eine Webseite ist,  die mit den Fixpunkt-Operationen berechnet werden, um rauszukriegen, wie das Ranking bei einer Suche dargestellt werden soll, welche Seite als Erste kommen soll.", "start": 1317.0, "end": 1328.0}, {"text": "  Da hat man natuerlich darauf verzichtet, bei diesen Millionen von Spalten und Zeilen in der Matriks, das wirklich so mit Order N hoch 3 auszurechnen.  Und da gibt es viele Tricks, insbesondere bei Matrizen, die sparse sind, also wo viele Nullen in den Elementen sind.", "start": 1329.0, "end": 1348.0}, {"text": "  Denn eine Webseite in dieser riesigen Matriks, wo die Spalten und die Reihen aller Webseiten sind, ist dort in einem Element dieser Matriks,  ist vermerkt, ob eine Webseite auf eine andere verweist.  Man natuerlich verweist jede einzelne Webseite nur auf ganz wenige andere Webseiten.", "start": 1348.0, "end": 1364.0}, {"text": "  Das heisst, die Gesamtmatrix hat sehr, sehr viele Nullen und das kann man ausnutzen, um diese Berechnung wesentlich effizienter zu machen.  Aber das ist vielleicht fuer einen anderen Kurs.  Wir haben also jetzt angeguckt, wie wir die Laufzeit in der Big O-Notation von einem Algorithmus anschauen koennen,  wenn wir dreieinander geschachtelte Schleifen haben.", "start": 1364.0, "end": 1385.0}, {"text": "  Es gibt aber noch ein paar andere Schematas, die man verwenden kann, um sich das anzuschauen.  Zum Beispiel haben wir die Sequenz.  Nehmen wir mal an.  Wir haben hier Order N-Facutet und wir haben hier Order N\u00b2.  Also wir haben zwei unterkomponenten Schema A und Schema B, die ausgefuehrt werden koennen.", "start": 1385.0, "end": 1411.0}, {"text": " Was ist das Gesamtergebnis?  Nun gut, die Laufzeit von Schema B wird immer einfach nur eine ganz normale Unterkomponente sein von N-Facutet.  Wir koennen praktisch N\u00b2 abdecken, indem wir einfach nur einen groesseren Faktor A vor N-Facutet machen.  Das heisst, diese Dinge zusammen hier ist Order N-Facutet.  Das N-Facutet dominiert den Aufwand, den Schema B erzeugt.", "start": 1411.0, "end": 1446.0}, {"text": "  Nehmen wir doch mal hier Order von N log N fuer Schema A und hier Order von N.  Gut, also das heisst, hier ist es ein Algorithmus der N\u00b2A oder B ausfuehrt.", "start": 1446.0, "end": 1476.0}, {"text": " Das heisst, wir muessen im Grunde genommen uns jetzt fragen, woran sind wir interessiert?  Sind wir interessiert an der Worst Case, also der schlimmsten Fall der Worst Case Analysis?  Sind wir interessiert an der Best Case Analysis?  Oder an der Average Case Analysis?  Ihr kennt das vielleicht noch von QuickSort, wo wir im Average Case N log N hatten,  aber im Worst Case N\u00b2.", "start": 1476.0, "end": 1494.0}, {"text": "  QuickSort braucht im schlimmsten Fall N\u00b2, aber im Durchschnitt ist es ein sehr effizienter Algorithmus.  Innerhalb dieses Kurses, glaube ich, werden wir hauptsaechlich uns immer mit dem Worst Case beschaeftigen,  und genauso auch jetzt.  Der Worst Case ist natuerlich, dass Schema A durchlaufen wird, weil Schema A aufwendiger ist, N log N.", "start": 1494.0, "end": 1522.0}, {"text": "  Das heisst, was insgesamt hier rauskommt, ist N log N, weil N log N dominiert oder N.  Hier ist die Wiederholung, und genau das ist das, was wir gerade hatten, nehmen wir an.  Schema B ist order N, und Schema A ist auch order N.  Dann koennen wir die einfach zusammen multiplizieren, weil das innere order N der N malen ausgefuehrt wird,  und wir haben also insgesamt order N\u00b2.", "start": 1522.0, "end": 1546.0}, {"text": "  Oder wir haben eine Schachtelung, wo hier order N hoch 5 ausgefuehrt wird,  und hier drin order N, das koennt ihr jetzt nicht sehen, da ist mein Gesicht,  und im Schema B order 2 hoch N.  Ja, im Grunde genommen ist das nicht so unaehnlich wie die Sequenz, die wir hier haben,  weil ja letztendlich sowohl Schema A als auch Schema B ausgefuehrt werden.", "start": 1546.0, "end": 1576.0}, {"text": "  Das heisst, wir nehmen einfach die groessere von den beiden, und das ist in diesem Fall order 2 hoch N.  Wiederum gilt, dass order N hoch 5 einfach absorbiert wird von diesem 2 hoch N.  Wir muessen einfach nur ein gewisses A oder ein gewisses B waehlen oder warten bis zum bestimmten hoeheren N 0,  und dann wird egal, was N hoch 5 macht, immer kleiner sein als 2 hoch N.", "start": 1576.0, "end": 1607.0}, {"text": "  Okay, das heisst, mit diesen verschiedenen Methoden koennt ihr euch ein Algorithmus, den ihr selber aufgeschrieben habt,  koennt ihr analysieren und rauskriegen, was ist die Laufzeit.  Wenn ihr also zwei Versionen von einem Algorithmus schreibt und diese beiden Laufzeiten analysiert,  koennt ihr rauskriegen, welcher von beiden asymptotisch sich besser verhalten wird.", "start": 1607.0, "end": 1628.0}, {"text": "  Also wenn N die groesste der Eingabe Richtung unendlich geht,  welcher dieser Algorithmen wird euch die bessere Laufzeit liefern.  Okay, wir haben uns jetzt sehr viel mit Laufzeit beschaeftigt, also eigentlich ausschliesslich.  Natuerlich kann man diese ganzen Untersuchungen auch fuer den benoetigten Speicherplatz machen  und in bestimmten Anwendungen ist das auch sinnvoll.", "start": 1628.0, "end": 1656.0}, {"text": "  Aber auf modernen Rechnen ist normalerweise Speicher mit Cash und Festplatte und so weiter.  Kein so grosses Problem und die meisten Anwendungen verwenden auch Algorithmen, die relativ Daten kompakt sind.  Deswegen ist die Laufzeitanalyse mit Hilfe dieser BigO-Notation eigentlich der Standard.", "start": 1656.0, "end": 1685.0}, {"text": " Und wenn wir uns gemeinsam Algorithmen angucken werden in den naechsten Vorlesungen,  wenn wir auch immer wieder darauf zurueckkommen und analysieren, was ist die Laufzeit,  das muss man wissen, um zu wissen wofuer kann ich so ein Algorithmus anwenden.  Wenn die Laufzeit zwei Hoch-N ist, also exponentiell,  dann wird es ziemlich schwierig sein diesen Algorithmus auf irgendetwas Sinnvolles anzuwenden.", "start": 1685.0, "end": 1708.0}, {"text": "  Wenn ihr Algorithmus findet, der Log N ist, dann wisst ihr ziemlich sicher,  dass ihr eine ganz gute Loesung habt, die fuer auch sehr grosse Inputs gut funktionieren wird.  Okay, also die Zusammenfassung.  Wir haben gesprochen ueber Laufzeit von Algorithmen und zwar asymptotisch.", "start": 1708.0, "end": 1754.0}, {"text": " Was passiert, wenn N Richtung unendlich geht?  Wir haben die BigO-Notation eingefuehrt, die eine Schranke darstellt,  in diesem Fall eine obere Schranke fuer das Wachstum.  Wir haben gesehen, wie wir ein Algorithmus analysieren koennen.  Ich nenne das mal verschiedene Schematah.", "start": 1759.0, "end": 1784.0}, {"text": " Um aus Einzelkomponenten eine Schematah fuer Komposition,  wie wir aus Einzelkomponenten ein groesseren Algorithmus komponieren koennen.  Wir haben gesehen, dass es best worst un average case analysis gibt,  dass wir aber in allermeisten Faellen uns mit der worst case analysis beschaeftigen.", "start": 1784.0, "end": 1818.0}, {"text": " Also sicherstellen wollen, dass im schlimmsten Fall ein Algorithmus nicht mehr Zeit in Anspruch nimmt,  als wir es berechnet haben.  Und wir haben natuerlich, das sollte man sich da erinnern,  diese Funktion zum Beispiel log n, log n, n, n, log n und so weiter bis hin zu n Fakultaet.", "start": 1818.0, "end": 1844.0}, {"text": " All diese Dinge sollten Leute, die euch merken, dass es da eine Hierarchie gibt  und dass je niedriger wir sein koennen, desto besser ist es, wenn wir wissen,  dass wir grosse Eingaben haben werden, also grosse Enz.", "start": 1844.0, "end": 1869.0}, {"text": " Okay, dieses kleine Werkzeug, die Big O-Notation,  oder einfach nur O-Notation, auf Englisch sagt man Big O-Notation,  ist absolut essentiell fuer jeden Informatiker, macht auch Sinn,  wir wollen verstehen, wie schnell der Rechenaufwand waechst,  wenn die Eingabe fuer mein Algorithmus waechst.  Und genau das koennt ihr jetzt. Bis bald.", "start": 1869.0, "end": 1877.0}]}]